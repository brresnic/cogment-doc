
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Cogment user documentation - Cogment is an innovative open source AI platform designed to leverage the advent of AI to benefit humankind through human-AI collaboration">
      
      
      
        <meta name="author" content="AI Redefined">
      
      
        <link rel="canonical" href="https://docs.cogment.ai/cogment/tutorial/7-dqn-player/">
      
      <link rel="icon" href="../../../images/cogment_favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.1.5">
    
    
      
        <title>Step 7: Add a player trained with Reinforcement Learning using DQN - Cogment</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.bde7dde4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ef6f36e2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../../style/theme.css">
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-146998765-2","doc.cogment.ai"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#step-7-add-a-player-trained-with-reinforcement-learning-using-dqn" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Cogment" class="md-header__button md-logo" aria-label="Cogment" data-md-component="logo">
      
  <img src="../../../images/cogment_logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cogment
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Step 7: Add a player trained with Reinforcement Learning using DQN
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/cogment/cogment-doc/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Cogment" class="md-nav__button md-logo" aria-label="Cogment" data-md-component="logo">
      
  <img src="../../../images/cogment_logo.png" alt="logo">

    </a>
    Cogment
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/cogment/cogment-doc/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      <label class="md-nav__link" for="__nav_1">
        Introduction
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Introduction" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Introduction
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Overview
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../introduction/installation/" class="md-nav__link">
        Installation & Setup
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        Support
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Support" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Support
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../support/community-channels/" class="md-nav__link">
        Community channels
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      <label class="md-nav__link" for="__nav_3">
        Concepts
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Concepts" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../concepts/core-concepts/" class="md-nav__link">
        Core Concepts
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../concepts/glossary/" class="md-nav__link">
        Glossary
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        Cogment
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Cogment" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Cogment
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" checked>
      
      <label class="md-nav__link" for="__nav_4_1">
        Tutorial
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Tutorial" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Tutorial
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../1-bootstrap-and-data-structures/" class="md-nav__link">
        Step 1: Bootstrap a Cogment app
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../2-random-player/" class="md-nav__link">
        Step 2: Implement actor and environment
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../3-rewards/" class="md-nav__link">
        Step 3: Introduce rewards
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../4-heuristic-player/" class="md-nav__link">
        Step 4: Create a heuristic player
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../5-human-player/" class="md-nav__link">
        Step 5: Add a human player in the loop
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../6-web-client/" class="md-nav__link">
        Step 6: Implement a web client for the human player
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Step 7: Add a player trained with Reinforcement Learning using DQN
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Step 7: Add a player trained with Reinforcement Learning using DQN
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#creating-an-actor-service" class="md-nav__link">
    Creating an actor service
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#playing-against-the-heuristic-player" class="md-nav__link">
    Playing against the heuristic player
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementing-the-deep-q-network" class="md-nav__link">
    Implementing the Deep Q Network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-exploration" class="md-nav__link">
    Random exploration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#replay-buffer" class="md-nav__link">
    Replay buffer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    Training!
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-guide/" class="md-nav__link">
        API Guide
      </a>
    </li>
  

          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      <label class="md-nav__link" for="__nav_4_3">
        API Reference
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="API Reference" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/cogment-yaml/" class="md-nav__link">
        cogment.yaml
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/python/" class="md-nav__link">
        python
      </a>
    </li>
  

          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_3" type="checkbox" id="__nav_4_3_3" >
      
      <label class="md-nav__link" for="__nav_4_3_3">
        Javascript/Typescript SDK
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Javascript/Typescript SDK" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_3">
          <span class="md-nav__icon md-icon"></span>
          Javascript/Typescript SDK
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/modules/" class="md-nav__link">
        Modules
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/classes/actorsession/" class="md-nav__link">
        Class: ActorSession
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/classes/cogmentservice/" class="md-nav__link">
        Class: CogmentService
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/classes/trialcontroller/" class="md-nav__link">
        Class: TrialController
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/enums/eventtype/" class="md-nav__link">
        Enum: EventType
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogmentyaml/" class="md-nav__link">
        Interface: CogmentYaml
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogmentyamlactor/" class="md-nav__link">
        Interface: CogmentYamlActor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/" class="md-nav__link">
        Interface: CogmentYamlActorClass
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogmentyamldatalog/" class="md-nav__link">
        Interface: CogmentYamlDatalog
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/" class="md-nav__link">
        Interface: CogmentYamlTrialParameters
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogsettings/" class="md-nav__link">
        Interface: CogSettings
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/cogsettingsactorclass/" class="md-nav__link">
        Interface: CogSettingsActorClass
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/createserviceoptions/" class="md-nav__link">
        Interface: CreateServiceOptions
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/event/" class="md-nav__link">
        Interface: Event
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/reward/" class="md-nav__link">
        Interface: Reward
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/sendmessageoptions/" class="md-nav__link">
        Interface: SendMessageOptions
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-api-reference/javascript/interfaces/trialactor/" class="md-nav__link">
        Interface: TrialActor
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_4" type="checkbox" id="__nav_4_4" >
      
      <label class="md-nav__link" for="__nav_4_4">
        Low Level API Guide
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Low Level API Guide" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Low Level API Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-low-level-api-guide/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../cogment-low-level-api-guide/grpc/" class="md-nav__link">
        gRPC API Reference
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../dashboard/metrics-and-dashboard/" class="md-nav__link">
        Metrics & Dashboard
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../license/" class="md-nav__link">
        License
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#creating-an-actor-service" class="md-nav__link">
    Creating an actor service
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#playing-against-the-heuristic-player" class="md-nav__link">
    Playing against the heuristic player
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementing-the-deep-q-network" class="md-nav__link">
    Implementing the Deep Q Network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#random-exploration" class="md-nav__link">
    Random exploration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#replay-buffer" class="md-nav__link">
    Replay buffer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    Training!
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/cogment/cogment-doc/edit/main/src/cogment/tutorial/7-dqn-player.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="step-7-add-a-player-trained-with-reinforcement-learning-using-dqn">Step 7: Add a player trained with Reinforcement Learning using DQN<a class="headerlink" href="#step-7-add-a-player-trained-with-reinforcement-learning-using-dqn" title="Permanent link">&para;</a></h1>
<blockquote>
<p>This part of the tutorial follows <a href="../5-human-player/">step 5</a> and <a href="../6-web-client/">step 6</a>, make sure you've gone through either one of those before starting this one. Alternatively the completed step 5 can be retrieved from the <a href="https://github.com/cogment/cogment-tutorial-rps" target="_blank">tutorial's repository</a>.</p>
</blockquote>
<p>In this step of the tutorial, we will go over yet another actor implementation and this implementation will be learning from its experience. We will implement an RPS player using Reinforcement Learning (RL) and more precisely a <a href="https://arxiv.org/pdf/1312.5602.pdf" target="_blank">Deep Q Network</a>, one of the foundational algorithms of modern RL.</p>
<p>While we will explain some aspects of RL and DQN along the way, we won't go into all the details. Interested readers can refer to <a href="http://incompleteideas.net/book/the-book-2nd.html" target="_blank">"Reinforcement Learning: An Introduction" by Richard S. Sutton and Andrew G. Barto</a> or to the original Deep Q Network article linked above.</p>
<h2 id="creating-an-actor-service">Creating an actor service<a class="headerlink" href="#creating-an-actor-service" title="Permanent link">&para;</a></h2>
<p>Back in <a href="../4-heuristic-player">step 4</a>, we created a new implementation of the <code>player</code> actor class in the same service as the previous one. It was a sound choice for this implementation because it was small and didn't require additional dependencies. In some cases it makes more sense to create a fully separated service for a new actor implementation. This is what we will do here.</p>
<p>Start by copy/pasting the <code>random_agent</code> folder and name the copy <code>dqn_agent</code>. Let's then clean up <code>dqn_agent/main.py</code> to keep only a single actor implentation and name it <code>dqn_agent</code>. You should end up with something like the following.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">cog_settings</span>
<span class="kn">from</span> <span class="nn">data_pb2</span> <span class="kn">import</span> <span class="n">PlayerAction</span>

<span class="kn">import</span> <span class="nn">cogment</span>

<span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">dqn_agent</span><span class="p">(</span><span class="n">actor_session</span><span class="p">):</span>
    <span class="c1"># ...</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Deep Q Network agents service up and running.&quot;</span><span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">cogment</span><span class="o">.</span><span class="n">Context</span><span class="p">(</span><span class="n">cog_settings</span><span class="o">=</span><span class="n">cog_settings</span><span class="p">,</span> <span class="n">user_id</span><span class="o">=</span><span class="s2">&quot;rps&quot;</span><span class="p">)</span>
    <span class="n">context</span><span class="o">.</span><span class="n">register_actor</span><span class="p">(</span>
        <span class="n">impl</span><span class="o">=</span><span class="n">dqn_agent</span><span class="p">,</span>
        <span class="n">impl_name</span><span class="o">=</span><span class="s2">&quot;dqn_agent&quot;</span><span class="p">,</span>
        <span class="n">actor_classes</span><span class="o">=</span><span class="p">[</span>
            <span class="s2">&quot;player&quot;</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">)</span>

    <span class="k">await</span> <span class="n">context</span><span class="o">.</span><span class="n">serve_all_registered</span><span class="p">(</span><span class="n">cogment</span><span class="o">.</span><span class="n">ServedEndpoint</span><span class="p">(</span><span class="n">port</span><span class="o">=</span><span class="mi">9000</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div>

<p>Since we have created a new service we need to reference it at several places for everything to work properly. First, let's edit <code>docker-compose.yaml</code> to add the new service. To do that, simply add the following under the <code>services</code> key: it tells docker-compose about the new service.</p>
<div class="highlight"><pre><span></span><code><span class="nt">dqn-agent</span><span class="p">:</span>
    <span class="nt">build</span><span class="p">:</span>
        <span class="nt">context</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dqn_agent</span>
        <span class="nt">dockerfile</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">../py_service.dockerfile</span>
</code></pre></div>

<p>Then we will need to edit <code>cogment.yaml</code> to make <code>cogment run generate</code> run in the new service's directory and have <code>cogment run build</code> and <code>cogment run start</code> respectively trigger its build and its start. We will change the <code>generate</code>, <code>build</code> and <code>start</code> keys under <code>commands</code>.</p>
<div class="highlight"><pre><span></span><code><span class="nt">commands</span><span class="p">:</span>
    <span class="nt">generate</span><span class="p">:</span> <span class="p p-Indicator">&gt;</span>
        <span class="no">cogment generate</span>
        <span class="no">--python_dir environment</span>
        <span class="no">--python_dir client</span>
        <span class="no">--python_dir random_agent</span>
        <span class="no">--python_dir dqn_agent</span>
    <span class="c1"># ...</span>
    <span class="nt">build</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">docker-compose build client dashboard metrics orchestrator environment random-agent dqn-agent</span>
    <span class="c1"># ...</span>
    <span class="nt">start</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">docker-compose up dashboard metrics orchestrator environment random-agent dqn-agent</span>
</code></pre></div>

<p>Finally, the metrics server needs to know about this new data source. In <code>metrics/prometheus.yml</code>, add a new item under the <code>scrape_configs</code> key.</p>
<div class="highlight"><pre><span></span><code><span class="p p-Indicator">-</span> <span class="nt">job_name</span><span class="p">:</span> <span class="s">&quot;dqn-agent&quot;</span>
  <span class="nt">dns_sd_configs</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">names</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="s">&quot;dqn-agent&quot;</span>
        <span class="nt">type</span><span class="p">:</span> <span class="s">&quot;A&quot;</span>
        <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8000</span>
        <span class="nt">refresh_interval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5s</span>
</code></pre></div>

<h2 id="playing-against-the-heuristic-player">Playing against the heuristic player<a class="headerlink" href="#playing-against-the-heuristic-player" title="Permanent link">&para;</a></h2>
<p>We will train our new player against the <a href="../4-heuristic-player/">heuristic player</a> we previously developed. We first need to update the trial config in <code>cogment.yaml</code>: <code>player_1</code> will be our new actor implementation while <code>player_2</code> will be the heuristic implementation. Trials will be 20 games long to generate enough meaningful data between each training step.</p>
<div class="highlight"><pre><span></span><code><span class="nt">trial_params</span><span class="p">:</span>
    <span class="nt">environment</span><span class="p">:</span>
        <span class="nt">endpoint</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grpc://environment:9000</span>
        <span class="nt">config</span><span class="p">:</span>
            <span class="nt">target_game_score</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
            <span class="nt">target_games_count</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
    <span class="nt">actors</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">player_1</span>
          <span class="nt">actor_class</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">player</span>
          <span class="nt">implementation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dqn_agent</span>
          <span class="nt">endpoint</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grpc://dqn-agent:9000</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">player_2</span>
          <span class="nt">actor_class</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">player</span>
          <span class="nt">implementation</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">heuristic_agent</span>
          <span class="nt">endpoint</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">grpc://random-agent:9000</span>
</code></pre></div>

<p>We can also update <code>client/main.py</code> to run a bunch of trials sequentially.</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Client starting...&quot;</span><span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">cogment</span><span class="o">.</span><span class="n">Context</span><span class="p">(</span><span class="n">cog_settings</span><span class="o">=</span><span class="n">cog_settings</span><span class="p">,</span> <span class="n">user_id</span><span class="o">=</span><span class="s2">&quot;rps&quot;</span><span class="p">)</span>

    <span class="c1"># Create a controller</span>
    <span class="n">controller</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">get_controller</span><span class="p">(</span><span class="n">endpoint</span><span class="o">=</span><span class="n">cogment</span><span class="o">.</span><span class="n">Endpoint</span><span class="p">(</span><span class="s2">&quot;orchestrator:9000&quot;</span><span class="p">))</span>

    <span class="c1"># Start a trial campaign</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">trial_id</span> <span class="o">=</span> <span class="k">await</span> <span class="n">controller</span><span class="o">.</span><span class="n">start_trial</span><span class="p">(</span><span class="n">trial_config</span><span class="o">=</span><span class="n">TrialConfig</span><span class="p">())</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running trial #</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> with id &#39;</span><span class="si">{</span><span class="n">trial_id</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

        <span class="c1"># Wait for the trial to end by itself</span>
        <span class="k">async</span> <span class="k">for</span> <span class="n">trial_info</span> <span class="ow">in</span> <span class="n">controller</span><span class="o">.</span><span class="n">watch_trials</span><span class="p">(</span>
            <span class="n">trial_state_filters</span><span class="o">=</span><span class="p">[</span><span class="n">cogment</span><span class="o">.</span><span class="n">TrialState</span><span class="o">.</span><span class="n">ENDED</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">trial_info</span><span class="o">.</span><span class="n">trial_id</span> <span class="o">==</span> <span class="n">trial_id</span><span class="p">:</span>
                <span class="k">break</span>
</code></pre></div>

<p>You can now <a href="../1-bootstrap-and-data-structures/#building-and-running-the-app">build and run</a> the application. It should take a few minutes to run as it goes through the trial campaign.</p>
<h2 id="implementing-the-deep-q-network">Implementing the Deep Q Network<a class="headerlink" href="#implementing-the-deep-q-network" title="Permanent link">&para;</a></h2>
<p>We have set everything up, we can now focus on implementing our DQN agent.</p>
<p>A Deep Q Network is a neural network taking an observation as input, and outputing the Q value for each of the actions in the action space. The Q Value is an estimation of the expected value of all the rewards if a given action is taken. The DQN agent action policy is therefore to take the action having the largest predicted Q Value. Let's start by implementing this part and we will then deal with training this model.</p>
<p>In the rest of this tutorial we will use <a href="https://www.tensorflow.org" target="_blank">Tensorflow and its Keras API</a> for the model itself, as well as <a href="https://numpy.org" target="_blank">numpy</a> for datastructures. Let's add these to <code>dqn_agent/requirements.txt</code> and import them at the top of <code>dqn_agent/main.py</code>.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</code></pre></div>

<p>Let's get into the meat of the matter by implementing a function to create our model. We are using <a href="https://www.tensorflow.org/guide/keras/functional" target="_blank">Keras functional API</a> to create the following layers:</p>
<ol>
<li>Two scalar inputs, the last moves of the player and the opponent.</li>
<li>Each input is <a href="https://en.wikipedia.org/wiki/One-hot#Machine_learning_and_statistics" target="_blank">one-hot encoded</a> to avoid assuming an unwanted ordering and quantitative relationship between the moves.</li>
<li>The two encoded inputs are concatenated to a single vector.</li>
<li>A dense non-linear hidden layer is added.</li>
<li>The output layer estimates the Q value for each move.</li>
</ol>
<p>Everything then gets wrapped up and returned.</p>
<p>This function is then used to create a global <code>_model</code> that we will use in the actor implementation.</p>
<div class="highlight"><pre><span></span><code><span class="n">MOVES</span> <span class="o">=</span> <span class="p">[</span><span class="n">ROCK</span><span class="p">,</span> <span class="n">PAPER</span><span class="p">,</span> <span class="n">SCISSORS</span><span class="p">]</span>
<span class="n">actions_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">MOVES</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
    <span class="c1"># 1. Input layers</span>
    <span class="n">in_me_last_move</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">in_them_last_move</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="c1"># 2. One hot encoding of the layers</span>
    <span class="n">one_hot_move</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">CategoryEncoding</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;one_hot_move&quot;</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">MOVES</span><span class="p">),</span> <span class="n">output_mode</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span>
    <span class="p">)</span>
    <span class="n">one_hot_me_last_move</span> <span class="o">=</span> <span class="n">one_hot_move</span><span class="p">(</span><span class="n">in_me_last_move</span><span class="p">)</span>
    <span class="n">one_hot_them_last_move</span> <span class="o">=</span> <span class="n">one_hot_move</span><span class="p">(</span><span class="n">in_them_last_move</span><span class="p">)</span>
    <span class="c1"># 3. Concatenating the two inputs</span>
    <span class="n">concat_ins</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">[</span><span class="n">one_hot_me_last_move</span><span class="p">,</span> <span class="n">one_hot_them_last_move</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="c1"># 4. Dense hidden layer</span>
    <span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">concat_ins</span><span class="p">)</span>
    <span class="c1"># 5. Output</span>
    <span class="n">outs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">actions_count</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)(</span><span class="n">hidden_layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">in_me_last_move</span><span class="p">,</span> <span class="n">in_them_last_move</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rps_dqn_policy&quot;</span>
    <span class="p">)</span>

<span class="n">_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
</code></pre></div>

<p>The other piece of the puzzle is implementing a small function that will convert our observations into inputs for the model we just created. As most of the encoding is handled by the model itself it's fairly straightforward.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">model_ins_from_observations</span><span class="p">(</span><span class="n">observations</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">o</span><span class="o">.</span><span class="n">snapshot</span><span class="o">.</span><span class="n">me</span><span class="o">.</span><span class="n">last_move</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">observations</span><span class="p">]),</span>
        <span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="p">[[</span><span class="n">o</span><span class="o">.</span><span class="n">snapshot</span><span class="o">.</span><span class="n">them</span><span class="o">.</span><span class="n">last_move</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">observations</span><span class="p">]</span>
        <span class="p">),</span>
    <span class="p">}</span>
</code></pre></div>

<p>Finally we can make it work together by replacing the random choice of action by the use of the model. At the moment the model will just use the random initialization weights so don't expect much!</p>
<p>Here is how the event loop in the <code>dqn_agent</code> function will need to be updated:</p>
<ol>
<li>Use <code>model_ins_from_observations</code> to compute the model inputs,</li>
<li>Use the model in inference mode to compute the q value of each of the possible actions,</li>
<li>Finally, do the action having the largest q value.</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">observation</span><span class="p">:</span>
  <span class="n">model_ins</span> <span class="o">=</span> <span class="n">model_ins_from_observations</span><span class="p">([</span><span class="n">event</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span>
  <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">cogment</span><span class="o">.</span><span class="n">EventType</span><span class="o">.</span><span class="n">ACTIVE</span><span class="p">:</span>
    <span class="n">model_outs</span> <span class="o">=</span> <span class="n">_model</span><span class="p">(</span><span class="n">model_ins</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">actor_session</span><span class="o">.</span><span class="n">do_action</span><span class="p">(</span><span class="n">PlayerAction</span><span class="p">(</span><span class="n">move</span><span class="o">=</span><span class="n">action</span><span class="p">))</span>
</code></pre></div>

<p>You can now <a href="../1-bootstrap-and-data-structures/#building-and-running-the-app">build and run</a> the application. It should take a few minutes to run as it goes through the trial campaign.</p>
<blockquote>
<p>In this example we define <code>_model</code> (and other variables in the following sections) as global mutable variables. It works in our case because the dqn agents are neither distributed nor multithreaded.</p>
</blockquote>
<h2 id="random-exploration">Random exploration<a class="headerlink" href="#random-exploration" title="Permanent link">&para;</a></h2>
<p>With the previous code, you might have noticed that the agent will play exactly the same action given the same set of observations, this is because the weights of the model are fixed. However, especially at the beginning of the training process we want the agent to <em>experience</em> a variety of situations. We address this issue by introducing a decaying exploration rate <em>epsilon</em>.</p>
<p>First we will define the parameters for this epsilon value as global variables: its minimum value, its maximum and initial value and its decay per tick. We also define as a global variable the current value of epsilon. You can add the following after the imports in <code>dqn_agent/main.py</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">epsilon_min</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">epsilon_max</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">epsilon_decay_per_tick</span> <span class="o">=</span> <span class="p">(</span>
  <span class="n">epsilon_max</span> <span class="o">-</span> <span class="n">epsilon_min</span>
<span class="p">)</span> <span class="o">/</span> <span class="mf">1000.0</span>  <span class="c1"># Linearly reach the lowest exploration rate after 1000 ticks</span>

<span class="n">_epsilon</span> <span class="o">=</span> <span class="n">epsilon_max</span>
</code></pre></div>

<p>We then create a simple function we can use everytime an action needs to be taken to retrieve and update <code>_epsilon</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_and_update_epsilon</span><span class="p">():</span>
  <span class="k">global</span> <span class="n">_epsilon</span>
  <span class="n">current_epsilon</span> <span class="o">=</span> <span class="n">_epsilon</span>
  <span class="n">_epsilon</span> <span class="o">-=</span> <span class="n">epsilon_decay_per_tick</span>
  <span class="n">_epsilon</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">_epsilon</span><span class="p">,</span> <span class="n">epsilon_min</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">current_epsilon</span>
</code></pre></div>

<p>This function can then be used to occasionally do random actions, to facilitate the exploration. To do that, we need to slightly modify how the actions are computed and submitted.</p>
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">cogment</span><span class="o">.</span><span class="n">EventType</span><span class="o">.</span><span class="n">ACTIVE</span><span class="p">:</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">get_and_update_epsilon</span><span class="p">():</span>
    <span class="c1"># Take random action</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">actions_count</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">model_outs</span> <span class="o">=</span> <span class="n">_model</span><span class="p">(</span><span class="n">model_ins</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">actor_session</span><span class="o">.</span><span class="n">do_action</span><span class="p">(</span><span class="n">PlayerAction</span><span class="p">(</span><span class="n">move</span><span class="o">=</span><span class="n">action</span><span class="p">))</span>
</code></pre></div>

<p>You can now <a href="../1-bootstrap-and-data-structures/#building-and-running-the-app">build and run</a> the application. Nothing should appear different at this stage.</p>
<h2 id="replay-buffer">Replay buffer<a class="headerlink" href="#replay-buffer" title="Permanent link">&para;</a></h2>
<p>In our journey to train a model, the next stage is to build an experience replay buffer to collect actions/observations/rewards triples over the course of the trials. Once done, it'll be usable to train the model using this data.</p>
<p>We will start by creating the datastructure. We are using a column-oriented structure relying on <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html" target="_blank">numpy arrays</a> as they interoperate easily with tensorflow and support the needed manipulation primitives. Each row is a <strong>sample</strong> corresponding to one tick: the received observation and reward, the selected action as well as the next tick's received observation.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">create_replay_buffer</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">{</span>
    <span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
    <span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
    <span class="s2">&quot;action&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
    <span class="s2">&quot;reward&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
    <span class="s2">&quot;next_obs_me_last_move&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
    <span class="s2">&quot;next_obs_them_last_move&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
  <span class="p">}</span>

<span class="n">_rb</span> <span class="o">=</span> <span class="n">create_replay_buffer</span><span class="p">()</span>
</code></pre></div>

<p>During each trial the agent will collect its data points in a <em>trial</em> replay buffer then append it to the global one. To achieve that we will first create the function in charge of the appending then collect data during the trial and call the "append" function.</p>
<p>The following function will take a <em>trial</em> replay buffer and append it to the global <code>_rb</code>. To avoid memory overflow the replay buffer size is capped.</p>
<div class="highlight"><pre><span></span><code><span class="n">_collected_samples_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_replay_buffer_size</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="k">def</span> <span class="nf">append_trial_replay_buffer</span><span class="p">(</span><span class="n">trial_rb</span><span class="p">):</span>
  <span class="k">global</span> <span class="n">_rb</span>
  <span class="k">global</span> <span class="n">_collected_samples_count</span>

  <span class="n">trial_rb_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">])</span>

  <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_rb</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="c1"># Append the trial data to the current vector</span>
    <span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">trial_rb</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
    <span class="c1"># Enforce the size limit by discarding older data</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">max_replay_buffer_size</span><span class="p">:</span>
        <span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="o">-</span><span class="n">max_replay_buffer_size</span><span class="p">:]</span>

  <span class="n">_collected_samples_count</span> <span class="o">+=</span> <span class="n">trial_rb_size</span>
  <span class="n">rb_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">])</span>

  <span class="c1"># Sanity check, all vectors in the replay buffer should have the same size</span>
  <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_rb</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">rb_size</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>

  <span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">trial_rb_size</span><span class="si">}</span><span class="s2"> new samples stored after a trial, now having </span><span class="si">{</span><span class="n">rb_size</span><span class="si">}</span><span class="s2"> samples over a total of </span><span class="si">{</span><span class="n">_collected_samples_count</span><span class="si">}</span><span class="s2"> collected samples.&quot;</span>
  <span class="p">)</span>
</code></pre></div>

<p>The <code>dqn_agent</code> function can then be updated to collect received observations, rewards and sent actions. By default every action gets a <em>zero</em> reward. When a reward for a specific tick is received, its value gets updated.</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span> <span class="k">def</span> <span class="nf">dqn_agent</span><span class="p">(</span><span class="n">actor_session</span><span class="p">):</span>
  <span class="n">actor_session</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

  <span class="n">trial_rb</span> <span class="o">=</span> <span class="n">create_replay_buffer</span><span class="p">()</span>

  <span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">actor_session</span><span class="o">.</span><span class="n">event_loop</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">observation</span><span class="p">:</span>
      <span class="n">model_ins</span> <span class="o">=</span> <span class="n">model_ins_from_observations</span><span class="p">([</span><span class="n">event</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">cogment</span><span class="o">.</span><span class="n">EventType</span><span class="o">.</span><span class="n">ACTIVE</span><span class="p">:</span>
        <span class="c1"># [...]</span>
        <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">],</span> <span class="n">model_ins</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">],</span> <span class="n">model_ins</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span> <span class="p">[</span><span class="n">action</span><span class="p">])</span>
        <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">],</span> <span class="n">model_ins</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">],</span> <span class="n">model_ins</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">reward</span> <span class="ow">in</span> <span class="n">event</span><span class="o">.</span><span class="n">rewards</span><span class="p">:</span>
      <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">][</span><span class="n">reward</span><span class="o">.</span><span class="n">tick_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">value</span>

  <span class="c1"># Shifting the observations to get the next observations</span>
  <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;next_obs_me_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
  <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;next_obs_them_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
  <span class="c1"># Dropping the last row, as it only contains the last observations</span>
  <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">append_trial_replay_buffer</span><span class="p">(</span><span class="n">trial_rb</span><span class="p">)</span>
</code></pre></div>

<p>You can now <a href="../1-bootstrap-and-data-structures/#building-and-running-the-app">build and run</a> the application. The behavior should be the same but the log should confirm that data gets accumulated.</p>
<h2 id="training">Training!<a class="headerlink" href="#training" title="Permanent link">&para;</a></h2>
<p>Here we are, all the pieces are in place, we can implement the training proper. The function is a standard implementation of DQN and is decomposed in 4 steps:</p>
<ol>
<li>Select a random batch of samples from the replay buffer</li>
<li>Compute the target Q value for each sample from the received reward and the next observation using a previous version of the model.</li>
<li>(Re)compute the estimated Q value of each sample from the selected action and observation using the current version of the model.</li>
<li>Perform an optimization step of the model parameters trying to reduce the loss between the samples estimated and target q values.</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># Size of batch taken from replay buffer</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>  <span class="c1"># Discount factor for future rewards</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00025</span><span class="p">,</span> <span class="n">clipnorm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Huber</span><span class="p">()</span>
<span class="n">target_model_update_interval</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">_target_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
  <span class="k">global</span> <span class="n">_model</span>
  <span class="k">global</span> <span class="n">_target_model</span>

  <span class="n">rb_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">rb_size</span> <span class="o">&gt;=</span> <span class="n">batch_size</span><span class="p">:</span>
    <span class="c1"># Step 1 - Randomly select a batch</span>
    <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">rb_size</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_rb</span> <span class="o">=</span> <span class="n">create_replay_buffer</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch_rb</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">batch_rb</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">_rb</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">batch_indices</span><span class="p">)</span>

    <span class="c1"># Step 2 - Compute target q values</span>
    <span class="c1">## Predict the expected reward for the next observation of each sample</span>
    <span class="c1">## Use the target model for stability</span>
    <span class="n">target_actions_q_values</span> <span class="o">=</span> <span class="n">_target_model</span><span class="p">(</span>
      <span class="p">{</span>
        <span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">:</span> <span class="n">batch_rb</span><span class="p">[</span><span class="s2">&quot;next_obs_me_last_move&quot;</span><span class="p">],</span>
        <span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">:</span> <span class="n">batch_rb</span><span class="p">[</span><span class="s2">&quot;next_obs_them_last_move&quot;</span><span class="p">],</span>
      <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1">## target Q value = reward + discount factor * expected future reward</span>
    <span class="n">target_q_values</span> <span class="o">=</span> <span class="n">batch_rb</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span>
      <span class="n">target_actions_q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

    <span class="c1"># Step 3 - Compute estimated q values</span>
    <span class="c1">## Create masks of the taken actions to later select relevant q values</span>
    <span class="n">selected_actions_masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">batch_rb</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">],</span> <span class="n">actions_count</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
      <span class="c1">## Recompute q values for all the actions at each sample</span>
      <span class="n">estimated_actions_q_values</span> <span class="o">=</span> <span class="n">_model</span><span class="p">(</span>
        <span class="p">{</span>
          <span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">:</span> <span class="n">batch_rb</span><span class="p">[</span><span class="s2">&quot;obs_me_last_move&quot;</span><span class="p">],</span>
          <span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">:</span> <span class="n">batch_rb</span><span class="p">[</span><span class="s2">&quot;obs_them_last_move&quot;</span><span class="p">],</span>
        <span class="p">}</span>
      <span class="p">)</span>

      <span class="c1">## Apply the masks to get the Q value for taken actions</span>
      <span class="n">estimated_q_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">estimated_actions_q_values</span><span class="p">,</span> <span class="n">selected_actions_masks</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
      <span class="p">)</span>

      <span class="c1">## Compute loss between the target Q values and the estimated Q values</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">target_q_values</span><span class="p">,</span> <span class="n">estimated_q_values</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss=</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

      <span class="c1">## Backpropagation!</span>
      <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">_model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">_model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

    <span class="c1"># Update the target model</span>
    <span class="k">if</span> <span class="n">_collected_samples_count</span> <span class="o">%</span> <span class="n">target_model_update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">_target_model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">_model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
</code></pre></div>

<p>This function then needs to be called at the end of each trial after the call to <code>append_trial_replay_buffer</code>.</p>
<p>You can now <a href="../1-bootstrap-and-data-structures/#building-and-running-the-app">build and run</a> the application. The dqn agent will start to learn and quickly prevail against the heuristic implementation.</p>
<p>This can be observed by opening the dashboard at <a href="http://localhost:3003" target="_blank">http://localhost:3003</a> and opening the reward page. You should be able to track the progression of the dqn implementation.</p>
<p><img alt="Cumulative reward by agent type diagram showing the dqn implementation prevailing against the heuristic agent" src="../figures/dqn_agent_rewards.png" /></p>
<p>This concludes the step 7 of the tutorial: you implemented your first trained actor implementation!</p>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        <a href="../6-web-client/" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Step 6: Implement a web client for the human player
            </div>
          </div>
        </a>
      
      
        <a href="../../cogment-api-guide/" class="md-footer__link md-footer__link--next" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              API Guide
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright 2021 AI Redefined Inc. <dev+cogment@ai-r.com>
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://github.com/cogment" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://twitter.com/AI_Redefined" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://www.linkedin.com/company/ai-r" target="_blank" rel="noopener" title="www.linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.sections"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../../../assets/javascripts/workers/search.d351de03.min.js", "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.a1609d9a.min.js"></script>
      
    
  </body>
</html>