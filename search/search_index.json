{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cogment Framework Overview \u00b6 What is Cogment? \u00b6 Cogment is an innovative open source AI platform designed to leverage the advent of AI to benefit humankind through human-AI collaboration developed by AI Redefined . Cogment enables AI researchers and engineers to build, train and operate AI agents in simulated or real environments shared with humans. When to use Cogment? \u00b6 Cogment is designed to allow the training of complex agent architectures in complex environments, with human users in the loop. It is especially well suited to address multi-agent contexts, regardless of their learning mechanisms (or, for that matter, whether they are of the learning kind or not). Cogment also allows for the Actor's abstraction, meaning that human users and learning or non-learning agents alike are treated in the same way from a high level point of view, being interchangeable. As such, Cogment is suited for, among others, these contexts: Easily bootstrapping a given system by using human users, or heuristic agents, or both, then transitioning seamlessly to ML implementations Architecture multiple ML approaches to contribute to a single role, either by balancing them through specific rulesets, or specific performance metrics, or any other criteria Comparing different agent types/implementations without requiring any change in the implementation of the environment When not to use Cogment \u00b6 Cogment can be used in many other contexts it wasn't specifically designed for. However, for several types and scales of ML-powered projects, it may not be the most fitting approach: Simple projects focused around one learning agent Projects deployed only locally with no plans of larger scale distributed deployment Features \u00b6 Cogment main features are: Tech Stack Agnosticity. With the use of protobufs and gRPC, Cogment allows the development of tech-heterogeneous components working together regardless of the tech stacks used to develop them. It is fully compatible with current tools, langages and commonly used techniques. Multi-Method. Cogment doesn't enforce any particular approach to agents implementation. It doesn't favor learning over non-learning agents, nor does it learning techniques over others. Multi-Actor. Cogment was designed to allow multiple agents and multiple human users (all \"actors\") to exist, train, and work together within the same environment, interacting with one another and their environment. Multi-Reward Multiple Reinforcement Learning (RL) agents can use any number of reward sources in a Cogment project, whether they are from human users, an environment (real or simulated), or other agents. The same is true for the kind or mechanic of those rewards. Humans in the loop. Interaction with human users is a core feature of the Cogment framework, at any step of a project from the bootstrapping to the deployment and productionalization. There is no enforced limit to the complexity of said interaction. Multi-Experience learning. Several deployments (instances) of a Cogment project can contribute to the learning of their agents in a parallel way, i.e. each instance contributing to the learning of a single implementation of an agent. Actor hot-swap. Cogment allows for the swapping in and out of an actor from one implementation of an agent to another, or from a human user to another, or from a human user to a trained or untrained agent, and vice-versa. You can for example use simulated humans for a while before switching in real users, or switch from AI to human control. Custom agent architectures. Cogment allows the architecturing behind an agent's role to be as complex and specific as needed; hybridation between techniques, in particular, can be used to build individual capabilities and ultimately assemble them into one complex agent. Distributed computing & training. The physical location of any given component or part of a Cogment's project does not have to be the same, and neither do instances of a deployed Cogment project. Training and use can all happen in a distributed way, running one large algorithm or an array of decentralized agents. Live development. There is virtually no difference between dev and prod versions of a Cogment project; any Cogment project can be developed in an iterative way, with any part of it being live-developed so iteration cycles between simulated and real environment, for example, can happen as quickly as possible. Components \u00b6 The Cogment framework consists of multiple components: The Orchestrator , the heart of a Cogment app, is in charge of running the components. The SDKs are used to build your Cogment app services and clients. The SDKs are currently available in Python and Javascript only. A command like tool to facilitate the creation of Cogment apps. First steps \u00b6 The easiest way to get started is to use the cogment command line tool. Please see our installation instructions for details. Before diving right in, we recommend taking the time to read the Core concepts section, as well as our glossary , which details the terminology we use for several critical concepts of the Cogment Framework. You can then proceed to read on how to install the framework. Last but not least, a tutorial gives you a hands on introduction on using Cogment.","title":"Overview"},{"location":"#cogment-framework-overview","text":"","title":"Cogment Framework Overview"},{"location":"#what-is-cogment","text":"Cogment is an innovative open source AI platform designed to leverage the advent of AI to benefit humankind through human-AI collaboration developed by AI Redefined . Cogment enables AI researchers and engineers to build, train and operate AI agents in simulated or real environments shared with humans.","title":"What is Cogment?"},{"location":"#when-to-use-cogment","text":"Cogment is designed to allow the training of complex agent architectures in complex environments, with human users in the loop. It is especially well suited to address multi-agent contexts, regardless of their learning mechanisms (or, for that matter, whether they are of the learning kind or not). Cogment also allows for the Actor's abstraction, meaning that human users and learning or non-learning agents alike are treated in the same way from a high level point of view, being interchangeable. As such, Cogment is suited for, among others, these contexts: Easily bootstrapping a given system by using human users, or heuristic agents, or both, then transitioning seamlessly to ML implementations Architecture multiple ML approaches to contribute to a single role, either by balancing them through specific rulesets, or specific performance metrics, or any other criteria Comparing different agent types/implementations without requiring any change in the implementation of the environment","title":"When to use Cogment?"},{"location":"#when-not-to-use-cogment","text":"Cogment can be used in many other contexts it wasn't specifically designed for. However, for several types and scales of ML-powered projects, it may not be the most fitting approach: Simple projects focused around one learning agent Projects deployed only locally with no plans of larger scale distributed deployment","title":"When not to use Cogment"},{"location":"#features","text":"Cogment main features are: Tech Stack Agnosticity. With the use of protobufs and gRPC, Cogment allows the development of tech-heterogeneous components working together regardless of the tech stacks used to develop them. It is fully compatible with current tools, langages and commonly used techniques. Multi-Method. Cogment doesn't enforce any particular approach to agents implementation. It doesn't favor learning over non-learning agents, nor does it learning techniques over others. Multi-Actor. Cogment was designed to allow multiple agents and multiple human users (all \"actors\") to exist, train, and work together within the same environment, interacting with one another and their environment. Multi-Reward Multiple Reinforcement Learning (RL) agents can use any number of reward sources in a Cogment project, whether they are from human users, an environment (real or simulated), or other agents. The same is true for the kind or mechanic of those rewards. Humans in the loop. Interaction with human users is a core feature of the Cogment framework, at any step of a project from the bootstrapping to the deployment and productionalization. There is no enforced limit to the complexity of said interaction. Multi-Experience learning. Several deployments (instances) of a Cogment project can contribute to the learning of their agents in a parallel way, i.e. each instance contributing to the learning of a single implementation of an agent. Actor hot-swap. Cogment allows for the swapping in and out of an actor from one implementation of an agent to another, or from a human user to another, or from a human user to a trained or untrained agent, and vice-versa. You can for example use simulated humans for a while before switching in real users, or switch from AI to human control. Custom agent architectures. Cogment allows the architecturing behind an agent's role to be as complex and specific as needed; hybridation between techniques, in particular, can be used to build individual capabilities and ultimately assemble them into one complex agent. Distributed computing & training. The physical location of any given component or part of a Cogment's project does not have to be the same, and neither do instances of a deployed Cogment project. Training and use can all happen in a distributed way, running one large algorithm or an array of decentralized agents. Live development. There is virtually no difference between dev and prod versions of a Cogment project; any Cogment project can be developed in an iterative way, with any part of it being live-developed so iteration cycles between simulated and real environment, for example, can happen as quickly as possible.","title":"Features"},{"location":"#components","text":"The Cogment framework consists of multiple components: The Orchestrator , the heart of a Cogment app, is in charge of running the components. The SDKs are used to build your Cogment app services and clients. The SDKs are currently available in Python and Javascript only. A command like tool to facilitate the creation of Cogment apps.","title":"Components"},{"location":"#first-steps","text":"The easiest way to get started is to use the cogment command line tool. Please see our installation instructions for details. Before diving right in, we recommend taking the time to read the Core concepts section, as well as our glossary , which details the terminology we use for several critical concepts of the Cogment Framework. You can then proceed to read on how to install the framework. Last but not least, a tutorial gives you a hands on introduction on using Cogment.","title":"First steps"},{"location":"license/","text":"Apache License \u00b6 Version 2.0, January 2004 < http://www.apache.org/licenses/ > Terms and Conditions for use, reproduction, and distribution \u00b6 1. Definitions \u00b6 \u201cLicense\u201d shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \u201cLicensor\u201d shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \u201cLegal Entity\u201d shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u201ccontrol\u201d means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \u201cYou\u201d (or \u201cYour\u201d) shall mean an individual or Legal Entity exercising permissions granted by this License. \u201cSource\u201d form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \u201cObject\u201d form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \u201cWork\u201d shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \u201cDerivative Works\u201d shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \u201cContribution\u201d shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u201csubmitted\u201d means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u201cNot a Contribution.\u201d \u201cContributor\u201d shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License \u00b6 Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License \u00b6 Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution \u00b6 You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \u201cNOTICE\u201d text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions \u00b6 Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks \u00b6 This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty \u00b6 Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability \u00b6 In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability \u00b6 While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. Copyright 2019 Artificial Intelligence Redefined","title":"License"},{"location":"license/#apache-license","text":"Version 2.0, January 2004 < http://www.apache.org/licenses/ >","title":"Apache License"},{"location":"license/#terms-and-conditions-for-use-reproduction-and-distribution","text":"","title":"Terms and Conditions for use, reproduction, and distribution"},{"location":"license/#1-definitions","text":"\u201cLicense\u201d shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \u201cLicensor\u201d shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \u201cLegal Entity\u201d shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u201ccontrol\u201d means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \u201cYou\u201d (or \u201cYour\u201d) shall mean an individual or Legal Entity exercising permissions granted by this License. \u201cSource\u201d form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \u201cObject\u201d form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \u201cWork\u201d shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \u201cDerivative Works\u201d shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \u201cContribution\u201d shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u201csubmitted\u201d means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u201cNot a Contribution.\u201d \u201cContributor\u201d shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.","title":"1. Definitions"},{"location":"license/#2-grant-of-copyright-license","text":"Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.","title":"2. Grant of Copyright License"},{"location":"license/#3-grant-of-patent-license","text":"Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.","title":"3. Grant of Patent License"},{"location":"license/#4-redistribution","text":"You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \u201cNOTICE\u201d text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.","title":"4. Redistribution"},{"location":"license/#5-submission-of-contributions","text":"Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.","title":"5. Submission of Contributions"},{"location":"license/#6-trademarks","text":"This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.","title":"6. Trademarks"},{"location":"license/#7-disclaimer-of-warranty","text":"Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.","title":"7. Disclaimer of Warranty"},{"location":"license/#8-limitation-of-liability","text":"In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.","title":"8. Limitation of Liability"},{"location":"license/#9-accepting-warranty-or-additional-liability","text":"While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. Copyright 2019 Artificial Intelligence Redefined","title":"9. Accepting Warranty or Additional Liability"},{"location":"cogment/cogment-api-guide/","text":"Cogment High-Level API guide (Python) \u00b6 Prerequisites \u00b6 This document assumes the reader is familiar with the Cogment Fundamentals . The High-level Cogment API expects users to use protocol buffers to declare a project's data structures. The intricacies of protobufs are beyond the scope of this document. Basic knowledge of the technology and its usage is assumed. The cogment.yaml file \u00b6 An actor class is primarily defined by its observation space and action space . The data structures describing these spaces are declared by using a protocol buffer message type. Observations and actions will simply be instances of the matching type. For example, in the following, driver and pedestrian share a common view of the environment, hence use the same observation space, but have different actions available to them. import : proto : - city.proto actors : driver : observation : space : city.Observation action : space : city.DriverAction pedestrian : observation : space : city.Observation action : space : city.PedestrianAction \u26a0\ufe0f This shows only the relevant part of the full cogment.yaml , you can find the full list of configurable options in the reference page . Compiling the cogment.yaml \u00b6 In order to use the cogment.yaml file within python scripts, it needs to be interpreted into a python module. This is done by the cogment cli (Command Line Interface) that can be installed following those directions . $ cogment run --file /path/to/cogment.yaml --python_dir = ./ This will create a cog_settings.py module in the current directory. The cogment cli will also compile the imported .proto files in python modules living in the same location. Environment \u00b6 Environments are implemented by a Python function that uses a cogment.EnvironmentSession instance. This function will be called once for each [trial][../concepts/glossary.md#trial)]. This function usually consists of three sections. The environment's initialization , where its internal state can be initialized and processes started. It ends with the sending of the initial observations to the actors participating in the trial. Its event loop , where the environment iterates through the events occurring during the trial and produces observations as well as receives messages . In this loop the environment can end the trial on its own or the end can be requested by a controller . Its termination , where cleanup occurs. In the common case where all actors within a trial share the same observation, a bare-minimum environment service would look like this: async def environment ( environment_session ): # -- Initialization -- # Retrieve the actors participating in the trial actors = environment_session . get_active_actors () # Start the trial and send a default observation to all actors environment_session . start ([( \"*\" , Observation ())]) # -- Event loop -- async for event in environment_session . event_loop (): if event . actions : # `event.actions` is a list of the actions done by the actors (with a 1-1 matching) actions = event . actions if event . type == cogment . EventType . ACTIVE : # The trial is active, produce an observation in response to the actions environment_session . produce_observations ([( \"*\" , Observation ())]) # Alternatively the environment can decide to **end** the trial with the following # environment_session.end([(\"*\", Observation())]) else : # The trial termination has been requested by an external controller # Produce a final observation environment_session . end ([( \"*\" , Observation ())]) for message in event . messages : # `event.messages` is a list of all the messages received by the environment (it can be empty) # Handle each message here. # -- Termination -- This environment implementation needs to be registered and served so that the orchestrator can reach it. This can be done through a Context instance. context = cogment . Context ( cog_settings = cog_settings , user_id = \"my_user_id\" ) context . register_environment ( impl = environment ) await context . serve_all_registered ( port = 9000 ) Sending observations \u00b6 The environment session has 3 different methods able to send observations: start , produce_observations and end . Each of those methods takes a list of 2-tuples destination / observation. As demonstrated above, sending the same observation to all actors is done using \"*\" as the destination. environment_session . produce_observations ([( \"*\" , Observation ( ... ))]) It is also possible to send different observations to different actors. This can be useful to send observations of the world from the point of view of the actor or to send partial observations. environment_session . produce_observations ([ ( \"my_first_actor_name\" , Observation ( ... )), ( \"my_second_actor_name\" , Observation ( ... )) ]) Please note that the environment should always send observations such as each actor in the trial receives one. Actor \u00b6 Actors implementations look a lot like the environment's . They take a cogment.ActorSession instance and have the same three sections: initialization , event loop and termination . The event loops in Actors' implementations handle three basic types of events: observation produced by the environment and that should lead to an action being done. rewards sent by other actors or the environment, we'll talk about them in more details below . messages sent by other actors or the environment, we'll talk about them in more details below . A typical actor implementation would look like this: async def driver_actor ( actor_session ): # -- Initialization -- # Notify that the actor is ready for the trial to start. actor_session . start () async for event in actor_session . event_loop (): if event . observation : # `event.observation` is an instance of the Observation produced by the environment observation = event . observation if event . type == cogment . EventType . ACTIVE : # The trial is active, it is expecting the agent to do an action actor_session . do_action ( DriverAction ( ... )) for reward in event . rewards : # `event.rewards` is a list of all the rewards received by the actor (it can be empty) # Handle each reward here. for message in event . messages : # `event.messages` is a list of all the messages received by the actor (it can be empty) # Handle each message here. Service actor / Client actor \u00b6 A Cogment app can use two types of actors, they are identical in terms of implementation but differ in how they interact with the app's Orchestrator . Service actors are accessible in the same way the environment is, through a Context instance. context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = actor , impl_name = \"driver_actor\" , actor_classes = [ \"driver\" ]) await context . serve_all_registered ( port = 9000 ) Please note that this is also through this registrating that the implementation is associated with one or more actor classes it implements. Client actors , contrary to Service actors, are not served to the orchestrator . They connect as clients of the orchestrator and join a trial that has started. context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = actor , impl_name = \"driver_actor\" , actor_classes = [ \"driver\" ]) await context . join_trial ( trial_id = trial_id , endpoint = \"orchestrator:9000\" , impl_name = \"human\" ) Please note, that a trial including one or more client actors will wait for all of them to join before any actor can start processing events. Due to the different network requirements, client actors are a good fit when implementing a frontend for human actors. In addition to the python SDK demonstrated above, client actors can be implemented in javascript using the corresponding SDK. Controller \u00b6 Trials are started by clients of the Orchestrator using a Controller. Instances of a controller are built from the Context instance and connect to an Orchestrator endpoint. controller = context . get_controller ( endpoint = cogment . Endpoint ( \"orchestrator:9000\" ) ) The controller can then be used to create trials and request their termination. trial_id = await controller . start_trial ( trial_config = TrialConfig ()) # ... await controller . terminate_trial ( trial_id ) The controller can also be used to subscribe to events occuring in the trials run by the Orchestrator it connects to. For example, this can be used to wait for a trial's end: async for trial_info in controller . watch_trials ( trial_state_filters = [ cogment . TrialState . ENDED ]): # The trial having id {trial_info.trial_id} ended. The full documentation for the controller can be found here . Rewards \u00b6 Creating \u00b6 Rewards are sent to actors from another actor or the environment . The session instance passed to their implementation can be used for this purpose. session . add_reward ( value =- 1 , confidence = 1 , tick_id =- 1 , to = [ 'an_actor_name' ]) Rewards consist of an arbitrary numerical value describing how the reward \"sender\" believes the actor performed. It is weighted by a value between 0 and 1 qualifying the confidence of the \"sender\" in its reward, from a very low confidence just above 0 to a very high confidence approaching 1. The confidence value is used to collate all the rewards sent to an actor at the same time. Optionally, a reward can be provided with arbitrary user data. Each reward applies to a list of recipients (either all the actors, all the actors of a given class or a specific actor) at a specific point in time, during the trial, defined as a tick . The full documentation for session.add_reward can be found here . Consuming \u00b6 All the rewards that are sent and destined to each specific actor for a given point in time are collated together by the framework. The actor can take into account the reward directly as the trial is running by consuming the \"reward\" event in their event loop. async for event in actor_session . event_loop (): # [...] for reward in event . rewards : # `reward.tick_id` is the id of the tick this reward concerns. tick_id = reward . tick_id # `reward.value` is the aggregated value of the reward. value = reward . value for ( src_value , src_confidence , sender , user_data ) in reward . all_sources (): # Iterate over individual source rewards. Messages \u00b6 Creating \u00b6 Messages can be created and sent between actors or the environment within a trial using their session instance. session . send_message user_data = MyProtobufDataStructure ( ... ), # any protobuf data structure can be used here. to = [ 'pedestrian:*' ], # send the message to all the actors of the \"pedestrian\" class to_environment = False ) Messages consist of an arbitrary payload, their user_data , defined as an instance of any protobuf data structure. A message can be sent to one, many or all actors in a trial and / or to the environment. The full documentation for session.send_message can be found here . Consuming \u00b6 All the messages that are sent and intended for each specific actor or environment will be received by the target actor or environment. Actors or the environment can use the message directly, live, as the trial is running by consuming message event in their event loop. async for event in actor_session . event_loop (): # [...] for message in event . messages : # `message.sender_name` is the name of the actor who sent a message sender_name = message . sender_name # `message.payload` is the content of the message, it needs to be unpacked payload = message . payload Delta Encoding \u00b6 By default, observations are sent in their entirety from the environment to the actors . However, it's fairly common to only have a small portion of an observation to change from one update to the next. Cogment allows you to specify a separate data structure to encode partial observation updates. However, if you do so, you must provide a method that can apply the deltas to previous observations. # delta.py def apply_delta ( previous_observation , delta ): # Return the updated observation, more often # than not, this should be the previous # observation that was modified in-place. previous_observation . car_position = delta . new_car_pos return previous_observation # cogment.yaml import : proto : - city.proto python : - delta actors : my_class : observation : space : city.Observation delta : city.ObservationDelta delta_apply_fn : python : delta.apply_delta","title":"Cogment API Guide"},{"location":"cogment/cogment-api-guide/#cogment-high-level-api-guide-python","text":"","title":"Cogment High-Level API guide (Python)"},{"location":"cogment/cogment-api-guide/#prerequisites","text":"This document assumes the reader is familiar with the Cogment Fundamentals . The High-level Cogment API expects users to use protocol buffers to declare a project's data structures. The intricacies of protobufs are beyond the scope of this document. Basic knowledge of the technology and its usage is assumed.","title":"Prerequisites"},{"location":"cogment/cogment-api-guide/#the-cogmentyaml-file","text":"An actor class is primarily defined by its observation space and action space . The data structures describing these spaces are declared by using a protocol buffer message type. Observations and actions will simply be instances of the matching type. For example, in the following, driver and pedestrian share a common view of the environment, hence use the same observation space, but have different actions available to them. import : proto : - city.proto actors : driver : observation : space : city.Observation action : space : city.DriverAction pedestrian : observation : space : city.Observation action : space : city.PedestrianAction \u26a0\ufe0f This shows only the relevant part of the full cogment.yaml , you can find the full list of configurable options in the reference page .","title":"The cogment.yaml file"},{"location":"cogment/cogment-api-guide/#compiling-the-cogmentyaml","text":"In order to use the cogment.yaml file within python scripts, it needs to be interpreted into a python module. This is done by the cogment cli (Command Line Interface) that can be installed following those directions . $ cogment run --file /path/to/cogment.yaml --python_dir = ./ This will create a cog_settings.py module in the current directory. The cogment cli will also compile the imported .proto files in python modules living in the same location.","title":"Compiling the cogment.yaml"},{"location":"cogment/cogment-api-guide/#environment","text":"Environments are implemented by a Python function that uses a cogment.EnvironmentSession instance. This function will be called once for each [trial][../concepts/glossary.md#trial)]. This function usually consists of three sections. The environment's initialization , where its internal state can be initialized and processes started. It ends with the sending of the initial observations to the actors participating in the trial. Its event loop , where the environment iterates through the events occurring during the trial and produces observations as well as receives messages . In this loop the environment can end the trial on its own or the end can be requested by a controller . Its termination , where cleanup occurs. In the common case where all actors within a trial share the same observation, a bare-minimum environment service would look like this: async def environment ( environment_session ): # -- Initialization -- # Retrieve the actors participating in the trial actors = environment_session . get_active_actors () # Start the trial and send a default observation to all actors environment_session . start ([( \"*\" , Observation ())]) # -- Event loop -- async for event in environment_session . event_loop (): if event . actions : # `event.actions` is a list of the actions done by the actors (with a 1-1 matching) actions = event . actions if event . type == cogment . EventType . ACTIVE : # The trial is active, produce an observation in response to the actions environment_session . produce_observations ([( \"*\" , Observation ())]) # Alternatively the environment can decide to **end** the trial with the following # environment_session.end([(\"*\", Observation())]) else : # The trial termination has been requested by an external controller # Produce a final observation environment_session . end ([( \"*\" , Observation ())]) for message in event . messages : # `event.messages` is a list of all the messages received by the environment (it can be empty) # Handle each message here. # -- Termination -- This environment implementation needs to be registered and served so that the orchestrator can reach it. This can be done through a Context instance. context = cogment . Context ( cog_settings = cog_settings , user_id = \"my_user_id\" ) context . register_environment ( impl = environment ) await context . serve_all_registered ( port = 9000 )","title":"Environment"},{"location":"cogment/cogment-api-guide/#sending-observations","text":"The environment session has 3 different methods able to send observations: start , produce_observations and end . Each of those methods takes a list of 2-tuples destination / observation. As demonstrated above, sending the same observation to all actors is done using \"*\" as the destination. environment_session . produce_observations ([( \"*\" , Observation ( ... ))]) It is also possible to send different observations to different actors. This can be useful to send observations of the world from the point of view of the actor or to send partial observations. environment_session . produce_observations ([ ( \"my_first_actor_name\" , Observation ( ... )), ( \"my_second_actor_name\" , Observation ( ... )) ]) Please note that the environment should always send observations such as each actor in the trial receives one.","title":"Sending observations"},{"location":"cogment/cogment-api-guide/#actor","text":"Actors implementations look a lot like the environment's . They take a cogment.ActorSession instance and have the same three sections: initialization , event loop and termination . The event loops in Actors' implementations handle three basic types of events: observation produced by the environment and that should lead to an action being done. rewards sent by other actors or the environment, we'll talk about them in more details below . messages sent by other actors or the environment, we'll talk about them in more details below . A typical actor implementation would look like this: async def driver_actor ( actor_session ): # -- Initialization -- # Notify that the actor is ready for the trial to start. actor_session . start () async for event in actor_session . event_loop (): if event . observation : # `event.observation` is an instance of the Observation produced by the environment observation = event . observation if event . type == cogment . EventType . ACTIVE : # The trial is active, it is expecting the agent to do an action actor_session . do_action ( DriverAction ( ... )) for reward in event . rewards : # `event.rewards` is a list of all the rewards received by the actor (it can be empty) # Handle each reward here. for message in event . messages : # `event.messages` is a list of all the messages received by the actor (it can be empty) # Handle each message here.","title":"Actor"},{"location":"cogment/cogment-api-guide/#service-actor-client-actor","text":"A Cogment app can use two types of actors, they are identical in terms of implementation but differ in how they interact with the app's Orchestrator . Service actors are accessible in the same way the environment is, through a Context instance. context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = actor , impl_name = \"driver_actor\" , actor_classes = [ \"driver\" ]) await context . serve_all_registered ( port = 9000 ) Please note that this is also through this registrating that the implementation is associated with one or more actor classes it implements. Client actors , contrary to Service actors, are not served to the orchestrator . They connect as clients of the orchestrator and join a trial that has started. context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = actor , impl_name = \"driver_actor\" , actor_classes = [ \"driver\" ]) await context . join_trial ( trial_id = trial_id , endpoint = \"orchestrator:9000\" , impl_name = \"human\" ) Please note, that a trial including one or more client actors will wait for all of them to join before any actor can start processing events. Due to the different network requirements, client actors are a good fit when implementing a frontend for human actors. In addition to the python SDK demonstrated above, client actors can be implemented in javascript using the corresponding SDK.","title":"Service actor / Client actor"},{"location":"cogment/cogment-api-guide/#controller","text":"Trials are started by clients of the Orchestrator using a Controller. Instances of a controller are built from the Context instance and connect to an Orchestrator endpoint. controller = context . get_controller ( endpoint = cogment . Endpoint ( \"orchestrator:9000\" ) ) The controller can then be used to create trials and request their termination. trial_id = await controller . start_trial ( trial_config = TrialConfig ()) # ... await controller . terminate_trial ( trial_id ) The controller can also be used to subscribe to events occuring in the trials run by the Orchestrator it connects to. For example, this can be used to wait for a trial's end: async for trial_info in controller . watch_trials ( trial_state_filters = [ cogment . TrialState . ENDED ]): # The trial having id {trial_info.trial_id} ended. The full documentation for the controller can be found here .","title":"Controller"},{"location":"cogment/cogment-api-guide/#rewards","text":"","title":"Rewards"},{"location":"cogment/cogment-api-guide/#creating","text":"Rewards are sent to actors from another actor or the environment . The session instance passed to their implementation can be used for this purpose. session . add_reward ( value =- 1 , confidence = 1 , tick_id =- 1 , to = [ 'an_actor_name' ]) Rewards consist of an arbitrary numerical value describing how the reward \"sender\" believes the actor performed. It is weighted by a value between 0 and 1 qualifying the confidence of the \"sender\" in its reward, from a very low confidence just above 0 to a very high confidence approaching 1. The confidence value is used to collate all the rewards sent to an actor at the same time. Optionally, a reward can be provided with arbitrary user data. Each reward applies to a list of recipients (either all the actors, all the actors of a given class or a specific actor) at a specific point in time, during the trial, defined as a tick . The full documentation for session.add_reward can be found here .","title":"Creating"},{"location":"cogment/cogment-api-guide/#consuming","text":"All the rewards that are sent and destined to each specific actor for a given point in time are collated together by the framework. The actor can take into account the reward directly as the trial is running by consuming the \"reward\" event in their event loop. async for event in actor_session . event_loop (): # [...] for reward in event . rewards : # `reward.tick_id` is the id of the tick this reward concerns. tick_id = reward . tick_id # `reward.value` is the aggregated value of the reward. value = reward . value for ( src_value , src_confidence , sender , user_data ) in reward . all_sources (): # Iterate over individual source rewards.","title":"Consuming"},{"location":"cogment/cogment-api-guide/#messages","text":"","title":"Messages"},{"location":"cogment/cogment-api-guide/#creating_1","text":"Messages can be created and sent between actors or the environment within a trial using their session instance. session . send_message user_data = MyProtobufDataStructure ( ... ), # any protobuf data structure can be used here. to = [ 'pedestrian:*' ], # send the message to all the actors of the \"pedestrian\" class to_environment = False ) Messages consist of an arbitrary payload, their user_data , defined as an instance of any protobuf data structure. A message can be sent to one, many or all actors in a trial and / or to the environment. The full documentation for session.send_message can be found here .","title":"Creating"},{"location":"cogment/cogment-api-guide/#consuming_1","text":"All the messages that are sent and intended for each specific actor or environment will be received by the target actor or environment. Actors or the environment can use the message directly, live, as the trial is running by consuming message event in their event loop. async for event in actor_session . event_loop (): # [...] for message in event . messages : # `message.sender_name` is the name of the actor who sent a message sender_name = message . sender_name # `message.payload` is the content of the message, it needs to be unpacked payload = message . payload","title":"Consuming"},{"location":"cogment/cogment-api-guide/#delta-encoding","text":"By default, observations are sent in their entirety from the environment to the actors . However, it's fairly common to only have a small portion of an observation to change from one update to the next. Cogment allows you to specify a separate data structure to encode partial observation updates. However, if you do so, you must provide a method that can apply the deltas to previous observations. # delta.py def apply_delta ( previous_observation , delta ): # Return the updated observation, more often # than not, this should be the previous # observation that was modified in-place. previous_observation . car_position = delta . new_car_pos return previous_observation # cogment.yaml import : proto : - city.proto python : - delta actors : my_class : observation : space : city.Observation delta : city.ObservationDelta delta_apply_fn : python : delta.apply_delta","title":"Delta Encoding"},{"location":"cogment/cogment-api-reference/cogment-yaml/","text":"Cogment.yaml \u00b6 At the heart of every Cogment project is a cogment.yaml file (default name). This file is used by the Cogment CLI tool to configure the language specific SDK. It is also used by the orchestrator to initialize the runtime environment. The top level sections in the file are: import : Used to import other files into the defintion of the project commands : Defines commands that can be run by the Cogment CLI trial : Define trial speficic properties environment : Define environment specific properties actor_classes : Define actor specific properties (for each actor class) trial_params : Defines the default parameters to run a trial datalog : Defines the data logging specific properties In this document, \"section\" refers to YAML mappings. Import \u00b6 The import section is used to specify external data structures, and optionally code, that is referenced in other parts of the file. The referenced files must be in the same folder as the cogment.yaml file. The import sections are: proto : List of protobuf definition files. Message types defined in these files are used to communicate between the various components python : (optional) List of Python modules javascript : (optional) List of Javascript files All Cogment projects will need at least one proto import to define the data structures exchanged between the various components. Python and/or javascript imports will be needed if you make use of delta encodings. E.g.: import : proto : - filename1.proto - filename2.proto python : - module_name javascript : - filename.js N.B. When using message types imported from a .proto file, types need to be referred through their package namespace, not the filename containing them. Commands \u00b6 This section is optional and defines commands that can then be executed using the Cogment CLI run command. The commands will be executed by a sub-shell and thus can be any shell command. The commands can also recursively call Cogment, either builtin CLI or other commands defined here. But care should be taken not to create infinite recursive calls. E.g.: commands : generate : cogment generate --python_dir=. start : docker-compose up orchestrator agent env play : cogment run start && docker-compose run launcher To run one of these commands, the Cogment CLI command run must be used, e.g.: cogment run start . And as such there is no problem differentiating between cogment run generate and cogment generate (the latter is the builtin CLI command, and the former is the command defined in the cogment.yaml file). Trial \u00b6 This section defines properties related to the trial and trial management. It has the properties: config_type : (optional) The protobuf message type (data structure) that will be passed on to the pre-trial hooks. pre_hooks : (optional) List of endpoint for pre-trial hook processing services. The services will all be called, and their responses waited upon before the trial starts. The services are called in order of listing. The first service to be called will receive the default parameters (set in the trial_params section of cogment.yaml ) and can change them. Each subsequent service will receive the parameters updated by the previous service, and can change them further. If no service is defined, the default parameters are used directly. E.g.: trial : config_type : namespace.DataType pre_hooks : - grpc://actorconfigserver:9000 - grpc://envconfigserver:9000 - grpc://logconfigserver:9000 Environment \u00b6 This section defines properties related to the environment. It has the properties: config_type : (optional) The protobuf message type used to configure the environment environment : config_type : namespace.DataType Actor Classes \u00b6 Arguably the most important section of the cogment.yaml file, the actor classes section describes the actor types that can be present in the project's trials. The content of this section is a list of actor classes, each containing the necessary properties to define an actor class. These properties are: id : The name by which this actor class is known action : Mapping of properties space : The protobuf message type that represents all the possible actions that this actor class can perform (its action space) observation : Mapping of properties space : The protobuf message type that represents a snapshot of the data that this actor class has access to (its observation space) delta : (optional) The protobuf message type that represents the difference between two observation spaces (snapshots) delta_apply_fn : (optional) Mapping for a function to combine an observation space and a delta, into a new observation space: fn(observation, delta) -> observation . Only one of the following can be defined python : The function defined in python javascript : The function defined in Javascript config_type : (optional) Defines the protobuf message type used to configure this actor class Each actor class should define both an observation and action space as protobuf message types. actor_classes : - id : BigPlayer action : space : namespace.PlayerAction observation : space : namespace.PlayerObservation delta : namespace.PlayerDeltaObservation delta_apply_fn : python : module_name.PlayerDeltaProcessingFn config_type : namespace.PlayerConfig - id : SmallPlayer action : space : namespace.PlayerAction observation : space : namespace.PlayerObservation delta : namespace.PlayerDeltaObservation delta_apply_fn : python : module_name.PlayerDeltaProcessingFn config_type : namespace.PlayerConfig - id : Referee action : space : namespace.RefereeAction observation : space : namespace.RefereeObservation delta : namespace.RefereeDeltaObservation delta_apply_fn : python : module_name.RefereeDeltaProcessingFn config_type : namespace.RefereeConfig Trial Params \u00b6 This section defines the different parameters that can be adjusted by pre-trial hooks for each trial. It also defines the default values for these parameters. These parameters are: trial : Mapping of properties config : Definition of properties to match the definition of config_type for the trial. I.e. the yaml definition needs to match the definition of the protobuf class declared as config_type . environment : Mapping of properties endpoint : The URL where the environment gRPC server resides implementation : The name of the implementation to be used for this instance of the environment. This must match an implementation that is defined at the endpoint. If not defined, an arbitraary implementation will be chosen at runtime config : Definition of properties to match the definition of config_type for the environment. I.e. the yaml definition needs to match the definition of the protobuf class declared as config_type . actors : List of actor properties name : The name of this actor (i.e. name of the specific instance of the actor class) actor_class : The name of the actor class. The actor class must be defined in the actor_classes section above endpoint : The URL where the actor gRPC server resides. If this is client , the actor will connect as a client (the orchestrator being the server in this case). implementation : The name of the implementation to be used for this actor instance. This must match an implementation that is defined at the endpoint. If not defined, an arbitraary implementation will be chosen at runtime. config : Definition of properties to match the definition of config_type for this actor class. I.e. the yaml definition needs to match the definition of the protobuf class declared as config_type . E.g.: trial_params : environment : endpoint : grpc://env:9000 implementation : default config : actors : - name : Alice actor_class : BigPlayer endpoint : grpc://bp1:9000 implementation : config : - name : Bob actor_class : BigPlayer endpoint : grpc://bp2:9000 implementation : Test config : - name : Carol actor_class : SmallPlayer endpoint : grpc://sp:9000 implementation : DQN_Hotel3 config : - name : Dave actor_class : SmallPlayer endpoint : grpc://sp:9000 implementation : DNN_Karma3.1.17 config : - name : Olivia actor_class : Referee endpoint : client implementation : Standard config : Datalog \u00b6 This section defines the properties related to the logging of the data. It has the properties: fields : (optional) Mapping of properties exclude : List of fields to exclude from the data to send for logging type : The type of data to send for logging. Can be grpc or none . url : URL where to send the data to be logged datalog : fields : exclude : [ time , msg , status ] type : grpc url : logserver:9000","title":"cogment.yaml"},{"location":"cogment/cogment-api-reference/cogment-yaml/#cogmentyaml","text":"At the heart of every Cogment project is a cogment.yaml file (default name). This file is used by the Cogment CLI tool to configure the language specific SDK. It is also used by the orchestrator to initialize the runtime environment. The top level sections in the file are: import : Used to import other files into the defintion of the project commands : Defines commands that can be run by the Cogment CLI trial : Define trial speficic properties environment : Define environment specific properties actor_classes : Define actor specific properties (for each actor class) trial_params : Defines the default parameters to run a trial datalog : Defines the data logging specific properties In this document, \"section\" refers to YAML mappings.","title":"Cogment.yaml"},{"location":"cogment/cogment-api-reference/cogment-yaml/#import","text":"The import section is used to specify external data structures, and optionally code, that is referenced in other parts of the file. The referenced files must be in the same folder as the cogment.yaml file. The import sections are: proto : List of protobuf definition files. Message types defined in these files are used to communicate between the various components python : (optional) List of Python modules javascript : (optional) List of Javascript files All Cogment projects will need at least one proto import to define the data structures exchanged between the various components. Python and/or javascript imports will be needed if you make use of delta encodings. E.g.: import : proto : - filename1.proto - filename2.proto python : - module_name javascript : - filename.js N.B. When using message types imported from a .proto file, types need to be referred through their package namespace, not the filename containing them.","title":"Import"},{"location":"cogment/cogment-api-reference/cogment-yaml/#commands","text":"This section is optional and defines commands that can then be executed using the Cogment CLI run command. The commands will be executed by a sub-shell and thus can be any shell command. The commands can also recursively call Cogment, either builtin CLI or other commands defined here. But care should be taken not to create infinite recursive calls. E.g.: commands : generate : cogment generate --python_dir=. start : docker-compose up orchestrator agent env play : cogment run start && docker-compose run launcher To run one of these commands, the Cogment CLI command run must be used, e.g.: cogment run start . And as such there is no problem differentiating between cogment run generate and cogment generate (the latter is the builtin CLI command, and the former is the command defined in the cogment.yaml file).","title":"Commands"},{"location":"cogment/cogment-api-reference/cogment-yaml/#trial","text":"This section defines properties related to the trial and trial management. It has the properties: config_type : (optional) The protobuf message type (data structure) that will be passed on to the pre-trial hooks. pre_hooks : (optional) List of endpoint for pre-trial hook processing services. The services will all be called, and their responses waited upon before the trial starts. The services are called in order of listing. The first service to be called will receive the default parameters (set in the trial_params section of cogment.yaml ) and can change them. Each subsequent service will receive the parameters updated by the previous service, and can change them further. If no service is defined, the default parameters are used directly. E.g.: trial : config_type : namespace.DataType pre_hooks : - grpc://actorconfigserver:9000 - grpc://envconfigserver:9000 - grpc://logconfigserver:9000","title":"Trial"},{"location":"cogment/cogment-api-reference/cogment-yaml/#environment","text":"This section defines properties related to the environment. It has the properties: config_type : (optional) The protobuf message type used to configure the environment environment : config_type : namespace.DataType","title":"Environment"},{"location":"cogment/cogment-api-reference/cogment-yaml/#actor-classes","text":"Arguably the most important section of the cogment.yaml file, the actor classes section describes the actor types that can be present in the project's trials. The content of this section is a list of actor classes, each containing the necessary properties to define an actor class. These properties are: id : The name by which this actor class is known action : Mapping of properties space : The protobuf message type that represents all the possible actions that this actor class can perform (its action space) observation : Mapping of properties space : The protobuf message type that represents a snapshot of the data that this actor class has access to (its observation space) delta : (optional) The protobuf message type that represents the difference between two observation spaces (snapshots) delta_apply_fn : (optional) Mapping for a function to combine an observation space and a delta, into a new observation space: fn(observation, delta) -> observation . Only one of the following can be defined python : The function defined in python javascript : The function defined in Javascript config_type : (optional) Defines the protobuf message type used to configure this actor class Each actor class should define both an observation and action space as protobuf message types. actor_classes : - id : BigPlayer action : space : namespace.PlayerAction observation : space : namespace.PlayerObservation delta : namespace.PlayerDeltaObservation delta_apply_fn : python : module_name.PlayerDeltaProcessingFn config_type : namespace.PlayerConfig - id : SmallPlayer action : space : namespace.PlayerAction observation : space : namespace.PlayerObservation delta : namespace.PlayerDeltaObservation delta_apply_fn : python : module_name.PlayerDeltaProcessingFn config_type : namespace.PlayerConfig - id : Referee action : space : namespace.RefereeAction observation : space : namespace.RefereeObservation delta : namespace.RefereeDeltaObservation delta_apply_fn : python : module_name.RefereeDeltaProcessingFn config_type : namespace.RefereeConfig","title":"Actor Classes"},{"location":"cogment/cogment-api-reference/cogment-yaml/#trial-params","text":"This section defines the different parameters that can be adjusted by pre-trial hooks for each trial. It also defines the default values for these parameters. These parameters are: trial : Mapping of properties config : Definition of properties to match the definition of config_type for the trial. I.e. the yaml definition needs to match the definition of the protobuf class declared as config_type . environment : Mapping of properties endpoint : The URL where the environment gRPC server resides implementation : The name of the implementation to be used for this instance of the environment. This must match an implementation that is defined at the endpoint. If not defined, an arbitraary implementation will be chosen at runtime config : Definition of properties to match the definition of config_type for the environment. I.e. the yaml definition needs to match the definition of the protobuf class declared as config_type . actors : List of actor properties name : The name of this actor (i.e. name of the specific instance of the actor class) actor_class : The name of the actor class. The actor class must be defined in the actor_classes section above endpoint : The URL where the actor gRPC server resides. If this is client , the actor will connect as a client (the orchestrator being the server in this case). implementation : The name of the implementation to be used for this actor instance. This must match an implementation that is defined at the endpoint. If not defined, an arbitraary implementation will be chosen at runtime. config : Definition of properties to match the definition of config_type for this actor class. I.e. the yaml definition needs to match the definition of the protobuf class declared as config_type . E.g.: trial_params : environment : endpoint : grpc://env:9000 implementation : default config : actors : - name : Alice actor_class : BigPlayer endpoint : grpc://bp1:9000 implementation : config : - name : Bob actor_class : BigPlayer endpoint : grpc://bp2:9000 implementation : Test config : - name : Carol actor_class : SmallPlayer endpoint : grpc://sp:9000 implementation : DQN_Hotel3 config : - name : Dave actor_class : SmallPlayer endpoint : grpc://sp:9000 implementation : DNN_Karma3.1.17 config : - name : Olivia actor_class : Referee endpoint : client implementation : Standard config :","title":"Trial Params"},{"location":"cogment/cogment-api-reference/cogment-yaml/#datalog","text":"This section defines the properties related to the logging of the data. It has the properties: fields : (optional) Mapping of properties exclude : List of fields to exclude from the data to send for logging type : The type of data to send for logging. Can be grpc or none . url : URL where to send the data to be logged datalog : fields : exclude : [ time , msg , status ] type : grpc url : logserver:9000","title":"Datalog"},{"location":"cogment/cogment-api-reference/python/","text":"Python SDK \u00b6 The Python SDK is designed to run concurently and asynchronously using the Python asyncio library. As such, it should be run in an asyncio.Task . Installation \u00b6 The simplest way to install the python SDK is to just install it using pip: pip install cogment The basic requiremetns is Python 3.7. General usage \u00b6 cogment.yaml \u00b6 The cogment.yaml file (including imported files) defines the high level API. For example, an actor class is defined by its required observation space and action space . These \"spaces\" are defined by using protobuf message types (from the imported files). Observations and actions will simply be instances of the appropriate type. Messages and feedback user data don't have a set type, they can be any type as long as the receiver can manage that type (i.e. the object received is an instance of google.protobuf.Any and the contained type should be checked against known types before handling). The type is determined by the provided message from the originator. The trial_params section represents default values that can be dynamically changed for each trial with pre-trial hooks. Therefore, below, when this section of the cogment.yaml file is refered, we mean the final parameters after any pre-trial hooks. Compiling the cogment.yaml \u00b6 In order to use the configuration found in the cogment.yaml file within python scripts, it needs to be compiled into python modules. This is done by a tool called the \u201ccogment cli\u201d (Command Line Interface). The cogment cli requires protoc (the Protobuf compiler). As a convenience, the cogment/cli docker image can be used to run it, as it has all the required dependencies correctly setup already: $ docker run -v $(pwd):/data --rm cogment/cli --file /data/cogment.yaml --python_dir=/data This will create a cog_settings.py module in the --python-dir directory. The cogment cli will also compile the imported *.proto files in python modules living in the same location (e.g. data_pb2.py in this case). There is no need to invoke protoc yourself for the imported files. cog_settings.py \u00b6 All API entrypoints require a cogment configuration object. This configuration object can be determined from the content of a project's cogment.yaml . As such, it should be generated using the cogment tool. # From the directory containing cogment.yaml $ cogment generate --python_dir = path/to/project This will generate both a cog_settings.py file, as well as any required compiled protocol buffer files. Top-level import \u00b6 Whether a script implements an actor or environment, it should import both the cogment module (generic python SDK for Cogment) and the cog_settings module (project specific definitions created from cogment.yaml ). import cog_settings import cogment class cogment.Context \u00b6 Class to setup and run all the different aspects of trials. __init__(self, user_id, cog_settings) \u00b6 Parameters: user_id : str - Identifier for the user of this context. cog_settings : module - Settings module associated with trials that will be run ( cog_settings namespace). async serve_all_registered(self, served_endpoint, prometheus_port = 8000) \u00b6 Method to start and run the communication server for the registered components (environment, actor, prehook, datalog). This coroutine will end when all activity has stopped. Parameters: served_endpoint : ServedEndpoint instance - Details of the connection for the served components. prometheus_port : int - TCP/IP port number for Prometheus Return: None get_controller(self, endpoint) \u00b6 Method to get a controller instance to manage trials (start, stop, inquire, etc). Parameters: endpoint : Endpoint instance - Details of the connection to the Orchestrator. Return: Controller instance - An instance of the Controller class used to manage trials. async join_trial(self, trial_id, endpoint, impl_name, actor_name=None) \u00b6 Method for an actor to asynchronously join an existing trial. This task will normally end after the user implementation has exited. Parameters: trial_id : str - The UUID of the trial to join. endpoint : Endpoint instance - Details of the connection to the Orchestrator. impl_name : str - The implementation name of the actor to join the trial. The implementation must have previously been registered with the register_actor method. actor_name : str - Name of the actor joining the trial. If None , the actor will join as any of the configured (free) actors of the actor class registered for impl_name . Otherwise, the name must match an actor with an actor_class compatible with impl_name as defined in cogment.yaml in the sections trial_params:actors:actor_class and trial_params:actors:name . Return: None register_environment(self, impl, impl_name = \"default\") \u00b6 Method to register the asynchronous callback function that will run an environment for a trial. Parameters: impl : async function(EnvironmentSession instance) - Callback function to be registered. impl_name : str - Name for the environment being run by the given callback function. Return: None register_actor(self, impl, impl_name, actor_classes=[]) \u00b6 Method to register the asynchronous callback function that will run an actor for a trial. Parameters: impl : async func(ActorSession instance) - Callback function to be registered. impl_name : str - Name for the actor implementation being run by the given callback function. actor_classes : list[str] - The actor class name(s) that can be run by the given callback function. The possible names are specified in file cogment.yaml under section actor_classes:name . If the list is empty, this implementation can run any actor class. Return: None register_pre_trial_hook(self, impl) \u00b6 Method to register an asynchronous callback function that will be called before a trial is started. Parameters: impl : async func(PrehookSession instance) - Callback function to be registered. The PrehookSession instance member data should be changed as needed for the new trial before returning from this function. Return: None register_datalog(self, impl) \u00b6 Method to register an asynchronous callback function that will be called for each log request (for any trial). Only one such function can be registered. Parameters: impl : async func(DatalogSession instance) - Callback function to be registered Return: None class Controller \u00b6 Class containing data and methods to control and manage trials. async start_trial(self, trial_config=None) \u00b6 Method to start a new trial. The parameters of the trial will be set by the pre-trial hooks (registered in cogment.Context ), and the hooks will receive the provided trial config. Parameters: trial_config : protobuf class instance - Configuration for the trial. The type is specified in file cogment.yaml under the section trial:config_type . Can be None if no configuration is provided. Return: str - The newly started trial ID. terminate_trial(self, trial_id) \u00b6 Method to request the end of a trial. Parameters: trial_id : str - The trial ID to request to terminate. Return: None async get_trial_info(self, trial_id) \u00b6 Method to get information about a trial. Parameters: trial_id : str - The trial ID from which to request information. If None returns information about all trials. Note that ended trials may only appear for a short time in this list after they have ended. Return: list[TrialInfo instance] - List of trial information, one per trial. Can be empty if no trial matches. async watch_trials(self, trial_state_filters=[]) \u00b6 Generator method to iterate, in real-time, through all trial states matching the filters. When called, it will first iterate over the current states matching the filters, for all trials. Afterward, it will iterate in real-time over the matching states as they change. Parameters: trial_state_filters : list[cogment.TrialState] - List of enum values from cogment.TrialState . for which we are intersted to receive state change. Return: generator(TrialInfo instance) - A generator for the state changes that arrive. The TrialInfo received here only contain the trial ID and the state. async get_actors(self, trial_id) \u00b6 Method to get the list of configured actors in a trial. Parameters: trial_id : str - The trial ID from which to request the list of actors. Return: list[ActorInfo instance] - List of actors configured in this trial. class Session \u00b6 Abstract class containing data and methods common to all sessions that manage aspects of a trial. get_trial_id(self) \u00b6 Method to get the UUID of the trial managed by this session. Parameters: None Return: str - UUID of the trial. get_tick_id(self) \u00b6 Method to get the current tick id of the trial (i.e. time step). Parameters: None Return: int - The current tick id. is_trial_over(self) \u00b6 Method to inquire if the current trial has ended. Parameters: None Return: bool - True if the trial has ended, false otherwise. get_active_actors(self) \u00b6 Method to get the list of active actors in the trial. This may be expensive to retrieve and thus should be stored if the list is not expected to change throughout the trial. Parameters: None Return: list[ActorInfo instance] - List of active actors and classes involved in this trial. add_reward(self, value, confidence, to, tick_id=-1, user_data=None) \u00b6 Method to send a reward to one or more actors. Parameters: value : float - Value of the reward. This will be aggregated with other rewards for the same target actor. confidence : float - Weight of this reward value in determining the final aggregated reward. to : list[str] - Target(s) of reward. A list value could be the name of an actor in the trial. Or it could represent a set of actors; A set of actors can be represented with the wildcard character \" * \" for all actors (of all classes), or \" actor_class.* \" for all actors of a specific class (the actor_class is the name of the class as specified in cogment.yaml ). tick_id : int - The tick id (time step) for which the reward should be applied. If \"-1\", then the reward applies to the current time step. user_data : protobuf class instance - Extra user data to be sent with the reward. The class can be any protobuf class. It is the responsibility of the receiving actor to manage the class received (packed in a google.protobuf.Any ). Return: None send_message(self, payload, to, to_environment=False) \u00b6 Method to send a message related to current time step (tick id). Parameters: payload : protobuf class instance - The message data to be sent. The class can be any protobuf class. It is the responsibility of the receiving actor or environment to manage the class received (packed in a google.protobuf.Any ). to : list[str] - Targets of feedback. A list value could be the name of an actor in the trial. Or it could represent a set of actors; A set of actors can be represented with the wildcard character \" * \" for all actors (of all classes), or \" actor_class.* \" for all actors of a specific class (the actor_class is the name of the class as specified in cogment.yaml ). to_environment : bool - If True, the message is also sent to the environment, otherwise the message is only sent to the actors specified. Return: None class EnvironmentSession(Session) \u00b6 Abstract class based on Session , containing session data and methods necessary to run an environment for a trial. An instance of this class is passed as argument to the environment callback function registered with cogment.Context.register_environment . impl_name : str - Name of the implementation running this environment. config : protobuf class instance - User configuration received for this environment instance. Can be None if no configuration was provided. The type of the protobuf class is specified in cogment.yaml in section environment:config_type . start(self, observations) \u00b6 Method to report that the environment is starting to run the trial. The method should be called before any other method in the session. Parameters: observations : list[tuple(str, protobuf class instance)] - The initial observations from which the environment is starting the trial. This is the same as the parameter for self.produce_observations . Return: None async event_loop(self) \u00b6 Generator method to iterate over all events (actions, messages) as they are received. This will block and wait for an event. When this generator exits, the callback function (registered with register_environment ) should return to end the trial cleanly. The generator will exit for various reasons indicating the termination of the trial, a loss of communication with the orchestrator, or if the generator is sent \"False\" (in which case the callback function does not necessarily need to exit). Parameters: None Return: generator(RecvEvent instance) - A generator for the events that arrive. The RecvEvent instances received from this generator will only contain actions or messages; no observations nor rewards. When receiving actions in the event, the self.produce_observation method is normally used to \"reply\" (or self.end to end the trial). produce_observations(self, observations) \u00b6 Method to send observations to actors. If called after receiving an event of type EventType.ENDING , the observation will be consired the final observation (equivalent to calling end() ). Parameters: observations : list[tuple(str, protobuf class instance)] - The observations to send to actors. The string in the tuple is the name of the destination actor (or \"*\" for all actors). The name of the actors can be found in cogment.yaml under trial_params:actors:name . The protobuf class is Observation Space for that actor, found in cogment.yaml in the corresponding section actor_classes:observation:space . Return: None end(self, final_observations) \u00b6 Method to report the end of the environment. This will effectively end the trial. Parameters: final_observations : list[tuple(str, protobuf class instance)] - The final observations to send to the actors. This is the same as the parameter for self.produce_observations . Return: None class ActorSession(Session) \u00b6 Abstract class based on Session , containing session/trial data and methods necessary to run an actor for a trial. An instance of this class is passed as argument to the actor callback function registered with cogment.Context.register_actor . class_name : str - Name of the class of actor this instance represents. Specified in cogment.yaml as actor_classes:name . impl_name : str - Name of the implementation of the actor represented by this instance. config : protobuf class instance - User configuration received for this actor instance. Can be None is no configuration was provided. The type of the protobuf class is specified in cogment.yaml in section actor_classes:config_type . name : str - Name of the actor this instance represents. start(self) \u00b6 Method to start the actor. This method should be called before any other method in the session. Parameters: None Return: None async event_loop(self) \u00b6 Generator method to iterate over all events (observations, rewards, messages) as they are received. This will block and wait for an event. When this generator exits, the callback function (registered with register_actor ) should return to end the trial cleanly. The generator will exit for various reasons indicating the end of the trial, a loss of communication with the orchestrator, or if the generator is sent \"False\". Parameters: None Return: generator(RecvEvent instance) - A generator for the events that arrive. The RecvEvent instances received from this generator will not contain actions. When receiving an observation in the event, the self.do_action method is normally used to \"reply\" (if the event type is EventType.ACTIVE ). do_action(self, action) \u00b6 Method to send actions to the environment. Parameters: action : protobuf class instance - An instance of the action space class specified in the corresponding section actor_classes:action:space of the cogment.yaml file. If None , then no action space is sent (empty content) and the environment will receive a default initialized action space of the appropriate type. Return: None class PrehookSession \u00b6 Abstract class containing trial configuration data to define the specifics of a trial. An instance of this class is passed as argument to the prehook callback function registered with cogment.Context.register_pre_trial_hook , and is part of the DatalogSession . trial_config : protobuf class instance - Configuration for the new trial. The type is specified in file cogment.yaml under the section trial:config_type . trial_max_steps : int - The maximum number of time steps (ticks) that the trial will run before terminating. trial_max_inactivity : int - The number of seconds of inactivity after which a trial will be terminated. If 0, the trial will not be terminated because of inactivity. environment_config : protobuf class instance - Configuration for the environment in the new trial. This configuration will be sent to the environment on start. The type is specified in file cogment.yaml under the section environment:config_type . environment_endpoint : str - The URL to connect to the environment. The protocol must be \"grpc\". E.g. \"grpc://myenv:9000\" actors : list[dict] - Each item (dictionary) of the list represents an actor. Each actor dictionary contains these key-value pairs: \"name\": str - Name of the actor \"actor_class\": str - The actor class for the actor \"endpoint\": str - The URL to connect to the actor. If, instead of a URL, the value is \"client\", then this actor will connect in (as opposed to be to connected to), and the actor will need to provide the URL to connect to the orchestrator. \"implementation: str - The name of the implementation to run this actor \"config\": protobuf class instance - The configuration data for the actor. get_trial_id(self) \u00b6 Method to retrieve the UUID of the trial. Parameters: None Return: str - UUID of the trial. validate(self) \u00b6 Method to validate that the data is valid. This is a superficial check; even if the data validates successfully, there can still be problems with the data. This method should be called if changes have been made to the data members of the class. Exceptions are raised on error. Parameters: None Return: None cogment.api.common_pb2.TrialParams \u00b6 TrialParams is defined in the low level grpc api. cogment.api.datalog.DatalogSample \u00b6 DatalogSample is defined in the low level grpc api. class DatalogSession \u00b6 Abstract class containing session data and methods necessary to manage logging of trial run data. An instance of this class is passed as argument to the datalog callback function registered with cogment.Context.register_datalog . trial_id : str - UUID of the trial managed by this instance. trial_params : dictionary - Parameters of the trial. This parameter has been deprecated . raw_trial_params : cogment.api.common_pb2.TrialParams - Parameters of the trial. start(self) \u00b6 Method to start receiving samples. Parameters: None Return: None get_all_samples(self) \u00b6 Generator method to iterate over all samples as they are received (waiting for each in turn). Parameters: None Return: generator(cogment.api.datalog.DatalogSample) - A generator for the samples received. class cogment.Endpoint \u00b6 Class enclosing the details for connecting to an Orchestrator. url : str - The URL where to connect to the Orchestrator. private_key : str - To use TLS for the connection, this must be set to the PEM-encoded private key. root_certificates : str - If using TLS for the connection (i.e. the private_key is not None ), this can be set to the PEM-encoded root certificates. If not set and using TLS for the connection, the root certificates will be fetched from the system default location. certificate_chain : str - If using TLS for the connection, this can be set to the PEM-encoded certificate chain. __init__(self, url) \u00b6 Parameters: url : str - The URL where to connect to the Orchestrator. class cogment.ServedEndpoint \u00b6 Class enclosing the details for connection from an Orchestrator. port : str - The TCP/IP port where the service will be awaiting the Orchestrator connection. private_key_certificate_chain_pairs : list[tupple(str, str)] - To use TLS for incoming connections, this must be se to a list of tuples of the form (PEM-encoded private key, PEM-encoded certificate chain). root_certificates : str - If using TLS for the connection (i.e. private_key_certificate_chain_pairs is not None ), this should be set to PEM-encoded Orchestrator root certificates that the server will use to verify Orchestrator authentication. __init__(self, port) \u00b6 Parameters: port : int - The TCP/IP port where the service will be awaiting the Orchestrator connection. class cogment.TrialState(enum.Enum) \u00b6 Enum representing the various states of trials. UNKNOWN: Should not be used. INITIALIZING: The trial is in the process of starting. PENDING: The trial is waiting for its final parameters, before running. RUNNING: The trial is running. TERMINATING: The trial is in the process of terminating (either a request to terminate has been received or the last observation has been received). ENDED: The trial has ended. Only a set number of ended trials will be kept (configured in the Orchestrator). class TrialInfo \u00b6 Class enclosing the details of a trial. trial_id : str - The trial ID for which the details pertain. state : cogment.TrialState - The current state of the trial. tick_id : int - The time step that the information relates to. Only provided from a call to get_trial_info . duration : int - The time (in nanoseconds) that the trial has run. Only provided from a call to get_trial_info . class ActorInfo \u00b6 Class enclosing the details of an actor. actor_name : str - The name of the actor. actor_class_name : str - The name of the actor's class (as defined in cogment.yaml ). class RecvEvent \u00b6 Class representing a received event (for environments and actors). It can contain any combination of data according to the receiver needs, or even be empty, but it will always have a type. type : Enum EventType - Type of event the enclosed data represents. observation : RecvObservation instance - Observation data. This can only be received by actors. None if not present. actions : list[RecvAction instance] - Action data from actors. This can only be received by the environment. The list is empty if not present. rewards : list[RecvReward instance] - Reward values and data. This can only be received by actors. The list is empty if not present. messages : *list[RecvMessage instance] - Message data. The list is empty if not present. class cogment.EventType(enum.Enum) \u00b6 Enum representing the type of an event. EventType.NONE : Empty event. This kind of event should never be received. EventType.ACTIVE : Normal event from an active trial. Most events will be of this type. EventType.ENDING : Events from a trial in the process of ending. For the environment, this means that these events contain the last actions from the actors, and the trial is awaiting a final observation. For the actors, this means that the trial is ending and no action can/need to be sent in response. Note that because of network timing, there may be ACTIVE events (e.g. rewards or messages) arriving after some ENDING events, but the trial is ending regardless. EventType.FINAL : Final event for the trial. This does not contain data. The event loop will exit after this event is delivered. This event can be ignored if nothing needs to be done before exiting the loop. class RecvObservation \u00b6 Class containing the details of an observation for an actor. tick_id : int - The time step that the observation relates to. timestamp : int - Unix style Epoch timestamp in nanoseconds (time since 00:00:00 UTC Jan 1, 1970). snapshot : protobuf class instance - Snaphot Observation (as opposed to a delta observation) received from the environment. The class of the snapshot observation is defined as observation space for the actor class. This is specified in section actor_classes:observation:space in cogment.yaml for the appropriate/receiving actor class. class RecvAction \u00b6 Class containing the details of an action from an actor. actor_index : int - Index of actor in the list of all trial actors (returned by Session.get_active_actors ). action : protobuf class instance - Action from the actor wich has index actor_index in the trial. The class of the action is defined as action space for the specific actor in section actor_classes:action:space in cogment.yaml . class RecvMessage \u00b6 Class containing a message. tick_id : int - The time step that the message relates to. sender_name : str - Name of the sender of the message (the name of an actor, or \"env\" if the environment sent the message). payload : google.protobuf.Any instance - Data for a received message. The class enclosed in google.protobuf.Any is of the type set by the sender; It is the responsibility of the receiver to manage the data received (i.e. determine the type and unpack the data). class RecvReward \u00b6 Class containing the details of a received reward. tick_id : int - The tick id (time step) for which the reward should be applied. value : float - Value of the reward (aggregated from the sources) ``get_nb_sources(self) \u00b6 Return the number of source rewards this reward is based upon. Parameters: None Return: int - Number of sources. all_sources(self) \u00b6 Generator method to iterate over all sources making up this reward. Parameters: None Return: generator(RecvRewardSource instance) - A generator for the sources in the reward (simple rewards that make up this final/aggregate reward). class RecvRewardSource \u00b6 Class containing the details of a received single source reward. value : float - Value of the reward from the sender confidence : float - Confidence level of this reward value. sender_name : str - Name of the sender of this reward (the name of an actor, or \"env\" if the environment sent the reward). user_data : google.protobuf.Any instance - Data for a user-specific reward format. Can be None if no specific data was provided. The class enclosed in google.protobuf.Any is of the type set by the sender; It is the responsibility of the receiver to manage the data received (i.e. determine the type and unpack the data).","title":"python"},{"location":"cogment/cogment-api-reference/python/#python-sdk","text":"The Python SDK is designed to run concurently and asynchronously using the Python asyncio library. As such, it should be run in an asyncio.Task .","title":"Python SDK"},{"location":"cogment/cogment-api-reference/python/#installation","text":"The simplest way to install the python SDK is to just install it using pip: pip install cogment The basic requiremetns is Python 3.7.","title":"Installation"},{"location":"cogment/cogment-api-reference/python/#general-usage","text":"","title":"General usage"},{"location":"cogment/cogment-api-reference/python/#cogmentyaml","text":"The cogment.yaml file (including imported files) defines the high level API. For example, an actor class is defined by its required observation space and action space . These \"spaces\" are defined by using protobuf message types (from the imported files). Observations and actions will simply be instances of the appropriate type. Messages and feedback user data don't have a set type, they can be any type as long as the receiver can manage that type (i.e. the object received is an instance of google.protobuf.Any and the contained type should be checked against known types before handling). The type is determined by the provided message from the originator. The trial_params section represents default values that can be dynamically changed for each trial with pre-trial hooks. Therefore, below, when this section of the cogment.yaml file is refered, we mean the final parameters after any pre-trial hooks.","title":"cogment.yaml"},{"location":"cogment/cogment-api-reference/python/#compiling-the-cogmentyaml","text":"In order to use the configuration found in the cogment.yaml file within python scripts, it needs to be compiled into python modules. This is done by a tool called the \u201ccogment cli\u201d (Command Line Interface). The cogment cli requires protoc (the Protobuf compiler). As a convenience, the cogment/cli docker image can be used to run it, as it has all the required dependencies correctly setup already: $ docker run -v $(pwd):/data --rm cogment/cli --file /data/cogment.yaml --python_dir=/data This will create a cog_settings.py module in the --python-dir directory. The cogment cli will also compile the imported *.proto files in python modules living in the same location (e.g. data_pb2.py in this case). There is no need to invoke protoc yourself for the imported files.","title":"Compiling the cogment.yaml"},{"location":"cogment/cogment-api-reference/python/#cog_settingspy","text":"All API entrypoints require a cogment configuration object. This configuration object can be determined from the content of a project's cogment.yaml . As such, it should be generated using the cogment tool. # From the directory containing cogment.yaml $ cogment generate --python_dir = path/to/project This will generate both a cog_settings.py file, as well as any required compiled protocol buffer files.","title":"cog_settings.py"},{"location":"cogment/cogment-api-reference/python/#top-level-import","text":"Whether a script implements an actor or environment, it should import both the cogment module (generic python SDK for Cogment) and the cog_settings module (project specific definitions created from cogment.yaml ). import cog_settings import cogment","title":"Top-level import"},{"location":"cogment/cogment-api-reference/python/#class-cogmentcontext","text":"Class to setup and run all the different aspects of trials.","title":"class cogment.Context"},{"location":"cogment/cogment-api-reference/python/#__init__self-user_id-cog_settings","text":"Parameters: user_id : str - Identifier for the user of this context. cog_settings : module - Settings module associated with trials that will be run ( cog_settings namespace).","title":"__init__(self, user_id, cog_settings)"},{"location":"cogment/cogment-api-reference/python/#async-serve_all_registeredself-served_endpoint-prometheus_port-8000","text":"Method to start and run the communication server for the registered components (environment, actor, prehook, datalog). This coroutine will end when all activity has stopped. Parameters: served_endpoint : ServedEndpoint instance - Details of the connection for the served components. prometheus_port : int - TCP/IP port number for Prometheus Return: None","title":"async serve_all_registered(self, served_endpoint, prometheus_port = 8000)"},{"location":"cogment/cogment-api-reference/python/#get_controllerself-endpoint","text":"Method to get a controller instance to manage trials (start, stop, inquire, etc). Parameters: endpoint : Endpoint instance - Details of the connection to the Orchestrator. Return: Controller instance - An instance of the Controller class used to manage trials.","title":"get_controller(self, endpoint)"},{"location":"cogment/cogment-api-reference/python/#async-join_trialself-trial_id-endpoint-impl_name-actor_namenone","text":"Method for an actor to asynchronously join an existing trial. This task will normally end after the user implementation has exited. Parameters: trial_id : str - The UUID of the trial to join. endpoint : Endpoint instance - Details of the connection to the Orchestrator. impl_name : str - The implementation name of the actor to join the trial. The implementation must have previously been registered with the register_actor method. actor_name : str - Name of the actor joining the trial. If None , the actor will join as any of the configured (free) actors of the actor class registered for impl_name . Otherwise, the name must match an actor with an actor_class compatible with impl_name as defined in cogment.yaml in the sections trial_params:actors:actor_class and trial_params:actors:name . Return: None","title":"async join_trial(self, trial_id, endpoint, impl_name, actor_name=None)"},{"location":"cogment/cogment-api-reference/python/#register_environmentself-impl-impl_name-default","text":"Method to register the asynchronous callback function that will run an environment for a trial. Parameters: impl : async function(EnvironmentSession instance) - Callback function to be registered. impl_name : str - Name for the environment being run by the given callback function. Return: None","title":"register_environment(self, impl, impl_name = \"default\")"},{"location":"cogment/cogment-api-reference/python/#register_actorself-impl-impl_name-actor_classes","text":"Method to register the asynchronous callback function that will run an actor for a trial. Parameters: impl : async func(ActorSession instance) - Callback function to be registered. impl_name : str - Name for the actor implementation being run by the given callback function. actor_classes : list[str] - The actor class name(s) that can be run by the given callback function. The possible names are specified in file cogment.yaml under section actor_classes:name . If the list is empty, this implementation can run any actor class. Return: None","title":"register_actor(self, impl, impl_name, actor_classes=[])"},{"location":"cogment/cogment-api-reference/python/#register_pre_trial_hookself-impl","text":"Method to register an asynchronous callback function that will be called before a trial is started. Parameters: impl : async func(PrehookSession instance) - Callback function to be registered. The PrehookSession instance member data should be changed as needed for the new trial before returning from this function. Return: None","title":"register_pre_trial_hook(self, impl)"},{"location":"cogment/cogment-api-reference/python/#register_datalogself-impl","text":"Method to register an asynchronous callback function that will be called for each log request (for any trial). Only one such function can be registered. Parameters: impl : async func(DatalogSession instance) - Callback function to be registered Return: None","title":"register_datalog(self, impl)"},{"location":"cogment/cogment-api-reference/python/#class-controller","text":"Class containing data and methods to control and manage trials.","title":"class Controller"},{"location":"cogment/cogment-api-reference/python/#async-start_trialself-trial_confignone","text":"Method to start a new trial. The parameters of the trial will be set by the pre-trial hooks (registered in cogment.Context ), and the hooks will receive the provided trial config. Parameters: trial_config : protobuf class instance - Configuration for the trial. The type is specified in file cogment.yaml under the section trial:config_type . Can be None if no configuration is provided. Return: str - The newly started trial ID.","title":"async start_trial(self, trial_config=None)"},{"location":"cogment/cogment-api-reference/python/#terminate_trialself-trial_id","text":"Method to request the end of a trial. Parameters: trial_id : str - The trial ID to request to terminate. Return: None","title":"terminate_trial(self, trial_id)"},{"location":"cogment/cogment-api-reference/python/#async-get_trial_infoself-trial_id","text":"Method to get information about a trial. Parameters: trial_id : str - The trial ID from which to request information. If None returns information about all trials. Note that ended trials may only appear for a short time in this list after they have ended. Return: list[TrialInfo instance] - List of trial information, one per trial. Can be empty if no trial matches.","title":"async get_trial_info(self, trial_id)"},{"location":"cogment/cogment-api-reference/python/#async-watch_trialsself-trial_state_filters","text":"Generator method to iterate, in real-time, through all trial states matching the filters. When called, it will first iterate over the current states matching the filters, for all trials. Afterward, it will iterate in real-time over the matching states as they change. Parameters: trial_state_filters : list[cogment.TrialState] - List of enum values from cogment.TrialState . for which we are intersted to receive state change. Return: generator(TrialInfo instance) - A generator for the state changes that arrive. The TrialInfo received here only contain the trial ID and the state.","title":"async watch_trials(self, trial_state_filters=[])"},{"location":"cogment/cogment-api-reference/python/#async-get_actorsself-trial_id","text":"Method to get the list of configured actors in a trial. Parameters: trial_id : str - The trial ID from which to request the list of actors. Return: list[ActorInfo instance] - List of actors configured in this trial.","title":"async get_actors(self, trial_id)"},{"location":"cogment/cogment-api-reference/python/#class-session","text":"Abstract class containing data and methods common to all sessions that manage aspects of a trial.","title":"class Session"},{"location":"cogment/cogment-api-reference/python/#get_trial_idself","text":"Method to get the UUID of the trial managed by this session. Parameters: None Return: str - UUID of the trial.","title":"get_trial_id(self)"},{"location":"cogment/cogment-api-reference/python/#get_tick_idself","text":"Method to get the current tick id of the trial (i.e. time step). Parameters: None Return: int - The current tick id.","title":"get_tick_id(self)"},{"location":"cogment/cogment-api-reference/python/#is_trial_overself","text":"Method to inquire if the current trial has ended. Parameters: None Return: bool - True if the trial has ended, false otherwise.","title":"is_trial_over(self)"},{"location":"cogment/cogment-api-reference/python/#get_active_actorsself","text":"Method to get the list of active actors in the trial. This may be expensive to retrieve and thus should be stored if the list is not expected to change throughout the trial. Parameters: None Return: list[ActorInfo instance] - List of active actors and classes involved in this trial.","title":"get_active_actors(self)"},{"location":"cogment/cogment-api-reference/python/#add_rewardself-value-confidence-to-tick_id-1-user_datanone","text":"Method to send a reward to one or more actors. Parameters: value : float - Value of the reward. This will be aggregated with other rewards for the same target actor. confidence : float - Weight of this reward value in determining the final aggregated reward. to : list[str] - Target(s) of reward. A list value could be the name of an actor in the trial. Or it could represent a set of actors; A set of actors can be represented with the wildcard character \" * \" for all actors (of all classes), or \" actor_class.* \" for all actors of a specific class (the actor_class is the name of the class as specified in cogment.yaml ). tick_id : int - The tick id (time step) for which the reward should be applied. If \"-1\", then the reward applies to the current time step. user_data : protobuf class instance - Extra user data to be sent with the reward. The class can be any protobuf class. It is the responsibility of the receiving actor to manage the class received (packed in a google.protobuf.Any ). Return: None","title":"add_reward(self, value, confidence, to, tick_id=-1, user_data=None)"},{"location":"cogment/cogment-api-reference/python/#send_messageself-payload-to-to_environmentfalse","text":"Method to send a message related to current time step (tick id). Parameters: payload : protobuf class instance - The message data to be sent. The class can be any protobuf class. It is the responsibility of the receiving actor or environment to manage the class received (packed in a google.protobuf.Any ). to : list[str] - Targets of feedback. A list value could be the name of an actor in the trial. Or it could represent a set of actors; A set of actors can be represented with the wildcard character \" * \" for all actors (of all classes), or \" actor_class.* \" for all actors of a specific class (the actor_class is the name of the class as specified in cogment.yaml ). to_environment : bool - If True, the message is also sent to the environment, otherwise the message is only sent to the actors specified. Return: None","title":"send_message(self, payload, to, to_environment=False)"},{"location":"cogment/cogment-api-reference/python/#class-environmentsessionsession","text":"Abstract class based on Session , containing session data and methods necessary to run an environment for a trial. An instance of this class is passed as argument to the environment callback function registered with cogment.Context.register_environment . impl_name : str - Name of the implementation running this environment. config : protobuf class instance - User configuration received for this environment instance. Can be None if no configuration was provided. The type of the protobuf class is specified in cogment.yaml in section environment:config_type .","title":"class EnvironmentSession(Session)"},{"location":"cogment/cogment-api-reference/python/#startself-observations","text":"Method to report that the environment is starting to run the trial. The method should be called before any other method in the session. Parameters: observations : list[tuple(str, protobuf class instance)] - The initial observations from which the environment is starting the trial. This is the same as the parameter for self.produce_observations . Return: None","title":"start(self, observations)"},{"location":"cogment/cogment-api-reference/python/#async-event_loopself","text":"Generator method to iterate over all events (actions, messages) as they are received. This will block and wait for an event. When this generator exits, the callback function (registered with register_environment ) should return to end the trial cleanly. The generator will exit for various reasons indicating the termination of the trial, a loss of communication with the orchestrator, or if the generator is sent \"False\" (in which case the callback function does not necessarily need to exit). Parameters: None Return: generator(RecvEvent instance) - A generator for the events that arrive. The RecvEvent instances received from this generator will only contain actions or messages; no observations nor rewards. When receiving actions in the event, the self.produce_observation method is normally used to \"reply\" (or self.end to end the trial).","title":"async event_loop(self)"},{"location":"cogment/cogment-api-reference/python/#produce_observationsself-observations","text":"Method to send observations to actors. If called after receiving an event of type EventType.ENDING , the observation will be consired the final observation (equivalent to calling end() ). Parameters: observations : list[tuple(str, protobuf class instance)] - The observations to send to actors. The string in the tuple is the name of the destination actor (or \"*\" for all actors). The name of the actors can be found in cogment.yaml under trial_params:actors:name . The protobuf class is Observation Space for that actor, found in cogment.yaml in the corresponding section actor_classes:observation:space . Return: None","title":"produce_observations(self, observations)"},{"location":"cogment/cogment-api-reference/python/#endself-final_observations","text":"Method to report the end of the environment. This will effectively end the trial. Parameters: final_observations : list[tuple(str, protobuf class instance)] - The final observations to send to the actors. This is the same as the parameter for self.produce_observations . Return: None","title":"end(self, final_observations)"},{"location":"cogment/cogment-api-reference/python/#class-actorsessionsession","text":"Abstract class based on Session , containing session/trial data and methods necessary to run an actor for a trial. An instance of this class is passed as argument to the actor callback function registered with cogment.Context.register_actor . class_name : str - Name of the class of actor this instance represents. Specified in cogment.yaml as actor_classes:name . impl_name : str - Name of the implementation of the actor represented by this instance. config : protobuf class instance - User configuration received for this actor instance. Can be None is no configuration was provided. The type of the protobuf class is specified in cogment.yaml in section actor_classes:config_type . name : str - Name of the actor this instance represents.","title":"class ActorSession(Session)"},{"location":"cogment/cogment-api-reference/python/#startself","text":"Method to start the actor. This method should be called before any other method in the session. Parameters: None Return: None","title":"start(self)"},{"location":"cogment/cogment-api-reference/python/#async-event_loopself_1","text":"Generator method to iterate over all events (observations, rewards, messages) as they are received. This will block and wait for an event. When this generator exits, the callback function (registered with register_actor ) should return to end the trial cleanly. The generator will exit for various reasons indicating the end of the trial, a loss of communication with the orchestrator, or if the generator is sent \"False\". Parameters: None Return: generator(RecvEvent instance) - A generator for the events that arrive. The RecvEvent instances received from this generator will not contain actions. When receiving an observation in the event, the self.do_action method is normally used to \"reply\" (if the event type is EventType.ACTIVE ).","title":"async event_loop(self)"},{"location":"cogment/cogment-api-reference/python/#do_actionself-action","text":"Method to send actions to the environment. Parameters: action : protobuf class instance - An instance of the action space class specified in the corresponding section actor_classes:action:space of the cogment.yaml file. If None , then no action space is sent (empty content) and the environment will receive a default initialized action space of the appropriate type. Return: None","title":"do_action(self, action)"},{"location":"cogment/cogment-api-reference/python/#class-prehooksession","text":"Abstract class containing trial configuration data to define the specifics of a trial. An instance of this class is passed as argument to the prehook callback function registered with cogment.Context.register_pre_trial_hook , and is part of the DatalogSession . trial_config : protobuf class instance - Configuration for the new trial. The type is specified in file cogment.yaml under the section trial:config_type . trial_max_steps : int - The maximum number of time steps (ticks) that the trial will run before terminating. trial_max_inactivity : int - The number of seconds of inactivity after which a trial will be terminated. If 0, the trial will not be terminated because of inactivity. environment_config : protobuf class instance - Configuration for the environment in the new trial. This configuration will be sent to the environment on start. The type is specified in file cogment.yaml under the section environment:config_type . environment_endpoint : str - The URL to connect to the environment. The protocol must be \"grpc\". E.g. \"grpc://myenv:9000\" actors : list[dict] - Each item (dictionary) of the list represents an actor. Each actor dictionary contains these key-value pairs: \"name\": str - Name of the actor \"actor_class\": str - The actor class for the actor \"endpoint\": str - The URL to connect to the actor. If, instead of a URL, the value is \"client\", then this actor will connect in (as opposed to be to connected to), and the actor will need to provide the URL to connect to the orchestrator. \"implementation: str - The name of the implementation to run this actor \"config\": protobuf class instance - The configuration data for the actor.","title":"class PrehookSession"},{"location":"cogment/cogment-api-reference/python/#get_trial_idself_1","text":"Method to retrieve the UUID of the trial. Parameters: None Return: str - UUID of the trial.","title":"get_trial_id(self)"},{"location":"cogment/cogment-api-reference/python/#validateself","text":"Method to validate that the data is valid. This is a superficial check; even if the data validates successfully, there can still be problems with the data. This method should be called if changes have been made to the data members of the class. Exceptions are raised on error. Parameters: None Return: None","title":"validate(self)"},{"location":"cogment/cogment-api-reference/python/#cogmentapicommon_pb2trialparams","text":"TrialParams is defined in the low level grpc api.","title":"cogment.api.common_pb2.TrialParams"},{"location":"cogment/cogment-api-reference/python/#cogmentapidatalogdatalogsample","text":"DatalogSample is defined in the low level grpc api.","title":"cogment.api.datalog.DatalogSample"},{"location":"cogment/cogment-api-reference/python/#class-datalogsession","text":"Abstract class containing session data and methods necessary to manage logging of trial run data. An instance of this class is passed as argument to the datalog callback function registered with cogment.Context.register_datalog . trial_id : str - UUID of the trial managed by this instance. trial_params : dictionary - Parameters of the trial. This parameter has been deprecated . raw_trial_params : cogment.api.common_pb2.TrialParams - Parameters of the trial.","title":"class DatalogSession"},{"location":"cogment/cogment-api-reference/python/#startself_1","text":"Method to start receiving samples. Parameters: None Return: None","title":"start(self)"},{"location":"cogment/cogment-api-reference/python/#get_all_samplesself","text":"Generator method to iterate over all samples as they are received (waiting for each in turn). Parameters: None Return: generator(cogment.api.datalog.DatalogSample) - A generator for the samples received.","title":"get_all_samples(self)"},{"location":"cogment/cogment-api-reference/python/#class-cogmentendpoint","text":"Class enclosing the details for connecting to an Orchestrator. url : str - The URL where to connect to the Orchestrator. private_key : str - To use TLS for the connection, this must be set to the PEM-encoded private key. root_certificates : str - If using TLS for the connection (i.e. the private_key is not None ), this can be set to the PEM-encoded root certificates. If not set and using TLS for the connection, the root certificates will be fetched from the system default location. certificate_chain : str - If using TLS for the connection, this can be set to the PEM-encoded certificate chain.","title":"class cogment.Endpoint"},{"location":"cogment/cogment-api-reference/python/#__init__self-url","text":"Parameters: url : str - The URL where to connect to the Orchestrator.","title":"__init__(self, url)"},{"location":"cogment/cogment-api-reference/python/#class-cogmentservedendpoint","text":"Class enclosing the details for connection from an Orchestrator. port : str - The TCP/IP port where the service will be awaiting the Orchestrator connection. private_key_certificate_chain_pairs : list[tupple(str, str)] - To use TLS for incoming connections, this must be se to a list of tuples of the form (PEM-encoded private key, PEM-encoded certificate chain). root_certificates : str - If using TLS for the connection (i.e. private_key_certificate_chain_pairs is not None ), this should be set to PEM-encoded Orchestrator root certificates that the server will use to verify Orchestrator authentication.","title":"class cogment.ServedEndpoint"},{"location":"cogment/cogment-api-reference/python/#__init__self-port","text":"Parameters: port : int - The TCP/IP port where the service will be awaiting the Orchestrator connection.","title":"__init__(self, port)"},{"location":"cogment/cogment-api-reference/python/#class-cogmenttrialstateenumenum","text":"Enum representing the various states of trials. UNKNOWN: Should not be used. INITIALIZING: The trial is in the process of starting. PENDING: The trial is waiting for its final parameters, before running. RUNNING: The trial is running. TERMINATING: The trial is in the process of terminating (either a request to terminate has been received or the last observation has been received). ENDED: The trial has ended. Only a set number of ended trials will be kept (configured in the Orchestrator).","title":"class cogment.TrialState(enum.Enum)"},{"location":"cogment/cogment-api-reference/python/#class-trialinfo","text":"Class enclosing the details of a trial. trial_id : str - The trial ID for which the details pertain. state : cogment.TrialState - The current state of the trial. tick_id : int - The time step that the information relates to. Only provided from a call to get_trial_info . duration : int - The time (in nanoseconds) that the trial has run. Only provided from a call to get_trial_info .","title":"class TrialInfo"},{"location":"cogment/cogment-api-reference/python/#class-actorinfo","text":"Class enclosing the details of an actor. actor_name : str - The name of the actor. actor_class_name : str - The name of the actor's class (as defined in cogment.yaml ).","title":"class ActorInfo"},{"location":"cogment/cogment-api-reference/python/#class-recvevent","text":"Class representing a received event (for environments and actors). It can contain any combination of data according to the receiver needs, or even be empty, but it will always have a type. type : Enum EventType - Type of event the enclosed data represents. observation : RecvObservation instance - Observation data. This can only be received by actors. None if not present. actions : list[RecvAction instance] - Action data from actors. This can only be received by the environment. The list is empty if not present. rewards : list[RecvReward instance] - Reward values and data. This can only be received by actors. The list is empty if not present. messages : *list[RecvMessage instance] - Message data. The list is empty if not present.","title":"class RecvEvent"},{"location":"cogment/cogment-api-reference/python/#class-cogmenteventtypeenumenum","text":"Enum representing the type of an event. EventType.NONE : Empty event. This kind of event should never be received. EventType.ACTIVE : Normal event from an active trial. Most events will be of this type. EventType.ENDING : Events from a trial in the process of ending. For the environment, this means that these events contain the last actions from the actors, and the trial is awaiting a final observation. For the actors, this means that the trial is ending and no action can/need to be sent in response. Note that because of network timing, there may be ACTIVE events (e.g. rewards or messages) arriving after some ENDING events, but the trial is ending regardless. EventType.FINAL : Final event for the trial. This does not contain data. The event loop will exit after this event is delivered. This event can be ignored if nothing needs to be done before exiting the loop.","title":"class cogment.EventType(enum.Enum)"},{"location":"cogment/cogment-api-reference/python/#class-recvobservation","text":"Class containing the details of an observation for an actor. tick_id : int - The time step that the observation relates to. timestamp : int - Unix style Epoch timestamp in nanoseconds (time since 00:00:00 UTC Jan 1, 1970). snapshot : protobuf class instance - Snaphot Observation (as opposed to a delta observation) received from the environment. The class of the snapshot observation is defined as observation space for the actor class. This is specified in section actor_classes:observation:space in cogment.yaml for the appropriate/receiving actor class.","title":"class RecvObservation"},{"location":"cogment/cogment-api-reference/python/#class-recvaction","text":"Class containing the details of an action from an actor. actor_index : int - Index of actor in the list of all trial actors (returned by Session.get_active_actors ). action : protobuf class instance - Action from the actor wich has index actor_index in the trial. The class of the action is defined as action space for the specific actor in section actor_classes:action:space in cogment.yaml .","title":"class RecvAction"},{"location":"cogment/cogment-api-reference/python/#class-recvmessage","text":"Class containing a message. tick_id : int - The time step that the message relates to. sender_name : str - Name of the sender of the message (the name of an actor, or \"env\" if the environment sent the message). payload : google.protobuf.Any instance - Data for a received message. The class enclosed in google.protobuf.Any is of the type set by the sender; It is the responsibility of the receiver to manage the data received (i.e. determine the type and unpack the data).","title":"class RecvMessage"},{"location":"cogment/cogment-api-reference/python/#class-recvreward","text":"Class containing the details of a received reward. tick_id : int - The tick id (time step) for which the reward should be applied. value : float - Value of the reward (aggregated from the sources)","title":"class RecvReward"},{"location":"cogment/cogment-api-reference/python/#get_nb_sourcesself","text":"Return the number of source rewards this reward is based upon. Parameters: None Return: int - Number of sources.","title":"``get_nb_sources(self)"},{"location":"cogment/cogment-api-reference/python/#all_sourcesself","text":"Generator method to iterate over all sources making up this reward. Parameters: None Return: generator(RecvRewardSource instance) - A generator for the sources in the reward (simple rewards that make up this final/aggregate reward).","title":"all_sources(self)"},{"location":"cogment/cogment-api-reference/python/#class-recvrewardsource","text":"Class containing the details of a received single source reward. value : float - Value of the reward from the sender confidence : float - Confidence level of this reward value. sender_name : str - Name of the sender of this reward (the name of an actor, or \"env\" if the environment sent the reward). user_data : google.protobuf.Any instance - Data for a user-specific reward format. Can be None if no specific data was provided. The class enclosed in google.protobuf.Any is of the type set by the sender; It is the responsibility of the receiver to manage the data received (i.e. determine the type and unpack the data).","title":"class RecvRewardSource"},{"location":"cogment/cogment-api-reference/javascript/modules/","text":"A library for interacting with the cogment.ai framework. Table of contents \u00b6 Enumerations \u00b6 EventType Classes \u00b6 ActorSession CogmentService TrialController Interfaces \u00b6 CogSettings CogSettingsActorClass CogmentYaml CogmentYamlActor CogmentYamlActorClass CogmentYamlDatalog CogmentYamlTrialParameters CreateServiceOptions Event Reward SendMessageOptions TrialActor Type aliases \u00b6 ActorImplementation \u00b6 \u01ac ActorImplementation <ActionT, ObservationT, RewardT>: ( session : ActorSession ) => Promise <void> A function that implements the participation of this actor class in a trial. param An ActorSession instance the actor controls to interact with a trial. Type parameters: \u00b6 Name Type Description ActionT Message The action space type for this actor class ObservationT Message The observation space type for this actor class RewardT Message The reward type for this actor class Type declaration: \u00b6 \u25b8 ( session : ActorSession <ActionT, ObservationT, RewardT>): Promise <void> Parameters: \u00b6 Name Type session ActorSession <ActionT, ObservationT, RewardT> Returns: Promise <void> Defined in: cogment/CogmentService.ts:44 JoinTrialArguments \u00b6 \u01ac JoinTrialArguments : object Arguments to joinTrial Type declaration: \u00b6 Name Type Description actorClass ? string The class of the actor; this must correspond with a CogmentYaml.actor_classes . actorName ? string Unique identifier for this actor connecting to the trial. Used for message passing. trialId string The id of the trial to join. Defined in: cogment/TrialController.ts:381 JoinTrialReturnType \u00b6 \u01ac JoinTrialReturnType : TrialJoinReply.AsObject & { config : any } Defined in: cogment/TrialController.ts:375 SendMessageReturnType \u00b6 \u01ac SendMessageReturnType : TrialMessageReply.AsObject Defined in: cogment/TrialController.ts:372 StartTrialReturnType \u00b6 \u01ac StartTrialReturnType : TrialStartReply.AsObject Defined in: cogment/TrialController.ts:373 VersionReturnType \u00b6 \u01ac VersionReturnType : object Type declaration: \u00b6 Name Type version VersionInfo.AsObject[ versionsList ] Defined in: cogment/TrialController.ts:376 Functions \u00b6 createService \u00b6 \u25b8 createService ( __namedParameters : { cogSettings : CogSettings ; grpcURL : string ; streamingTransportFactory? : grpc.TransportFactory ; unaryTransportFactory? : grpc.TransportFactory }): CogmentService Creates a new CogmentService from a generated CogSettings . Optionally accepts transports used by gRPC clients. example Instantiating the cogment API. import { createService } from 'cogment' ; import cogSettings from 'CogSettings' ; const cogment = createService ( cogSettings ); Parameters: \u00b6 Name Type Description __namedParameters object - __namedParameters.cogSettings CogSettings Settings loaded from a generated CogSettings file. __namedParameters.grpcURL string HTTP(S) url of grpc-web reverse proxy to orchestrator. Defaults to //${window.location.hostname}:8080 __namedParameters.streamingTransportFactory? grpc.TransportFactory A grpc.TransportFactory used to instantiate streaming connections to the backend. Defaults to grpc.WebsocketTransport() . __namedParameters.unaryTransportFactory? grpc.TransportFactory A grpc.TransportFactory used to make unary (non-streaming) requests to the backend. Defaults to grpc.CrossBrowserHttpTransport({withCredentials: false}) . Returns: CogmentService Defined in: cogment/Cogment.ts:61","title":"Modules"},{"location":"cogment/cogment-api-reference/javascript/modules/#table-of-contents","text":"","title":"Table of contents"},{"location":"cogment/cogment-api-reference/javascript/modules/#enumerations","text":"EventType","title":"Enumerations"},{"location":"cogment/cogment-api-reference/javascript/modules/#classes","text":"ActorSession CogmentService TrialController","title":"Classes"},{"location":"cogment/cogment-api-reference/javascript/modules/#interfaces","text":"CogSettings CogSettingsActorClass CogmentYaml CogmentYamlActor CogmentYamlActorClass CogmentYamlDatalog CogmentYamlTrialParameters CreateServiceOptions Event Reward SendMessageOptions TrialActor","title":"Interfaces"},{"location":"cogment/cogment-api-reference/javascript/modules/#type-aliases","text":"","title":"Type aliases"},{"location":"cogment/cogment-api-reference/javascript/modules/#actorimplementation","text":"\u01ac ActorImplementation <ActionT, ObservationT, RewardT>: ( session : ActorSession ) => Promise <void> A function that implements the participation of this actor class in a trial. param An ActorSession instance the actor controls to interact with a trial.","title":"ActorImplementation"},{"location":"cogment/cogment-api-reference/javascript/modules/#type-parameters","text":"Name Type Description ActionT Message The action space type for this actor class ObservationT Message The observation space type for this actor class RewardT Message The reward type for this actor class","title":"Type parameters:"},{"location":"cogment/cogment-api-reference/javascript/modules/#type-declaration","text":"\u25b8 ( session : ActorSession <ActionT, ObservationT, RewardT>): Promise <void>","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/modules/#parameters","text":"Name Type session ActorSession <ActionT, ObservationT, RewardT> Returns: Promise <void> Defined in: cogment/CogmentService.ts:44","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/modules/#jointrialarguments","text":"\u01ac JoinTrialArguments : object Arguments to joinTrial","title":"JoinTrialArguments"},{"location":"cogment/cogment-api-reference/javascript/modules/#type-declaration_1","text":"Name Type Description actorClass ? string The class of the actor; this must correspond with a CogmentYaml.actor_classes . actorName ? string Unique identifier for this actor connecting to the trial. Used for message passing. trialId string The id of the trial to join. Defined in: cogment/TrialController.ts:381","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/modules/#jointrialreturntype","text":"\u01ac JoinTrialReturnType : TrialJoinReply.AsObject & { config : any } Defined in: cogment/TrialController.ts:375","title":"JoinTrialReturnType"},{"location":"cogment/cogment-api-reference/javascript/modules/#sendmessagereturntype","text":"\u01ac SendMessageReturnType : TrialMessageReply.AsObject Defined in: cogment/TrialController.ts:372","title":"SendMessageReturnType"},{"location":"cogment/cogment-api-reference/javascript/modules/#starttrialreturntype","text":"\u01ac StartTrialReturnType : TrialStartReply.AsObject Defined in: cogment/TrialController.ts:373","title":"StartTrialReturnType"},{"location":"cogment/cogment-api-reference/javascript/modules/#versionreturntype","text":"\u01ac VersionReturnType : object","title":"VersionReturnType"},{"location":"cogment/cogment-api-reference/javascript/modules/#type-declaration_2","text":"Name Type version VersionInfo.AsObject[ versionsList ] Defined in: cogment/TrialController.ts:376","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/modules/#functions","text":"","title":"Functions"},{"location":"cogment/cogment-api-reference/javascript/modules/#createservice","text":"\u25b8 createService ( __namedParameters : { cogSettings : CogSettings ; grpcURL : string ; streamingTransportFactory? : grpc.TransportFactory ; unaryTransportFactory? : grpc.TransportFactory }): CogmentService Creates a new CogmentService from a generated CogSettings . Optionally accepts transports used by gRPC clients. example Instantiating the cogment API. import { createService } from 'cogment' ; import cogSettings from 'CogSettings' ; const cogment = createService ( cogSettings );","title":"createService"},{"location":"cogment/cogment-api-reference/javascript/modules/#parameters_1","text":"Name Type Description __namedParameters object - __namedParameters.cogSettings CogSettings Settings loaded from a generated CogSettings file. __namedParameters.grpcURL string HTTP(S) url of grpc-web reverse proxy to orchestrator. Defaults to //${window.location.hostname}:8080 __namedParameters.streamingTransportFactory? grpc.TransportFactory A grpc.TransportFactory used to instantiate streaming connections to the backend. Defaults to grpc.WebsocketTransport() . __namedParameters.unaryTransportFactory? grpc.TransportFactory A grpc.TransportFactory used to make unary (non-streaming) requests to the backend. Defaults to grpc.CrossBrowserHttpTransport({withCredentials: false}) . Returns: CogmentService Defined in: cogment/Cogment.ts:61","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/","text":"Controller object passed to each ActorImplementation callback. Type parameters \u00b6 Name Type Description ActionT Message The action space type for this actor class ObservationT Message The observation space type for this actor class RewardT Message The reward type for this actor class Methods \u00b6 addFeedback \u00b6 \u25b8 addFeedback ( to : string [], feedback : Reward ): void Parameters: \u00b6 Name Type to string [] feedback Reward Returns: void Defined in: cogment/ActorSession.ts:93 eventLoop \u00b6 \u25b8 eventLoop (): AsyncGenerator < Event <ObservationT, RewardT>, any, unknown> Yields observations, messages and rewards received from the Cogment framework. Returns: AsyncGenerator < Event <ObservationT, RewardT>, any, unknown> A generator that yields observations, messages and rewards. Defined in: cogment/ActorSession.ts:101 getTickId \u00b6 \u25b8 getTickId (): undefined | number Get the trial's current tick id, matching the latest received observation. Returns: undefined | number The current tick id. Defined in: cogment/ActorSession.ts:130 isTrialOver \u00b6 \u25b8 isTrialOver (): boolean Check if the trial is over. Returns: boolean Defined in: cogment/ActorSession.ts:137 sendAction \u00b6 \u25b8 sendAction ( userAction : ActionT): void Send an action to the environment. Parameters: \u00b6 Name Type Description userAction ActionT An action space protobuf for this actor class. Returns: void Defined in: cogment/ActorSession.ts:145 sendMessage \u00b6 \u25b8 sendMessage ( __namedParameters : SendMessageOptions ): Promise <AsObject> Send an asynchronous message to a cogment entity. Parameters: \u00b6 Name Type __namedParameters SendMessageOptions Returns: Promise <AsObject> Defined in: cogment/ActorSession.ts:161 start \u00b6 \u25b8 start (): void Start this ActorSession, the eventLoop will begin yielding events received from the Cogment framework. Returns: void Defined in: cogment/ActorSession.ts:194 stop \u00b6 \u25b8 stop (): void End this ActorSession, ending the eventLoop. Returns: void Defined in: cogment/ActorSession.ts:201","title":"Class: ActorSession"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#type-parameters","text":"Name Type Description ActionT Message The action space type for this actor class ObservationT Message The observation space type for this actor class RewardT Message The reward type for this actor class","title":"Type parameters"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#methods","text":"","title":"Methods"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#addfeedback","text":"\u25b8 addFeedback ( to : string [], feedback : Reward ): void","title":"addFeedback"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#parameters","text":"Name Type to string [] feedback Reward Returns: void Defined in: cogment/ActorSession.ts:93","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#eventloop","text":"\u25b8 eventLoop (): AsyncGenerator < Event <ObservationT, RewardT>, any, unknown> Yields observations, messages and rewards received from the Cogment framework. Returns: AsyncGenerator < Event <ObservationT, RewardT>, any, unknown> A generator that yields observations, messages and rewards. Defined in: cogment/ActorSession.ts:101","title":"eventLoop"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#gettickid","text":"\u25b8 getTickId (): undefined | number Get the trial's current tick id, matching the latest received observation. Returns: undefined | number The current tick id. Defined in: cogment/ActorSession.ts:130","title":"getTickId"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#istrialover","text":"\u25b8 isTrialOver (): boolean Check if the trial is over. Returns: boolean Defined in: cogment/ActorSession.ts:137","title":"isTrialOver"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#sendaction","text":"\u25b8 sendAction ( userAction : ActionT): void Send an action to the environment.","title":"sendAction"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#parameters_1","text":"Name Type Description userAction ActionT An action space protobuf for this actor class. Returns: void Defined in: cogment/ActorSession.ts:145","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#sendmessage","text":"\u25b8 sendMessage ( __namedParameters : SendMessageOptions ): Promise <AsObject> Send an asynchronous message to a cogment entity.","title":"sendMessage"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#parameters_2","text":"Name Type __namedParameters SendMessageOptions Returns: Promise <AsObject> Defined in: cogment/ActorSession.ts:161","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#start","text":"\u25b8 start (): void Start this ActorSession, the eventLoop will begin yielding events received from the Cogment framework. Returns: void Defined in: cogment/ActorSession.ts:194","title":"start"},{"location":"cogment/cogment-api-reference/javascript/classes/actorsession/#stop","text":"\u25b8 stop (): void End this ActorSession, ending the eventLoop. Returns: void Defined in: cogment/ActorSession.ts:201","title":"stop"},{"location":"cogment/cogment-api-reference/javascript/classes/cogmentservice/","text":"Instantiate a new CogmentService that is bound to CogSettings and gRPC clients. This class tracks registered actors and is used for creating TrialController's Methods \u00b6 createTrialController \u00b6 \u25b8 createTrialController (): TrialController Return a TrialController configured with registered TrialActor's, CogSettings and gRPC clients. Returns: TrialController Defined in: cogment/CogmentService.ts:84 registerActor \u00b6 \u25b8 registerActor <ActionT, ObservationT, RewardT>( actorConfig : TrialActor , actorImpl : ActorImplementation <ActionT, ObservationT, RewardT>): void Register a new actor that will participate in the trial. The actor must be defined in cogment.yaml Type parameters: \u00b6 Name Type Description ActionT Message <ActionT> the action space type for this actor class ObservationT Message <ObservationT> the observation space type for this actor class RewardT Message <RewardT> the reward type for this actor class Parameters: \u00b6 Name Type Description actorConfig TrialActor Configuration matching a CogmentYamlActor.name actorImpl ActorImplementation <ActionT, ObservationT, RewardT> The function implementation for this actor Returns: void Defined in: cogment/CogmentService.ts:103","title":"Class: CogmentService"},{"location":"cogment/cogment-api-reference/javascript/classes/cogmentservice/#methods","text":"","title":"Methods"},{"location":"cogment/cogment-api-reference/javascript/classes/cogmentservice/#createtrialcontroller","text":"\u25b8 createTrialController (): TrialController Return a TrialController configured with registered TrialActor's, CogSettings and gRPC clients. Returns: TrialController Defined in: cogment/CogmentService.ts:84","title":"createTrialController"},{"location":"cogment/cogment-api-reference/javascript/classes/cogmentservice/#registeractor","text":"\u25b8 registerActor <ActionT, ObservationT, RewardT>( actorConfig : TrialActor , actorImpl : ActorImplementation <ActionT, ObservationT, RewardT>): void Register a new actor that will participate in the trial. The actor must be defined in cogment.yaml","title":"registerActor"},{"location":"cogment/cogment-api-reference/javascript/classes/cogmentservice/#type-parameters","text":"Name Type Description ActionT Message <ActionT> the action space type for this actor class ObservationT Message <ObservationT> the observation space type for this actor class RewardT Message <RewardT> the reward type for this actor class","title":"Type parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/cogmentservice/#parameters","text":"Name Type Description actorConfig TrialActor Configuration matching a CogmentYamlActor.name actorImpl ActorImplementation <ActionT, ObservationT, RewardT> The function implementation for this actor Returns: void Defined in: cogment/CogmentService.ts:103","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/","text":"Controller for interacting with trials in the Cogment framework. Each instance is bound to CogSettings , TrialActor's ActorImplementation's and gRPC connections to the Cogment framework. Methods \u00b6 getActiveActors \u00b6 \u25b8 getActiveActors (): TrialActor [] A list of TrialActor's associated to this trial. Returns: TrialActor [] The trial actors for this trial. Defined in: cogment/TrialController.ts:101 getTriaId \u00b6 \u25b8 getTriaId (): string The id of any started or joined trial. Returns: string The trial id Defined in: cogment/TrialController.ts:109 getTrialInfo \u00b6 \u25b8 getTrialInfo ( trialId : string ): Promise <TrialInfoReply> Get trial information for a given trial. Parameters: \u00b6 Name Type Description trialId string Id of the trial to retrieve info for. Returns: Promise <TrialInfoReply> Defined in: cogment/TrialController.ts:120 isTrialOver \u00b6 \u25b8 isTrialOver ( trialId : string ): Promise <boolean> Check if a given trial is completed. Parameters: \u00b6 Name Type Description trialId string the id of the trial to check. Returns: Promise <boolean> Defined in: cogment/TrialController.ts:141 joinTrial \u00b6 \u25b8 joinTrial ( trialId : string , trialActor? : TrialActor ): Promise < JoinTrialReturnType > Join a trial given a trial id. Parameters: \u00b6 Name Type Description trialId string The trialId of the trial to join. trialActor? TrialActor The TrialActor configuration to join as. Returns: Promise < JoinTrialReturnType > Defined in: cogment/TrialController.ts:151 startTrial \u00b6 \u25b8 startTrial ( actorClass : string , trialConfig? : Message ): Promise <AsObject> Start a new trial. Parameters: \u00b6 Name Type Description actorClass string The name of an actor_class corresponding to cogment.yaml trialConfig? Message A TrialConfig protobuf that will be passed to any pre-hooks configured in cogment.yaml Returns: Promise <AsObject> A trial start response Defined in: cogment/TrialController.ts:204 terminateTrial \u00b6 \u25b8 terminateTrial ( trialId : string ): Promise <void> Terminate a trial. Parameters: \u00b6 Name Type Description trialId string Id of the trial to terminate. Returns: Promise <void> Defined in: cogment/TrialController.ts:238 version \u00b6 \u25b8 version (): Promise < VersionReturnType > Request the version from the Cogment framework. Returns: Promise < VersionReturnType > Defined in: cogment/TrialController.ts:258 watchTrials \u00b6 \u25b8 watchTrials ( filter? : ( 0 | 2 | 1 | 3 | 4 | 5 )[]): AsyncGenerator <TrialListEntry, void, void> Watch cogment for trial changes. Parameters: \u00b6 Name Type Description filter? ( 0 | 2 | 1 | 3 | 4 | 5 )[] An enum of TrialState's to watch trial changes of. Returns: AsyncGenerator <TrialListEntry, void, void> Defined in: cogment/TrialController.ts:277","title":"Class: TrialController"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#methods","text":"","title":"Methods"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#getactiveactors","text":"\u25b8 getActiveActors (): TrialActor [] A list of TrialActor's associated to this trial. Returns: TrialActor [] The trial actors for this trial. Defined in: cogment/TrialController.ts:101","title":"getActiveActors"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#gettriaid","text":"\u25b8 getTriaId (): string The id of any started or joined trial. Returns: string The trial id Defined in: cogment/TrialController.ts:109","title":"getTriaId"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#gettrialinfo","text":"\u25b8 getTrialInfo ( trialId : string ): Promise <TrialInfoReply> Get trial information for a given trial.","title":"getTrialInfo"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#parameters","text":"Name Type Description trialId string Id of the trial to retrieve info for. Returns: Promise <TrialInfoReply> Defined in: cogment/TrialController.ts:120","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#istrialover","text":"\u25b8 isTrialOver ( trialId : string ): Promise <boolean> Check if a given trial is completed.","title":"isTrialOver"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#parameters_1","text":"Name Type Description trialId string the id of the trial to check. Returns: Promise <boolean> Defined in: cogment/TrialController.ts:141","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#jointrial","text":"\u25b8 joinTrial ( trialId : string , trialActor? : TrialActor ): Promise < JoinTrialReturnType > Join a trial given a trial id.","title":"joinTrial"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#parameters_2","text":"Name Type Description trialId string The trialId of the trial to join. trialActor? TrialActor The TrialActor configuration to join as. Returns: Promise < JoinTrialReturnType > Defined in: cogment/TrialController.ts:151","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#starttrial","text":"\u25b8 startTrial ( actorClass : string , trialConfig? : Message ): Promise <AsObject> Start a new trial.","title":"startTrial"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#parameters_3","text":"Name Type Description actorClass string The name of an actor_class corresponding to cogment.yaml trialConfig? Message A TrialConfig protobuf that will be passed to any pre-hooks configured in cogment.yaml Returns: Promise <AsObject> A trial start response Defined in: cogment/TrialController.ts:204","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#terminatetrial","text":"\u25b8 terminateTrial ( trialId : string ): Promise <void> Terminate a trial.","title":"terminateTrial"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#parameters_4","text":"Name Type Description trialId string Id of the trial to terminate. Returns: Promise <void> Defined in: cogment/TrialController.ts:238","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#version","text":"\u25b8 version (): Promise < VersionReturnType > Request the version from the Cogment framework. Returns: Promise < VersionReturnType > Defined in: cogment/TrialController.ts:258","title":"version"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#watchtrials","text":"\u25b8 watchTrials ( filter? : ( 0 | 2 | 1 | 3 | 4 | 5 )[]): AsyncGenerator <TrialListEntry, void, void> Watch cogment for trial changes.","title":"watchTrials"},{"location":"cogment/cogment-api-reference/javascript/classes/trialcontroller/#parameters_5","text":"Name Type Description filter? ( 0 | 2 | 1 | 3 | 4 | 5 )[] An enum of TrialState's to watch trial changes of. Returns: AsyncGenerator <TrialListEntry, void, void> Defined in: cogment/TrialController.ts:277","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/enums/eventtype/","text":"The type of an incoming event, representing the state of the trial. Enumeration members \u00b6 ACTIVE \u00b6 \u2022 ACTIVE : = 1 Defined in: cogment/types/Event.ts:26 ENDING \u00b6 \u2022 ENDING : = 2 Defined in: cogment/types/Event.ts:27 FINAL \u00b6 \u2022 FINAL : = 3 Defined in: cogment/types/Event.ts:28 NONE \u00b6 \u2022 NONE : = 0 Defined in: cogment/types/Event.ts:25","title":"Enum: EventType"},{"location":"cogment/cogment-api-reference/javascript/enums/eventtype/#enumeration-members","text":"","title":"Enumeration members"},{"location":"cogment/cogment-api-reference/javascript/enums/eventtype/#active","text":"\u2022 ACTIVE : = 1 Defined in: cogment/types/Event.ts:26","title":"ACTIVE"},{"location":"cogment/cogment-api-reference/javascript/enums/eventtype/#ending","text":"\u2022 ENDING : = 2 Defined in: cogment/types/Event.ts:27","title":"ENDING"},{"location":"cogment/cogment-api-reference/javascript/enums/eventtype/#final","text":"\u2022 FINAL : = 3 Defined in: cogment/types/Event.ts:28","title":"FINAL"},{"location":"cogment/cogment-api-reference/javascript/enums/eventtype/#none","text":"\u2022 NONE : = 0 Defined in: cogment/types/Event.ts:25","title":"NONE"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/","text":"Static configuration of various entities participating in a Cogment application. This human-readable file is transformed by the cogment generate command into a language specific module. Properties \u00b6 actor_classes \u00b6 \u2022 actor_classes : CogmentYamlActorClass [] Static configuration of actor classes available for participation in a trial. Defined in: cogment/types/CogmentYaml.ts:133 commands \u00b6 \u2022 commands : Record <string, string> List of arbitrary shell commands available for invocation through cogment run xyz Defined in: cogment/types/CogmentYaml.ts:138 datalog \u00b6 \u2022 Optional datalog : CogmentYamlDatalog Datalog static configuration. Defined in: cogment/types/CogmentYaml.ts:142 environment \u00b6 \u2022 environment : object Environment static configuration. Type declaration: \u00b6 Name Type Description config_type string Full protobuf message type representing an environment's configuration. Defined in: cogment/types/CogmentYaml.ts:146 import \u00b6 \u2022 import : object User generated imports. Type declaration: \u00b6 Name Type Description proto string [] List of paths to .proto files used by application specific entities. Defined in: cogment/types/CogmentYaml.ts:155 pre_hooks \u00b6 \u2022 Optional pre_hooks : string [] List of gRPC endpoints that are called in order prior to starting a trial. Pre-hooks act as a pipeline for mutating a trial's configuration before it's start. Pre-hooks may additionally be used for other purposes. Defined in: cogment/types/CogmentYaml.ts:165 trial \u00b6 \u2022 trial : object Trial static configuration. Type declaration: \u00b6 Name Type Description config_type string Full protobuf message type representing a trial's configuration. Defined in: cogment/types/CogmentYaml.ts:169 trial_params \u00b6 \u2022 trial_params : CogmentYamlTrialParameters Trial specific configuration such as the actor slots available for registration, configuration for entities (eg: values for an environment's configuration). Defined in: cogment/types/CogmentYaml.ts:179","title":"Interface: CogmentYaml"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#actor_classes","text":"\u2022 actor_classes : CogmentYamlActorClass [] Static configuration of actor classes available for participation in a trial. Defined in: cogment/types/CogmentYaml.ts:133","title":"actor_classes"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#commands","text":"\u2022 commands : Record <string, string> List of arbitrary shell commands available for invocation through cogment run xyz Defined in: cogment/types/CogmentYaml.ts:138","title":"commands"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#datalog","text":"\u2022 Optional datalog : CogmentYamlDatalog Datalog static configuration. Defined in: cogment/types/CogmentYaml.ts:142","title":"datalog"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#environment","text":"\u2022 environment : object Environment static configuration.","title":"environment"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#type-declaration","text":"Name Type Description config_type string Full protobuf message type representing an environment's configuration. Defined in: cogment/types/CogmentYaml.ts:146","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#import","text":"\u2022 import : object User generated imports.","title":"import"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#type-declaration_1","text":"Name Type Description proto string [] List of paths to .proto files used by application specific entities. Defined in: cogment/types/CogmentYaml.ts:155","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#pre_hooks","text":"\u2022 Optional pre_hooks : string [] List of gRPC endpoints that are called in order prior to starting a trial. Pre-hooks act as a pipeline for mutating a trial's configuration before it's start. Pre-hooks may additionally be used for other purposes. Defined in: cogment/types/CogmentYaml.ts:165","title":"pre_hooks"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#trial","text":"\u2022 trial : object Trial static configuration.","title":"trial"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#type-declaration_2","text":"Name Type Description config_type string Full protobuf message type representing a trial's configuration. Defined in: cogment/types/CogmentYaml.ts:169","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyaml/#trial_params","text":"\u2022 trial_params : CogmentYamlTrialParameters Trial specific configuration such as the actor slots available for registration, configuration for entities (eg: values for an environment's configuration). Defined in: cogment/types/CogmentYaml.ts:179","title":"trial_params"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactor/","text":"Static configuration of an actor participating in a trial. Properties \u00b6 actor_class \u00b6 \u2022 actor_class : string The CogmentYamlActorClass this actor is an instance of (must match CogmentYamlActorClass.name ). Defined in: cogment/types/CogmentYaml.ts:107 endpoint \u00b6 \u2022 endpoint : string gRPC endpoint of this actor. The special value of client is used for connecting actors (vs. served actors). Defined in: cogment/types/CogmentYaml.ts:111 implementation \u00b6 \u2022 implementation : string Which implementation of this actor class to use. Actors may have multiple implementations. The special value of client is used for connecting actors (vs. served actors). Defined in: cogment/types/CogmentYaml.ts:116 name \u00b6 \u2022 name : string A unique name for this actor instance. This identifier is used for communication between actors using message passing. Defined in: cogment/types/CogmentYaml.ts:121","title":"Interface: CogmentYamlActor"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactor/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactor/#actor_class","text":"\u2022 actor_class : string The CogmentYamlActorClass this actor is an instance of (must match CogmentYamlActorClass.name ). Defined in: cogment/types/CogmentYaml.ts:107","title":"actor_class"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactor/#endpoint","text":"\u2022 endpoint : string gRPC endpoint of this actor. The special value of client is used for connecting actors (vs. served actors). Defined in: cogment/types/CogmentYaml.ts:111","title":"endpoint"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactor/#implementation","text":"\u2022 implementation : string Which implementation of this actor class to use. Actors may have multiple implementations. The special value of client is used for connecting actors (vs. served actors). Defined in: cogment/types/CogmentYaml.ts:116","title":"implementation"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactor/#name","text":"\u2022 name : string A unique name for this actor instance. This identifier is used for communication between actors using message passing. Defined in: cogment/types/CogmentYaml.ts:121","title":"name"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/","text":"Static configuration for an actor class. Properties \u00b6 action \u00b6 \u2022 action : object Action space static configuration. Type declaration: \u00b6 Name Type Description space string Full protobuf message type representing the action space of this actor. Defined in: cogment/types/CogmentYaml.ts:25 config_type \u00b6 \u2022 Optional config_type : string Full protobuf message type representing the configuration of this actor. Defined in: cogment/types/CogmentYaml.ts:34 name \u00b6 \u2022 name : string Unique identifier for this actor. This identifier corresponds to TrialActor.actorClass and is used to register actor implementations with CogmentService.registerActor . Defined in: cogment/types/CogmentYaml.ts:39 observation \u00b6 \u2022 observation : object Observation space static configuration. Type declaration: \u00b6 Name Type Description space string Full protobuf message type representing the observation space of this actor. Defined in: cogment/types/CogmentYaml.ts:43","title":"Interface: CogmentYamlActorClass"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#action","text":"\u2022 action : object Action space static configuration.","title":"action"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#type-declaration","text":"Name Type Description space string Full protobuf message type representing the action space of this actor. Defined in: cogment/types/CogmentYaml.ts:25","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#config_type","text":"\u2022 Optional config_type : string Full protobuf message type representing the configuration of this actor. Defined in: cogment/types/CogmentYaml.ts:34","title":"config_type"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#name","text":"\u2022 name : string Unique identifier for this actor. This identifier corresponds to TrialActor.actorClass and is used to register actor implementations with CogmentService.registerActor . Defined in: cogment/types/CogmentYaml.ts:39","title":"name"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#observation","text":"\u2022 observation : object Observation space static configuration.","title":"observation"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamlactorclass/#type-declaration_1","text":"Name Type Description space string Full protobuf message type representing the observation space of this actor. Defined in: cogment/types/CogmentYaml.ts:43","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamldatalog/","text":"Datalog static configuration. Properties \u00b6 type \u00b6 \u2022 type : grpc The type of connection. defaultvalue grpc Defined in: cogment/types/CogmentYaml.ts:92 url \u00b6 \u2022 url : string gRPC endpoint of the Datalog service. Defined in: cogment/types/CogmentYaml.ts:96","title":"Interface: CogmentYamlDatalog"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamldatalog/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamldatalog/#type","text":"\u2022 type : grpc The type of connection. defaultvalue grpc Defined in: cogment/types/CogmentYaml.ts:92","title":"type"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamldatalog/#url","text":"\u2022 url : string gRPC endpoint of the Datalog service. Defined in: cogment/types/CogmentYaml.ts:96","title":"url"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/","text":"Default static configuration for a trial. Properties \u00b6 actors \u00b6 \u2022 actors : CogmentYamlActor [] List of actor slots available for registration during the trial. Defined in: cogment/types/CogmentYaml.ts:58 environment \u00b6 \u2022 environment : object Static environment configuration. Type declaration: \u00b6 Name Type Description config ? Record <string, unknown> Custom configuration for this trial passed to CogmentYaml.pre_hooks - keys/values must match the environment's config protobuf {@link CogmentYaml.environment.config_type endpoint string gRPC URI of the environment endpoint. Defined in: cogment/types/CogmentYaml.ts:62 max_inactivity \u00b6 \u2022 Optional max_inactivity : number The maximum number of ticks before the trial is considered inactive and eligible for garbage collection. Defined in: cogment/types/CogmentYaml.ts:77 max_steps \u00b6 \u2022 Optional max_steps : number The maximum number of ticks the trial should run for. Defined in: cogment/types/CogmentYaml.ts:81","title":"Interface: CogmentYamlTrialParameters"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/#actors","text":"\u2022 actors : CogmentYamlActor [] List of actor slots available for registration during the trial. Defined in: cogment/types/CogmentYaml.ts:58","title":"actors"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/#environment","text":"\u2022 environment : object Static environment configuration.","title":"environment"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/#type-declaration","text":"Name Type Description config ? Record <string, unknown> Custom configuration for this trial passed to CogmentYaml.pre_hooks - keys/values must match the environment's config protobuf {@link CogmentYaml.environment.config_type endpoint string gRPC URI of the environment endpoint. Defined in: cogment/types/CogmentYaml.ts:62","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/#max_inactivity","text":"\u2022 Optional max_inactivity : number The maximum number of ticks before the trial is considered inactive and eligible for garbage collection. Defined in: cogment/types/CogmentYaml.ts:77","title":"max_inactivity"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogmentyamltrialparameters/#max_steps","text":"\u2022 Optional max_steps : number The maximum number of ticks the trial should run for. Defined in: cogment/types/CogmentYaml.ts:81","title":"max_steps"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/","text":"Generated static configuration for a Cogment application. Properties \u00b6 actorClasses \u00b6 \u2022 actorClasses : Record <string, CogSettingsActorClass > Actor class static configuration. Defined in: cogment/types/CogSettings.ts:60 environment \u00b6 \u2022 environment : object Environment static configuration. Type declaration: \u00b6 Name Type Description config ? typeof Message Protobuf message type of the environment's configuration. Defined in: cogment/types/CogSettings.ts:64 trial \u00b6 \u2022 trial : object Trial static configuration. Type declaration: \u00b6 Name Type Description config typeof Message Protobuf message type of the trial's configuration. Defined in: cogment/types/CogSettings.ts:73","title":"Interface: CogSettings"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/#actorclasses","text":"\u2022 actorClasses : Record <string, CogSettingsActorClass > Actor class static configuration. Defined in: cogment/types/CogSettings.ts:60","title":"actorClasses"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/#environment","text":"\u2022 environment : object Environment static configuration.","title":"environment"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/#type-declaration","text":"Name Type Description config ? typeof Message Protobuf message type of the environment's configuration. Defined in: cogment/types/CogSettings.ts:64","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/#trial","text":"\u2022 trial : object Trial static configuration.","title":"trial"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettings/#type-declaration_1","text":"Name Type Description config typeof Message Protobuf message type of the trial's configuration. Defined in: cogment/types/CogSettings.ts:73","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/","text":"Generated static configuration of a Cogment actor. Properties \u00b6 actionSpace \u00b6 \u2022 actionSpace : typeof Message Protobuf message type of this actor's action space. see {@link CogmentYamlActorClass.action.space} Defined in: cogment/types/CogSettings.ts:28 config \u00b6 \u2022 Optional config : typeof Message Protobuf message type of this actor's config type. see CogmentYamlActorClass.config_type Defined in: cogment/types/CogSettings.ts:33 name \u00b6 \u2022 name : string see CogmentYamlActorClass.name Defined in: cogment/types/CogSettings.ts:37 observationDelta \u00b6 \u2022 Optional observationDelta : typeof Message Protobuf message type of this actor's observation delta. Defined in: cogment/types/CogSettings.ts:41 observationDeltaApply \u00b6 \u2022 Optional observationDeltaApply : ( x : Message ) => Message Function used to transform observation deltas. Type declaration: \u00b6 \u25b8 ( x : Message ): Message Parameters: \u00b6 Name Type x Message Returns: Message Defined in: cogment/types/CogSettings.ts:45 Defined in: cogment/types/CogSettings.ts:45 observationSpace \u00b6 \u2022 observationSpace : typeof Message Protobuf message type of this actor's observation space. see {@link CogmentYamlActorClass.observation.space} Defined in: cogment/types/CogSettings.ts:50","title":"Interface: CogSettingsActorClass"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#actionspace","text":"\u2022 actionSpace : typeof Message Protobuf message type of this actor's action space. see {@link CogmentYamlActorClass.action.space} Defined in: cogment/types/CogSettings.ts:28","title":"actionSpace"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#config","text":"\u2022 Optional config : typeof Message Protobuf message type of this actor's config type. see CogmentYamlActorClass.config_type Defined in: cogment/types/CogSettings.ts:33","title":"config"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#name","text":"\u2022 name : string see CogmentYamlActorClass.name Defined in: cogment/types/CogSettings.ts:37","title":"name"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#observationdelta","text":"\u2022 Optional observationDelta : typeof Message Protobuf message type of this actor's observation delta. Defined in: cogment/types/CogSettings.ts:41","title":"observationDelta"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#observationdeltaapply","text":"\u2022 Optional observationDeltaApply : ( x : Message ) => Message Function used to transform observation deltas.","title":"observationDeltaApply"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#type-declaration","text":"\u25b8 ( x : Message ): Message","title":"Type declaration:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#parameters","text":"Name Type x Message Returns: Message Defined in: cogment/types/CogSettings.ts:45 Defined in: cogment/types/CogSettings.ts:45","title":"Parameters:"},{"location":"cogment/cogment-api-reference/javascript/interfaces/cogsettingsactorclass/#observationspace","text":"\u2022 observationSpace : typeof Message Protobuf message type of this actor's observation space. see {@link CogmentYamlActorClass.observation.space} Defined in: cogment/types/CogSettings.ts:50","title":"observationSpace"},{"location":"cogment/cogment-api-reference/javascript/interfaces/createserviceoptions/","text":"Options for creating a service. Properties \u00b6 cogSettings \u00b6 \u2022 cogSettings : CogSettings CogSettings file generated by cogment generate . example import CogSettings from './CogSettings' ; Defined in: cogment/Cogment.ts:124 grpcURL \u00b6 \u2022 Optional grpcURL : string URL of the Cogment gRPC backend. defaultvalue //${window.location.hostname}:8080 Defined in: cogment/Cogment.ts:130 streamingTransportFactory \u00b6 \u2022 Optional streamingTransportFactory : TransportFactory gRPC transport for streaming calls. defaultvalue grpc . WebsocketTransport () Defined in: cogment/Cogment.ts:138 unaryTransportFactory \u00b6 \u2022 Optional unaryTransportFactory : TransportFactory gRPC transport for unary calls. defaultvalue grpc . CrossBrowserHttpTransport ({ withCredentials : false , }) Defined in: cogment/Cogment.ts:148","title":"Interface: CreateServiceOptions"},{"location":"cogment/cogment-api-reference/javascript/interfaces/createserviceoptions/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/createserviceoptions/#cogsettings","text":"\u2022 cogSettings : CogSettings CogSettings file generated by cogment generate . example import CogSettings from './CogSettings' ; Defined in: cogment/Cogment.ts:124","title":"cogSettings"},{"location":"cogment/cogment-api-reference/javascript/interfaces/createserviceoptions/#grpcurl","text":"\u2022 Optional grpcURL : string URL of the Cogment gRPC backend. defaultvalue //${window.location.hostname}:8080 Defined in: cogment/Cogment.ts:130","title":"grpcURL"},{"location":"cogment/cogment-api-reference/javascript/interfaces/createserviceoptions/#streamingtransportfactory","text":"\u2022 Optional streamingTransportFactory : TransportFactory gRPC transport for streaming calls. defaultvalue grpc . WebsocketTransport () Defined in: cogment/Cogment.ts:138","title":"streamingTransportFactory"},{"location":"cogment/cogment-api-reference/javascript/interfaces/createserviceoptions/#unarytransportfactory","text":"\u2022 Optional unaryTransportFactory : TransportFactory gRPC transport for unary calls. defaultvalue grpc . CrossBrowserHttpTransport ({ withCredentials : false , }) Defined in: cogment/Cogment.ts:148","title":"unaryTransportFactory"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/","text":"An event received from the Cogment framework. Type parameters \u00b6 Name Type Description ObservationT Message Protobuf message type of the observation space. FeedbackT Message Protobuf message type of the feedback space. Properties \u00b6 message \u00b6 \u2022 Optional message : CogMessage The next message encoded as a protobuf message. Defined in: cogment/types/Event.ts:43 observation \u00b6 \u2022 Optional observation : ObservationT The next observation from the environment encoded as a protobuf message. Defined in: cogment/types/Event.ts:47 reward \u00b6 \u2022 Optional reward : FeedbackT The next reward encoded as a protobuf message. Defined in: cogment/types/Event.ts:51 tickId \u00b6 \u2022 Optional tickId : number The tick id of this event. Defined in: cogment/types/Event.ts:55 timestamp \u00b6 \u2022 Optional timestamp : number Epoch timestamp in milliseconds when this event was generated by the Cogment framework. Defined in: cogment/types/Event.ts:59 type \u00b6 \u2022 Optional type : EventType The trial state at the tick id of this event. Defined in: cogment/types/Event.ts:63","title":"Interface: Event"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#type-parameters","text":"Name Type Description ObservationT Message Protobuf message type of the observation space. FeedbackT Message Protobuf message type of the feedback space.","title":"Type parameters"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#message","text":"\u2022 Optional message : CogMessage The next message encoded as a protobuf message. Defined in: cogment/types/Event.ts:43","title":"message"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#observation","text":"\u2022 Optional observation : ObservationT The next observation from the environment encoded as a protobuf message. Defined in: cogment/types/Event.ts:47","title":"observation"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#reward","text":"\u2022 Optional reward : FeedbackT The next reward encoded as a protobuf message. Defined in: cogment/types/Event.ts:51","title":"reward"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#tickid","text":"\u2022 Optional tickId : number The tick id of this event. Defined in: cogment/types/Event.ts:55","title":"tickId"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#timestamp","text":"\u2022 Optional timestamp : number Epoch timestamp in milliseconds when this event was generated by the Cogment framework. Defined in: cogment/types/Event.ts:59","title":"timestamp"},{"location":"cogment/cogment-api-reference/javascript/interfaces/event/#type","text":"\u2022 Optional type : EventType The trial state at the tick id of this event. Defined in: cogment/types/Event.ts:63","title":"type"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/","text":"A reward received from the Cogment framework. Properties \u00b6 confidence \u00b6 \u2022 confidence : number Confidence in this reward's value. Defined in: cogment/types/Reward.ts:27 receiverName \u00b6 \u2022 receiverName : string The name of the actor receiving the reward. Defined in: cogment/types/Reward.ts:31 sources \u00b6 \u2022 sources : RewardSource Reward sources. Defined in: cogment/types/Reward.ts:35 tickId \u00b6 \u2022 tickId : number The tick id of this reward. Defined in: cogment/types/Reward.ts:39 value \u00b6 \u2022 value : number The value of this reward. Defined in: cogment/types/Reward.ts:43","title":"Interface: Reward"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/#confidence","text":"\u2022 confidence : number Confidence in this reward's value. Defined in: cogment/types/Reward.ts:27","title":"confidence"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/#receivername","text":"\u2022 receiverName : string The name of the actor receiving the reward. Defined in: cogment/types/Reward.ts:31","title":"receiverName"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/#sources","text":"\u2022 sources : RewardSource Reward sources. Defined in: cogment/types/Reward.ts:35","title":"sources"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/#tickid","text":"\u2022 tickId : number The tick id of this reward. Defined in: cogment/types/Reward.ts:39","title":"tickId"},{"location":"cogment/cogment-api-reference/javascript/interfaces/reward/#value","text":"\u2022 value : number The value of this reward. Defined in: cogment/types/Reward.ts:43","title":"value"},{"location":"cogment/cogment-api-reference/javascript/interfaces/sendmessageoptions/","text":"Properties \u00b6 from \u00b6 \u2022 from : string The unique identifier for the connected actor generating the message. Defined in: cogment/ActorSession.ts:310 payload \u00b6 \u2022 payload : Any The payload data, encoded as an Any protobuf message. Defined in: cogment/ActorSession.ts:314 to \u00b6 \u2022 to : string The unique identifier for the messages destination. Can be another actors name, or the special value env to send a message to the environment. Defined in: cogment/ActorSession.ts:319 trialId \u00b6 \u2022 trialId : string The id of the trial to send the message to. Defined in: cogment/ActorSession.ts:323","title":"Interface: SendMessageOptions"},{"location":"cogment/cogment-api-reference/javascript/interfaces/sendmessageoptions/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/sendmessageoptions/#from","text":"\u2022 from : string The unique identifier for the connected actor generating the message. Defined in: cogment/ActorSession.ts:310","title":"from"},{"location":"cogment/cogment-api-reference/javascript/interfaces/sendmessageoptions/#payload","text":"\u2022 payload : Any The payload data, encoded as an Any protobuf message. Defined in: cogment/ActorSession.ts:314","title":"payload"},{"location":"cogment/cogment-api-reference/javascript/interfaces/sendmessageoptions/#to","text":"\u2022 to : string The unique identifier for the messages destination. Can be another actors name, or the special value env to send a message to the environment. Defined in: cogment/ActorSession.ts:319","title":"to"},{"location":"cogment/cogment-api-reference/javascript/interfaces/sendmessageoptions/#trialid","text":"\u2022 trialId : string The id of the trial to send the message to. Defined in: cogment/ActorSession.ts:323","title":"trialId"},{"location":"cogment/cogment-api-reference/javascript/interfaces/trialactor/","text":"Configuration for an actor joining a trial. Properties \u00b6 actorClass \u00b6 \u2022 actorClass : string The actors class. see CogmentYamlActorClass.name Defined in: cogment/types/TrialActor.ts:26 name \u00b6 \u2022 name : string A unique identifier for this actor, used for message passing between actors in a running trial. Defined in: cogment/types/TrialActor.ts:30","title":"Interface: TrialActor"},{"location":"cogment/cogment-api-reference/javascript/interfaces/trialactor/#properties","text":"","title":"Properties"},{"location":"cogment/cogment-api-reference/javascript/interfaces/trialactor/#actorclass","text":"\u2022 actorClass : string The actors class. see CogmentYamlActorClass.name Defined in: cogment/types/TrialActor.ts:26","title":"actorClass"},{"location":"cogment/cogment-api-reference/javascript/interfaces/trialactor/#name","text":"\u2022 name : string A unique identifier for this actor, used for message passing between actors in a running trial. Defined in: cogment/types/TrialActor.ts:30","title":"name"},{"location":"cogment/cogment-low-level-api-guide/grpc/","text":"Cogment gRPC API \u00b6 The low-level cogment communication API is implemented using gRPC services. These services are collections of procedures to be called remotely (RPC). gRPC abstracts the network communication with familiar looking functions (representing the defined procedures), in any number of programming languages. How services are implemented or accessed is highly dependant on the programming language being interfaced, and is beyond the scope of this document (see gRPC API documentation). This reference requires a basic understanding of gRPC, and in particular the format of the proto files. General \u00b6 In this API, the bytes data type is normally used to contain the serialized data of externally defined messages. These messages are well defined in the cogment.yaml file. On the other hand, the google.protobuf.Any data type is normally used to contain messages that are not pre-defined, and may be decided at runtime. Empty messages are normally used as a placeholder for easy future, backward compatible, extension of the API. In this API, gRPC metadata is normally used only for service request (procedure calls) for identifying purposes. The details of the required metadata are described with the service calls. Service replies are not expecting to provide metadata. In many places in the API, we use a list of actor data without information about which actor is where in the list. These lists have a constant length and order throughout a trial (set in the trial parameters), and thus can/must be cross referenced with other such lists within the same trial (e.g. actors_in_trial , actors_map ). The actor can be infered by the position in the list, and the index into the list can sometimes be used to identify an actor. Limitations \u00b6 Due to normal network delays and unpredictability of the various componenents, there are limitations related to the communication with the Ochestrator that translate in issues that can arise. In the current version, to simplify the implementation, there is an expectation of \"good behavior\" from the various components: Actors are expected to respond with an action only after receiving an observation, and to send only one action per observation received. The environment is expected to respond with an observation set only after receiving an action set, and to send only one observation set per action set received. All components are expected to respond within a reasonable time (e.g. less than 5 sec). Hooks do not assume to receive specific parameters, reply only with well formed parameters, and do not assume a specific order of hooks being called (when multiple hooks are defined). A TerminateTrial (from the Control API) is called only a reasonable amount of time after a StartTrial (e.g. more than 2 sec). All components are started after the Orchestrator is running. Note that what constitutes a \"reasonable\" amount of time is dependent on many variables and the numbers given here are only vaguely safe values for most systems. It is generally understood that most actors do not know when a trial will end. Because of this, there may be unpredictable behavior at the end of a trial: Rewards and messages sent after the last action may not reach their destination. If a trial is terminated by the Control API, actions from some actors may not reach the environment before the end of the trial. Common types \u00b6 Most of the messages are defined in the common.proto file. ObservationSet is defined in environment.proto . VersionRequest \u00b6 Empty message to serve as the request for the Version procedure (present in all gRPC services defined in the Cogment API). message VersionRequest {} VersionInfo \u00b6 Reply message for the Version procedure (present in all gRPC services defined in the API). It contains a list of version information. The Cogment framework expects at least \"cogment-api\" and \"grpc\" versions present in the list. The \"cogment-api\" is for the local version of the Cogment API used by the service. The \"grpc\" is for the version of gRPC used by the service. Other reported versions are specific to the service called, possibly for use by utility and management tools. message Version { string name = 1 ; string version = 2 ; } message VersionInfo { repeated Version versions = 1 ; } versions: List of version information name: The name/software/module for which the version is given. E.g. \"cogment-api\" version: The version related to the name. E.g. \"1.0.0b5\" TrialParams \u00b6 Global parameters for a trial. message TrialParams { TrialConfig trial_config = 1 ; EnvironmentParams environment = 2 ; repeated ActorParams actors = 3 ; uint32 max_steps = 4 ; uint32 max_inactivity = 5 ; } trial_config: (optional) The user config for the controler of the trial. environment: The parameters for the environment of the trial. actors: The parameters for all actors involved in the trial. This length and order of this list defines the length and order of the lists of actors provided in different places in the API (e.g. actors_in_trial ), for the trial. max_steps: The maximum number of steps/ticks that the trial should run. After this number of steps/ticks, an end request will be sent to the environment. max_inactivity: The maximum amount of time (in seconds) that the trial should be without activity before an end request is sent to the environment (or the trial is forcefully terminated). Activity is defined as a message received by the Orchestrator from a user component. EnvironmentParams \u00b6 Parameters related to an environment. message EnvironmentParams { string endpoint = 1 ; EnvironmentConfig config = 2 ; string implementation = 3 ; } endpoint: The URL where the environment is being served. This is used by the Orchestrator to connect to the environment using the EnvironmentEndpoint gRPC service. config: (optional) The user config for the environment. implementation: (optional) The name of the implementation of the environment to run. ActorParams \u00b6 Parameters related to an actor. message ActorParams { string name = 1 ; string actor_class = 2 ; string endpoint = 3 ; string implementation = 4 ; ActorConfig config = 5 ; } name: The name of the actor. actor_class: The name of the class of actor. Actor classes are defined in the cogment.yaml file in the actor_classes:id sections. endpoint: The URL where the actor is being served, or \"client\". The URL is used by the Orchestrator to connect to the actor using the AgentEndpoint gRPC service. If set to \"client\", then the actor is a client and will connect to the Orchestrator instead, using the ClientActor gRPC service. implementation: (optional) The name of the implementation of the actor class to run. config: (optional) The user config for the actor. TrialConfig , ActorConfig , EnvironmentConfig \u00b6 These contain the config data for various user components. message EnvironmentConfig { bytes content = 1 ; } message ActorConfig { bytes content = 1 ; } message TrialConfig { bytes content = 1 ; } content: The serialized protobuf message representing a config. The actual message type is defined in the cogment.yaml file in its respective section: environment:config_type , actor_classes:config_type , and trial:config_type . Environment config is for use by environments. Actor config is for use by actors (each actor class can have a different config type). Trial config is for use by controlers. TrialActor \u00b6 Details of an actor participating in a trial. message TrialActor { string actor_class = 1 ; string name = 2 ; } actor_class: The name of the class of actor. Actor classes are defined in the cogment.yaml file in the actor_classes:id sections. name: The name of the actor. Observation \u00b6 A singular observation. message Observation { uint64 tick_id = 1 ; fixed64 timestamp = 2 ; ObservationData data = 3 ; } tick_id: The monotonic Time, related to the number of observations since the start of the trial. timestamp: The wall-clock time of the observation. data: The observation data. ObservationData \u00b6 The data payload of an observation. message ObservationData { bytes content = 1 ; bool snapshot = 2 ; } content: The serialized protobuf message representing an observation for a specific actor. If the snapshot field value is true, the type of message is an observation space (i.e. a full observation snapshot) defined in section actor_classes:observation:space of the cogment.yaml file. If the snapshot field value is false, the type is an observation delta (i.e. a difference from a previous observation) defined in the section actor_classes:observation:delta of the cogment.yaml file. Note that the specific actor represented is defined by the enclosing message. snapshot: Determines the type of the message in the content field. Action \u00b6 Data associated with an actor's action. message Action { bytes content = 1 ; uint64 tick_id = 2 ; } content: The serialized protobuf message representing an action from a specific actor. The actual message type for the action space is defined in the cogment.yaml file for each actor class in section actor_classes:action:space . Note that the specific actor represented is defined by the enclosing message. tick_id: The tick ID of the observation on which the action is taken. Message \u00b6 Data associated with a communication (message) destined for an actor or the environment. message Message { sint64 tick_id = 1 ; string sender_name = 2 ; string receiver_name = 3 ; google.protobuf.Any payload = 4 ; } tick_id: Time associated with the message. sender_name: The name of the sending actor. \"env\" for the environment. This is optional when sending messages (i.e. the sender is already known). receiver_name: The name of the target/receiving actor. \"env\" for the environment. payload: Data for the target actor/environment. It is the responsibility of the target to understand the type received. RewardSource \u00b6 Data representing a simple reward source made by a single component/sender, usually for the purpose of training automated agents. message RewardSource { string sender_name = 1 ; float value = 2 ; float confidence = 3 ; google.protobuf.Any user_data = 4 ; } sender_name: Name of the sender that sent the reward. This is not needed when sending becasue it will be set by the orchestrator. It is only used by receiving actors. value: The numerical value of the provided reward. confidence: The weight of this reward in computing the final (aggregated) reward. user_data: Additional user data to be consumed by the receiving actor. It is the responsibility of the receiver to understand the type received. Reward \u00b6 Data representing a reward sent or received, usually for the purpose of training automated agents. This is an aggregate of possibly multiple RewardSource (but at least one). message Reward { string receiver_name = 1 ; sint64 tick_id = 2 ; float value = 3 ; repeated RewardSource sources = 4 ; } receiver_name: Name of the receiving actor (the reward destination). tick_id: The time step associated with the reward. If set to -1 when sending a reward, the orchestrator will automatically assign the latest tick. This will always be a valid tick when receiving a reward. value: The aggregated value (weighted sum) of the provided reward sources. May be ignored when sending a reward; The final value will be computed by the orchestrator. sources: The simple reward sources that form this aggregated reward. There must be at least one. ActorPeriodData \u00b6 Timely trial data sent to an actor. The data may span a period of time. message ActorPeriodData { repeated Observation observations = 1 ; repeated Reward rewards = 2 ; repeated Message messages = 3 ; } observations: Observations from the environment for a period of time. Typically only for one time step (tick). If there are multiple, they are ordered by tick_id. rewards: List of rewards sent by actors or the environment. Ordered by tick_id. messages: List of user data sent by actors or the environment. Ordered by tick_id. ObservationSet \u00b6 A set of environment observations for all actors in the trial. message ObservationSet { uint64 tick_id = 1 ; fixed64 timestamp = 2 ; repeated ObservationData observations = 3 ; repeated int32 actors_map = 4 ; } tick_id: The time step (tick) to which the observations relate to. timestamp: A wall clock time stamp when the observation set was made. Unix Epoch in nanoseconds. observations: A list of observations. Indexed into by the actors_map . actors_map: A list of indexes into the observations list above. This list of indexes has the same length and order as the list of actors provided in different places in the API (e.g. actors_in_trial ), for the same trial. Control API \u00b6 This API is defined in orchestrator.proto . It is implemented by the cogment orchestrator, and client applications are expected to connect to it using the gRPC client API. This API is used for general control and services related to trials. Service TrialLifecycle \u00b6 service TrialLifecycle { rpc StartTrial ( TrialStartRequest ) returns ( TrialStartReply ) {} rpc TerminateTrial ( TerminateTrialRequest ) returns ( TerminateTrialReply ) {} rpc GetTrialInfo ( TrialInfoRequest ) returns ( TrialInfoReply ) {} rpc WatchTrials ( TrialListRequest ) returns ( stream TrialListEntry ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} } StartTrial() \u00b6 Start a new trial. Metadata: None TerminateTrial() \u00b6 Request the environment to terminate an existing trial. Metadata: trial-id : UUID of the trial to terminate. GetTrialInfo() \u00b6 Get extra information about an existing trial. Metadata: trial-id : ( optional ) UUID of the trial to terminate. If not provided, the request is for informatrion about all running trials. WatchTrials() \u00b6 Stream state changes from trials. Metadata: None Version() \u00b6 Request version data. Metadata: None TrialStartRequest \u00b6 Request message for the StartTrial procedure. message TrialStartRequest { TrialConfig config = 1 ; string user_id = 2 ; } config: The trial config data. This data can be used by the pre-trial hooks to determine the config for the rest of the componenents. user_id: The ID of the user that is starting the trial. TrialStartReply \u00b6 Reply message for the StartTrial procedure. message TrialStartReply { string trial_id = 1 ; repeated TrialActor actors_in_trial = 2 ; } trial_id: UUID of the newly started trial. actors_in_trial: The list of all actors in the trial. This list has the same length and order as the list of actors provided in different places in the API, for the same trial. The list can be empty (or not present) in some circumstances, even if there are actors (if necessary the list can be obtained in other ways). TerminateTrialRequest \u00b6 Request message for the TerminateTrial procedure. message TerminateTrialRequest {} TerminateTrialReply \u00b6 Reply message for the TerminateTrial procedure. message TerminateTrialReply {} TrialInfoRequest \u00b6 Request message for the GetTrialInfo procedure. message TrialInfoRequest { bool get_latest_observation = 1 ; } get_latest_observation: If true, request the latest environment observation available for the trial (in addition to standard information). TrialInfoReply \u00b6 Reply message for the GetTrialInfo procedure. message TrialInfoReply { repeated TrialInfo trial = 1 ; } trial: List of information about the trials. Contains only the requested trial info if a trial ID was provided when the call was made (as metadata to the procedure). Otherwise contains information about all active trials. TrialState \u00b6 Enum representing the state of a trial. enum TrialState { UNKNOWN = 0 ; INITIALIZING = 1 ; PENDING = 2 ; RUNNING = 3 ; TERMINATING = 4 ; ENDED = 5 ; } UNKNOWN: Should not be used (requirements of protobuf enums to have a 0 default value). INITIALIZING: The trial is in the process of starting. PENDING: The trial is waiting for its final parameters, before running. RUNNING: The trial is running. TERMINATING: The trial is in the process of terminating (either a request to terminate has been received or the last observation has been received). ENDED: The trial has ended. Only a set number of ended trials will be kept (configured in the Orchestrator). TrialInfo \u00b6 Message containing information about a trial. message TrialInfo { string trial_id = 1 ; TrialState state = 2 ; uint64 tick_id = 3 ; fixed64 trial_duration = 4 ; ObservationSet latest_observation = 3 ; repeated TrialActor actors_in_trial = 6 ; } trial_id: The UUID of the trial. state: The state of the trial. tick_id: The current tick ID of the trial. trial_duration: The duration of the trial so far, in nanoseconds. If the trial has ended, this is the duration from start to end of the trial. This is meant as an indicator; resolution may not be a nanosecond, and precision is not garanteed. latest_observation: The latest environment observations for all actors. This will be provided only if requested in the TrialInfoRequest . actors_in_trial: The list of active actors in the trial. TrialListRequest \u00b6 Request message for the WatchTrials procedure. message TrialListRequest { repeated TrialState filter = 1 ; } filter: The list of states that are requested. If a trial is not in a state found in this list, it will not be reported. If the list is empty, all states will be reported. TrialListEntry \u00b6 Stream reply message for the WatchTrials procedure. message TrialListEntry { string trial_id = 1 ; TrialState state = 2 ; } trial_id: The UUID of the trial. state: The state of the trial. Client Actor API \u00b6 This API is defined in orchestrator.proto . It is implemented by the cogment orchestrator, and client applications are expected to connect to the orchestrator using the gRPC client API. This API is used by client actors participating in existing trials. Multiple simultaneous actors can connect using a single client application instance. The actors connecting this way must have an endpoint set to \"client\" in the trial parameters . Service ClientActor \u00b6 service ClientActor { rpc JoinTrial ( TrialJoinRequest ) returns ( TrialJoinReply ) {} rpc ActionStream ( stream TrialActionRequest ) returns ( stream TrialActionReply ) {} rpc Heartbeat ( TrialHeartbeatRequest ) returns ( TrialHeartbeatReply ) {} rpc SendReward ( TrialRewardRequest ) returns ( TrialRewardReply ) {} rpc SendMessage ( TrialMessageRequest ) returns ( TrialMessageReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} } JoinTrial() \u00b6 Join an existing trial. Metadata: None ActionStream() \u00b6 Main call to participate in the trial. It is typically active for the duration of the trial. Actor actions are provided to the orchestrator in the request stream, and trial data is provided by the orchestrator in the reply stream. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply. Heartbeat() \u00b6 This should be called on a regular basis (at least every 30 seconds), if there are no actions sent in the ActionStream . Otherwise the actor will be considered terminated and be disconnected. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply. SendReward() \u00b6 Used to provide feedback to other actors in the same trial as current actor. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply. SendMessage() \u00b6 Used to asynchronously send data to other actors (or the environment) in the same trial as current actor. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply. Version() \u00b6 Request version data. Metadata: None TrialJoinRequest \u00b6 Request message for the JoinTrial procedure. message TrialJoinRequest { string trial_id = 1 ; oneof slot_selection { string actor_class = 2 ; string actor_name = 3 ; } } trial_id: The UUID of the trial the actor requests to join. actor_class: The class the actor requests to join as. No actor name should be requested if this is used. actor_name: The name the actor requests to join as. No actor class should be requested if this is used. TrialJoinReply \u00b6 Reply message for the JoinTrial procedure. message TrialJoinReply { string actor_name = 1 ; string trial_id = 2 ; ActorConfig config = 3 ; repeated TrialActor actors_in_trial = 4 ; } actor_name: The name assignbed to the current actor in joining the trial. trial_id: The UUID of the trial joined. config: The configuration to start the actor. actors_in_trial: The list of all actors in the trial (including current actor). This list has the same length and order as the list of actors provided in different places in the API, for the same trial. The list can be empty (or not present) in some circumstances, even if there are actors (if necessary the list can be obtained in other ways). TrialHeartbeatRequest \u00b6 Request message for the Heartbeat procedure. message TrialHeartbeatRequest {} TrialHeartbeatReply \u00b6 Reply message for the Heartbeat procedure. message TrialHeartbeatReply {} TrialActionRequest \u00b6 Stream request message for the ActionStream procedure. message TrialActionRequest { Action action = 1 ; } action: The action taken by the current actor. This is typically in response to an observation (from the reply message). The first action after joining a trial (before any observations have been received) should be empty. TrialActionReply \u00b6 Stream reply message for the ActionStream procedure. message TrialActionReply { ActorPeriodData data = 1 ; bool final_data = 2 ; } data: The trial data for the current actor. This data can span a period of time, but is typically for one time step (tick). final_data: If this is true, the data provided is final and no more reply messages will be received after this one. TrialRewardRequest \u00b6 Request message for the SendReward procedure. message TrialRewardRequest { repeated Reward rewards = 1 ; } rewards: The rewards to send to one or more actors. TrialRewardReply \u00b6 Reply message for the SendReward procedure. message TrialRewardReply {} TrialMessageRequest \u00b6 Request message for the SendMessage procedure. message TrialMessageRequest { repeated Message messages = 1 ; } messages: User data to send to other actors or the environment. The sender_name entry should not be set (it is part of the metadata of the procedure). TrialMessageReply \u00b6 Reply message for the SendMessage procedure. message TrialMessageReply {} Agent Actor API \u00b6 This API is defined in agent.proto . It is implemented by the agent application using the gRPC server API, and the orchestrator connects to the agent application. This API is used by agent actors that will be participating in new trials. Multiple simultaneous agent actors can be served from a single agent application instance. An actor endpoint, for the orchestrator to connect to, is defined in the trial parameters . Service AgentEndpoint \u00b6 service AgentEndpoint { rpc OnStart ( AgentStartRequest ) returns ( AgentStartReply ) {} rpc OnObservation ( stream AgentObservationRequest ) returns ( stream AgentActionReply ) {} rpc OnReward ( AgentRewardRequest ) returns ( AgentRewardReply ) {} rpc OnMessage ( AgentMessageRequest ) returns ( AgentMessageReply ) {} rpc OnEnd ( AgentEndRequest ) returns ( AgentEndReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} } OnStart() \u00b6 Called when a new trial is started. Metadata: trial-id : UUID of the new trial the actor is participating in. actor-name : The name the actor has been assigned in the new trial. OnObservation() \u00b6 Called when a new observation from the environment is available. Metadata: trial-id : UUID of the trial that is the source of the data. actor-name : The name of the actor for which the data is intended. OnReward() \u00b6 Called when a new reward is available. Metadata: trial-id : UUID of the trial that is the source of the data. actor-name : The name of the actor for which the data is intended. OnMessage() \u00b6 Called when new user data (messages) is available. Metadata: trial-id : UUID of the trial that is the source of the data. actor-name : The name of the actor for which the data is intended. OnEnd() \u00b6 Called at the end of the trial. No more calls will be done related to the trial after this call. Metadata: trial-id : UUID of the trial that ended. actor-name : The name of the actor for which the data is intended. Version() \u00b6 Called to request version data. Metadata: None AgentStartRequest \u00b6 Request message for the OnStart procedure. message AgentStartRequest { string impl_name = 1 ; ActorConfig config = 2 ; repeated TrialActor actors_in_trial = 3 ; } impl_name: (optional) Name of the implementation that should run the actor in this trial. If not provided, an arbitrary implementation will be used. config: The configuration to start the actor. actors_in_trial: The list of all actors in the trial (including current actor). This list has the same length and order as the list of actors provided in different places in the API, for the same trial. The list can be empty (or not present) in some circumstances, even if there are actors (if necessary the list can be obtained in other ways). AgentStartReply \u00b6 Reply message for the OnStart procedure. message AgentStartReply {} AgentObservationRequest \u00b6 Request message for the OnObservation procedure. message AgentObservationRequest { Observation observation = 1 ; } observation: An observation from the environment. AgenActionReply \u00b6 Reply message for the OnObservation procedure. message AgentActionReply { Action action = 1 ; repeated Reward rewards = 2 ; repeated Message messages = 3 ; } action: An action for the environment. rewards: Rewards for other actors. messages: User data to send to other actors or the environment. The sender_name entry should not be set. AgentRewardRequest \u00b6 Request message for the OnReward procedure. message AgentRewardRequest { Reward reward = 1 ; } reward: Reward received from aggregating various rewards from actors or the environment. AgentRewardReply \u00b6 Reply message for the OnReward procedure. message AgentRewardReply {} AgentMessageRequest \u00b6 Request message for the OnMessage procedure. message AgentMessageRequest { repeated Message messages = 1 ; } messages: List of messages from actors or the environment. AgentMessageReply \u00b6 Reply message for the OnMessage procedure. message AgentMessageReply {} AgentEndRequest \u00b6 Request message for the OnEnd procedure. message AgentEndRequest { ActorPeriodData final_data = 1 ; } final_data: The final (last) data for the trial. AgentEndReply \u00b6 Reply message for the OnEnd procedure. message AgentEndReply {} Environment API \u00b6 This API is defined in environment.proto . It is implemented by the environment application using the gRPC server API, and the orchestrator connects to the environment application. This API is used by environments that will run trials. There is only one environment per trial. Multiple simultaneous environments can be served from a single environment application instance (for different trials). The environment endpoint, for the orchestrator to connect to, is defined in the trial parameters . Service EnvironmentEndpoint \u00b6 service EnvironmentEndpoint { rpc OnStart ( EnvStartRequest ) returns ( EnvStartReply ) {} rpc OnAction ( stream EnvActionRequest ) returns ( stream EnvActionReply ) {} rpc OnMessage ( EnvMessageRequest ) returns ( EnvMessageReply ) {} rpc OnEnd ( EnvActionRequest ) returns ( EnvActionReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} } OnStart() \u00b6 Called when a new trial is started. Metadata: trial-id : UUID of the new trial the environment is running. OnAction() \u00b6 Called when a set of actions from actors is available. Metadata: trial-id : UUID of the trial that is the source of the data. OnMessage() \u00b6 Called when user data from actors is received. Metadata: trial-id : UUID of the trial that is the source of the data. OnEnd() \u00b6 Called to request the end of the trial. If no reply is sent within a pre-determined time, the environment is considered stalled, and the trial will force terminate. Metadata: trial-id : UUID of the trial to end. Version() \u00b6 Called to request version data. Metadata: None EnvStartRequest \u00b6 Request message for the OnStart procedure. message EnvStartRequest { string impl_name = 1 ; EnvironmentConfig config = 2 ; repeated TrialActor actors_in_trial = 3 ; uint64 tick_id = 4 ; } impl_name: (optional) Name of the implementation that should run the environment for this trial. If not provided, an arbitrary implementation will be used. config: The configuration to start the environment. actors_in_trial: The list of all actors in the trial. This list has the same length and order as the list of actors provided in different places in the API, for the same trial. tick_id: The expected tick ID of the observation set returned in EnvStartReply . EnvStartReply \u00b6 Reply message for the OnStart procedure. message EnvStartReply { ObservationSet observation_set = 1 ; } observation_set: A set of observations for all actors of the trial. EnvActionRequest \u00b6 Request message for the OnAction and OnEnd procedures. message ActionSet { repeated bytes actions = 1 ; uint64 tick_id = 2 ; } message EnvActionRequest { ActionSet action_set = 1 ; bool reply_with_snapshot = 2 ; } actions: A list of actions, one for each actor of the trial. This list has the same length and order as the list of actors provided in different places in the API (e.g. actors_in_trial ), for the same trial. Each action is the serialization of the appropriate type for the actor (as defined in the cogment.yaml file). tick_id: The tick ID of the observations on which the actions are taken. action_set: The set of actions for all actors. reply_with_snapshot: If true, then request that the observations for the actors (in the reply) be snapshots. If false, the observations can be snapshots or deltas (at the discretion of the environment). See ObservationData . EnvActionReply \u00b6 Reply message for the OnAction and OnEnd procedures. message EnvActionReply { ObservationSet observation_set = 1 ; repeated Reward rewards = 2 ; repeated Message messages = 3 ; bool final_update = 4 ; } observation_set: A set of observations for all actors of the trial. rewards: A list of rewards for actors. messages: User data to send to actors. The sender_name entry should not be set. messages: A list of messages for actors. The sender actor entry should not be filled. final_update: If true, this will be the final update of the environment for this trial (i.e. end of the trial). This should always be true when replying to an OnEnd procedure call. EnvMessageRequest \u00b6 Request message for the OnMessage procedure. message EnvMessageRequest { repeated Message messages = 1 ; } messages: List of messages from actors. EnvMessageReply \u00b6 Reply message for the OnMessage procedure. message EnvMessageReply {} Data/Log API \u00b6 This API is defined in datalog.proto . It is implemented by the data logger application using the gRPC server API, and the orchestrator connects to the data logger application. The data logger endpoint, for the orchestrator to connect to, is defined in the cogment.yaml file. Service LogExporter \u00b6 service LogExporter { rpc OnLogSample ( stream LogExporterSampleRequest ) returns ( LogExporterSampleReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} } OnLogSample() \u00b6 Called the first time a sample is available. This call will normally stay active as long as the orchestrator is running. If disconnected, the orchestrator will not reconnect unless restarted. Data samples are provided by the orchestrator in the request stream. Metadata: None Version() \u00b6 Called to request version data. Metadata: None LogExporterSampleRequest \u00b6 Stream request message for the OnLogSample procedure. message DatalogSample { string user_id = 1 ; ObservationSet observations = 2 ; repeated Action actions = 3 ; repeated Reward rewards = 4 ; repeated Message messages = 5 ; } message LogExporterSampleRequest { oneof msg { TrialParams trial_params = 1 ; DatalogSample sample = 2 ; } } user_id: The ID of the user that started the trial. observations: A set of observations for all actors. actions: Actions from all actors. This list has the same length and order as the list of actors provided in different places in the API (e.g. actors_in_trial ), for the same trial. Of interest here; it matches the list of actors provided in trial_params . rewards: List of rewards sent to actors. messages: List of user data sent to actors or the environment. trial_params: Trial params used for a new trial. This is usually sent on start of a trial before any other sample from the trial. sample: A data sample to be logged. LogExporterSampleReply \u00b6 Reply message for the OnLogSample procedure. message LogExporterSampleReply {} Hook API \u00b6 This API is defined in hooks.proto . It is implemented by the pre-trial hook application using the gRPC server API, and the orchestrator connects to the application. The pre-trial hook endpoint, for the orchestrator to connect to, is defined in the cogment.yaml file. Service TrialHooks \u00b6 service TrialHooks { rpc OnPreTrial ( PreTrialContext ) returns ( PreTrialContext ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} } OnPreTrial() \u00b6 Called before a trial is started to set or modify the parameters for the trial. Metadata: trial-id : UUID of the new trial that will be started. Version() \u00b6 Called to request version data. Metadata: None PreTrialContext \u00b6 Request and reply message for the OnPreTrial procedure. message PreTrialContext { string impl_name = 1 ; TrialParams params = 2 ; string user_id = 3 ; } impl_name: (optional) Name of the implementation that should run the hook. If not provided, an arbitrary implementation will be used. Set on a request, ignored when replying. params: The trial parameters so far. The first hook to be called will receive the default parameters present in the cogment.yaml file, and subsequent hooks will receive the parameters sent from the previous hook. Typically, changes are made to this data and the message sent as a reply. user_id: The ID of the user that is starting the trial. Set on a request, ignored when replying.","title":"gRPC API Reference"},{"location":"cogment/cogment-low-level-api-guide/grpc/#cogment-grpc-api","text":"The low-level cogment communication API is implemented using gRPC services. These services are collections of procedures to be called remotely (RPC). gRPC abstracts the network communication with familiar looking functions (representing the defined procedures), in any number of programming languages. How services are implemented or accessed is highly dependant on the programming language being interfaced, and is beyond the scope of this document (see gRPC API documentation). This reference requires a basic understanding of gRPC, and in particular the format of the proto files.","title":"Cogment gRPC API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#general","text":"In this API, the bytes data type is normally used to contain the serialized data of externally defined messages. These messages are well defined in the cogment.yaml file. On the other hand, the google.protobuf.Any data type is normally used to contain messages that are not pre-defined, and may be decided at runtime. Empty messages are normally used as a placeholder for easy future, backward compatible, extension of the API. In this API, gRPC metadata is normally used only for service request (procedure calls) for identifying purposes. The details of the required metadata are described with the service calls. Service replies are not expecting to provide metadata. In many places in the API, we use a list of actor data without information about which actor is where in the list. These lists have a constant length and order throughout a trial (set in the trial parameters), and thus can/must be cross referenced with other such lists within the same trial (e.g. actors_in_trial , actors_map ). The actor can be infered by the position in the list, and the index into the list can sometimes be used to identify an actor.","title":"General"},{"location":"cogment/cogment-low-level-api-guide/grpc/#limitations","text":"Due to normal network delays and unpredictability of the various componenents, there are limitations related to the communication with the Ochestrator that translate in issues that can arise. In the current version, to simplify the implementation, there is an expectation of \"good behavior\" from the various components: Actors are expected to respond with an action only after receiving an observation, and to send only one action per observation received. The environment is expected to respond with an observation set only after receiving an action set, and to send only one observation set per action set received. All components are expected to respond within a reasonable time (e.g. less than 5 sec). Hooks do not assume to receive specific parameters, reply only with well formed parameters, and do not assume a specific order of hooks being called (when multiple hooks are defined). A TerminateTrial (from the Control API) is called only a reasonable amount of time after a StartTrial (e.g. more than 2 sec). All components are started after the Orchestrator is running. Note that what constitutes a \"reasonable\" amount of time is dependent on many variables and the numbers given here are only vaguely safe values for most systems. It is generally understood that most actors do not know when a trial will end. Because of this, there may be unpredictable behavior at the end of a trial: Rewards and messages sent after the last action may not reach their destination. If a trial is terminated by the Control API, actions from some actors may not reach the environment before the end of the trial.","title":"Limitations"},{"location":"cogment/cogment-low-level-api-guide/grpc/#common-types","text":"Most of the messages are defined in the common.proto file. ObservationSet is defined in environment.proto .","title":"Common types"},{"location":"cogment/cogment-low-level-api-guide/grpc/#versionrequest","text":"Empty message to serve as the request for the Version procedure (present in all gRPC services defined in the Cogment API). message VersionRequest {}","title":"VersionRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#versioninfo","text":"Reply message for the Version procedure (present in all gRPC services defined in the API). It contains a list of version information. The Cogment framework expects at least \"cogment-api\" and \"grpc\" versions present in the list. The \"cogment-api\" is for the local version of the Cogment API used by the service. The \"grpc\" is for the version of gRPC used by the service. Other reported versions are specific to the service called, possibly for use by utility and management tools. message Version { string name = 1 ; string version = 2 ; } message VersionInfo { repeated Version versions = 1 ; } versions: List of version information name: The name/software/module for which the version is given. E.g. \"cogment-api\" version: The version related to the name. E.g. \"1.0.0b5\"","title":"VersionInfo"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialparams","text":"Global parameters for a trial. message TrialParams { TrialConfig trial_config = 1 ; EnvironmentParams environment = 2 ; repeated ActorParams actors = 3 ; uint32 max_steps = 4 ; uint32 max_inactivity = 5 ; } trial_config: (optional) The user config for the controler of the trial. environment: The parameters for the environment of the trial. actors: The parameters for all actors involved in the trial. This length and order of this list defines the length and order of the lists of actors provided in different places in the API (e.g. actors_in_trial ), for the trial. max_steps: The maximum number of steps/ticks that the trial should run. After this number of steps/ticks, an end request will be sent to the environment. max_inactivity: The maximum amount of time (in seconds) that the trial should be without activity before an end request is sent to the environment (or the trial is forcefully terminated). Activity is defined as a message received by the Orchestrator from a user component.","title":"TrialParams"},{"location":"cogment/cogment-low-level-api-guide/grpc/#environmentparams","text":"Parameters related to an environment. message EnvironmentParams { string endpoint = 1 ; EnvironmentConfig config = 2 ; string implementation = 3 ; } endpoint: The URL where the environment is being served. This is used by the Orchestrator to connect to the environment using the EnvironmentEndpoint gRPC service. config: (optional) The user config for the environment. implementation: (optional) The name of the implementation of the environment to run.","title":"EnvironmentParams"},{"location":"cogment/cogment-low-level-api-guide/grpc/#actorparams","text":"Parameters related to an actor. message ActorParams { string name = 1 ; string actor_class = 2 ; string endpoint = 3 ; string implementation = 4 ; ActorConfig config = 5 ; } name: The name of the actor. actor_class: The name of the class of actor. Actor classes are defined in the cogment.yaml file in the actor_classes:id sections. endpoint: The URL where the actor is being served, or \"client\". The URL is used by the Orchestrator to connect to the actor using the AgentEndpoint gRPC service. If set to \"client\", then the actor is a client and will connect to the Orchestrator instead, using the ClientActor gRPC service. implementation: (optional) The name of the implementation of the actor class to run. config: (optional) The user config for the actor.","title":"ActorParams"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialconfig-actorconfig-environmentconfig","text":"These contain the config data for various user components. message EnvironmentConfig { bytes content = 1 ; } message ActorConfig { bytes content = 1 ; } message TrialConfig { bytes content = 1 ; } content: The serialized protobuf message representing a config. The actual message type is defined in the cogment.yaml file in its respective section: environment:config_type , actor_classes:config_type , and trial:config_type . Environment config is for use by environments. Actor config is for use by actors (each actor class can have a different config type). Trial config is for use by controlers.","title":"TrialConfig, ActorConfig, EnvironmentConfig"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialactor","text":"Details of an actor participating in a trial. message TrialActor { string actor_class = 1 ; string name = 2 ; } actor_class: The name of the class of actor. Actor classes are defined in the cogment.yaml file in the actor_classes:id sections. name: The name of the actor.","title":"TrialActor"},{"location":"cogment/cogment-low-level-api-guide/grpc/#observation","text":"A singular observation. message Observation { uint64 tick_id = 1 ; fixed64 timestamp = 2 ; ObservationData data = 3 ; } tick_id: The monotonic Time, related to the number of observations since the start of the trial. timestamp: The wall-clock time of the observation. data: The observation data.","title":"Observation"},{"location":"cogment/cogment-low-level-api-guide/grpc/#observationdata","text":"The data payload of an observation. message ObservationData { bytes content = 1 ; bool snapshot = 2 ; } content: The serialized protobuf message representing an observation for a specific actor. If the snapshot field value is true, the type of message is an observation space (i.e. a full observation snapshot) defined in section actor_classes:observation:space of the cogment.yaml file. If the snapshot field value is false, the type is an observation delta (i.e. a difference from a previous observation) defined in the section actor_classes:observation:delta of the cogment.yaml file. Note that the specific actor represented is defined by the enclosing message. snapshot: Determines the type of the message in the content field.","title":"ObservationData"},{"location":"cogment/cogment-low-level-api-guide/grpc/#action","text":"Data associated with an actor's action. message Action { bytes content = 1 ; uint64 tick_id = 2 ; } content: The serialized protobuf message representing an action from a specific actor. The actual message type for the action space is defined in the cogment.yaml file for each actor class in section actor_classes:action:space . Note that the specific actor represented is defined by the enclosing message. tick_id: The tick ID of the observation on which the action is taken.","title":"Action"},{"location":"cogment/cogment-low-level-api-guide/grpc/#message","text":"Data associated with a communication (message) destined for an actor or the environment. message Message { sint64 tick_id = 1 ; string sender_name = 2 ; string receiver_name = 3 ; google.protobuf.Any payload = 4 ; } tick_id: Time associated with the message. sender_name: The name of the sending actor. \"env\" for the environment. This is optional when sending messages (i.e. the sender is already known). receiver_name: The name of the target/receiving actor. \"env\" for the environment. payload: Data for the target actor/environment. It is the responsibility of the target to understand the type received.","title":"Message"},{"location":"cogment/cogment-low-level-api-guide/grpc/#rewardsource","text":"Data representing a simple reward source made by a single component/sender, usually for the purpose of training automated agents. message RewardSource { string sender_name = 1 ; float value = 2 ; float confidence = 3 ; google.protobuf.Any user_data = 4 ; } sender_name: Name of the sender that sent the reward. This is not needed when sending becasue it will be set by the orchestrator. It is only used by receiving actors. value: The numerical value of the provided reward. confidence: The weight of this reward in computing the final (aggregated) reward. user_data: Additional user data to be consumed by the receiving actor. It is the responsibility of the receiver to understand the type received.","title":"RewardSource"},{"location":"cogment/cogment-low-level-api-guide/grpc/#reward","text":"Data representing a reward sent or received, usually for the purpose of training automated agents. This is an aggregate of possibly multiple RewardSource (but at least one). message Reward { string receiver_name = 1 ; sint64 tick_id = 2 ; float value = 3 ; repeated RewardSource sources = 4 ; } receiver_name: Name of the receiving actor (the reward destination). tick_id: The time step associated with the reward. If set to -1 when sending a reward, the orchestrator will automatically assign the latest tick. This will always be a valid tick when receiving a reward. value: The aggregated value (weighted sum) of the provided reward sources. May be ignored when sending a reward; The final value will be computed by the orchestrator. sources: The simple reward sources that form this aggregated reward. There must be at least one.","title":"Reward"},{"location":"cogment/cogment-low-level-api-guide/grpc/#actorperioddata","text":"Timely trial data sent to an actor. The data may span a period of time. message ActorPeriodData { repeated Observation observations = 1 ; repeated Reward rewards = 2 ; repeated Message messages = 3 ; } observations: Observations from the environment for a period of time. Typically only for one time step (tick). If there are multiple, they are ordered by tick_id. rewards: List of rewards sent by actors or the environment. Ordered by tick_id. messages: List of user data sent by actors or the environment. Ordered by tick_id.","title":"ActorPeriodData"},{"location":"cogment/cogment-low-level-api-guide/grpc/#observationset","text":"A set of environment observations for all actors in the trial. message ObservationSet { uint64 tick_id = 1 ; fixed64 timestamp = 2 ; repeated ObservationData observations = 3 ; repeated int32 actors_map = 4 ; } tick_id: The time step (tick) to which the observations relate to. timestamp: A wall clock time stamp when the observation set was made. Unix Epoch in nanoseconds. observations: A list of observations. Indexed into by the actors_map . actors_map: A list of indexes into the observations list above. This list of indexes has the same length and order as the list of actors provided in different places in the API (e.g. actors_in_trial ), for the same trial.","title":"ObservationSet"},{"location":"cogment/cogment-low-level-api-guide/grpc/#control-api","text":"This API is defined in orchestrator.proto . It is implemented by the cogment orchestrator, and client applications are expected to connect to it using the gRPC client API. This API is used for general control and services related to trials.","title":"Control API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#service-triallifecycle","text":"service TrialLifecycle { rpc StartTrial ( TrialStartRequest ) returns ( TrialStartReply ) {} rpc TerminateTrial ( TerminateTrialRequest ) returns ( TerminateTrialReply ) {} rpc GetTrialInfo ( TrialInfoRequest ) returns ( TrialInfoReply ) {} rpc WatchTrials ( TrialListRequest ) returns ( stream TrialListEntry ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} }","title":"Service TrialLifecycle"},{"location":"cogment/cogment-low-level-api-guide/grpc/#starttrial","text":"Start a new trial. Metadata: None","title":"StartTrial()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#terminatetrial","text":"Request the environment to terminate an existing trial. Metadata: trial-id : UUID of the trial to terminate.","title":"TerminateTrial()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#gettrialinfo","text":"Get extra information about an existing trial. Metadata: trial-id : ( optional ) UUID of the trial to terminate. If not provided, the request is for informatrion about all running trials.","title":"GetTrialInfo()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#watchtrials","text":"Stream state changes from trials. Metadata: None","title":"WatchTrials()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#version","text":"Request version data. Metadata: None","title":"Version()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialstartrequest","text":"Request message for the StartTrial procedure. message TrialStartRequest { TrialConfig config = 1 ; string user_id = 2 ; } config: The trial config data. This data can be used by the pre-trial hooks to determine the config for the rest of the componenents. user_id: The ID of the user that is starting the trial.","title":"TrialStartRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialstartreply","text":"Reply message for the StartTrial procedure. message TrialStartReply { string trial_id = 1 ; repeated TrialActor actors_in_trial = 2 ; } trial_id: UUID of the newly started trial. actors_in_trial: The list of all actors in the trial. This list has the same length and order as the list of actors provided in different places in the API, for the same trial. The list can be empty (or not present) in some circumstances, even if there are actors (if necessary the list can be obtained in other ways).","title":"TrialStartReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#terminatetrialrequest","text":"Request message for the TerminateTrial procedure. message TerminateTrialRequest {}","title":"TerminateTrialRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#terminatetrialreply","text":"Reply message for the TerminateTrial procedure. message TerminateTrialReply {}","title":"TerminateTrialReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialinforequest","text":"Request message for the GetTrialInfo procedure. message TrialInfoRequest { bool get_latest_observation = 1 ; } get_latest_observation: If true, request the latest environment observation available for the trial (in addition to standard information).","title":"TrialInfoRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialinforeply","text":"Reply message for the GetTrialInfo procedure. message TrialInfoReply { repeated TrialInfo trial = 1 ; } trial: List of information about the trials. Contains only the requested trial info if a trial ID was provided when the call was made (as metadata to the procedure). Otherwise contains information about all active trials.","title":"TrialInfoReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialstate","text":"Enum representing the state of a trial. enum TrialState { UNKNOWN = 0 ; INITIALIZING = 1 ; PENDING = 2 ; RUNNING = 3 ; TERMINATING = 4 ; ENDED = 5 ; } UNKNOWN: Should not be used (requirements of protobuf enums to have a 0 default value). INITIALIZING: The trial is in the process of starting. PENDING: The trial is waiting for its final parameters, before running. RUNNING: The trial is running. TERMINATING: The trial is in the process of terminating (either a request to terminate has been received or the last observation has been received). ENDED: The trial has ended. Only a set number of ended trials will be kept (configured in the Orchestrator).","title":"TrialState"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialinfo","text":"Message containing information about a trial. message TrialInfo { string trial_id = 1 ; TrialState state = 2 ; uint64 tick_id = 3 ; fixed64 trial_duration = 4 ; ObservationSet latest_observation = 3 ; repeated TrialActor actors_in_trial = 6 ; } trial_id: The UUID of the trial. state: The state of the trial. tick_id: The current tick ID of the trial. trial_duration: The duration of the trial so far, in nanoseconds. If the trial has ended, this is the duration from start to end of the trial. This is meant as an indicator; resolution may not be a nanosecond, and precision is not garanteed. latest_observation: The latest environment observations for all actors. This will be provided only if requested in the TrialInfoRequest . actors_in_trial: The list of active actors in the trial.","title":"TrialInfo"},{"location":"cogment/cogment-low-level-api-guide/grpc/#triallistrequest","text":"Request message for the WatchTrials procedure. message TrialListRequest { repeated TrialState filter = 1 ; } filter: The list of states that are requested. If a trial is not in a state found in this list, it will not be reported. If the list is empty, all states will be reported.","title":"TrialListRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#triallistentry","text":"Stream reply message for the WatchTrials procedure. message TrialListEntry { string trial_id = 1 ; TrialState state = 2 ; } trial_id: The UUID of the trial. state: The state of the trial.","title":"TrialListEntry"},{"location":"cogment/cogment-low-level-api-guide/grpc/#client-actor-api","text":"This API is defined in orchestrator.proto . It is implemented by the cogment orchestrator, and client applications are expected to connect to the orchestrator using the gRPC client API. This API is used by client actors participating in existing trials. Multiple simultaneous actors can connect using a single client application instance. The actors connecting this way must have an endpoint set to \"client\" in the trial parameters .","title":"Client Actor API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#service-clientactor","text":"service ClientActor { rpc JoinTrial ( TrialJoinRequest ) returns ( TrialJoinReply ) {} rpc ActionStream ( stream TrialActionRequest ) returns ( stream TrialActionReply ) {} rpc Heartbeat ( TrialHeartbeatRequest ) returns ( TrialHeartbeatReply ) {} rpc SendReward ( TrialRewardRequest ) returns ( TrialRewardReply ) {} rpc SendMessage ( TrialMessageRequest ) returns ( TrialMessageReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} }","title":"Service ClientActor"},{"location":"cogment/cogment-low-level-api-guide/grpc/#jointrial","text":"Join an existing trial. Metadata: None","title":"JoinTrial()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#actionstream","text":"Main call to participate in the trial. It is typically active for the duration of the trial. Actor actions are provided to the orchestrator in the request stream, and trial data is provided by the orchestrator in the reply stream. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply.","title":"ActionStream()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#heartbeat","text":"This should be called on a regular basis (at least every 30 seconds), if there are no actions sent in the ActionStream . Otherwise the actor will be considered terminated and be disconnected. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply.","title":"Heartbeat()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#sendreward","text":"Used to provide feedback to other actors in the same trial as current actor. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply.","title":"SendReward()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#sendmessage","text":"Used to asynchronously send data to other actors (or the environment) in the same trial as current actor. Metadata: trial-id : UUID of the trial the current actor is participating in. This comes from the JoinTrial reply. actor-name : The name of the current actor participating in the trial. This is supplied (or confirmed) in the JoinTrial reply.","title":"SendMessage()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#version_1","text":"Request version data. Metadata: None","title":"Version()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialjoinrequest","text":"Request message for the JoinTrial procedure. message TrialJoinRequest { string trial_id = 1 ; oneof slot_selection { string actor_class = 2 ; string actor_name = 3 ; } } trial_id: The UUID of the trial the actor requests to join. actor_class: The class the actor requests to join as. No actor name should be requested if this is used. actor_name: The name the actor requests to join as. No actor class should be requested if this is used.","title":"TrialJoinRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialjoinreply","text":"Reply message for the JoinTrial procedure. message TrialJoinReply { string actor_name = 1 ; string trial_id = 2 ; ActorConfig config = 3 ; repeated TrialActor actors_in_trial = 4 ; } actor_name: The name assignbed to the current actor in joining the trial. trial_id: The UUID of the trial joined. config: The configuration to start the actor. actors_in_trial: The list of all actors in the trial (including current actor). This list has the same length and order as the list of actors provided in different places in the API, for the same trial. The list can be empty (or not present) in some circumstances, even if there are actors (if necessary the list can be obtained in other ways).","title":"TrialJoinReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialheartbeatrequest","text":"Request message for the Heartbeat procedure. message TrialHeartbeatRequest {}","title":"TrialHeartbeatRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialheartbeatreply","text":"Reply message for the Heartbeat procedure. message TrialHeartbeatReply {}","title":"TrialHeartbeatReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialactionrequest","text":"Stream request message for the ActionStream procedure. message TrialActionRequest { Action action = 1 ; } action: The action taken by the current actor. This is typically in response to an observation (from the reply message). The first action after joining a trial (before any observations have been received) should be empty.","title":"TrialActionRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialactionreply","text":"Stream reply message for the ActionStream procedure. message TrialActionReply { ActorPeriodData data = 1 ; bool final_data = 2 ; } data: The trial data for the current actor. This data can span a period of time, but is typically for one time step (tick). final_data: If this is true, the data provided is final and no more reply messages will be received after this one.","title":"TrialActionReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialrewardrequest","text":"Request message for the SendReward procedure. message TrialRewardRequest { repeated Reward rewards = 1 ; } rewards: The rewards to send to one or more actors.","title":"TrialRewardRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialrewardreply","text":"Reply message for the SendReward procedure. message TrialRewardReply {}","title":"TrialRewardReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialmessagerequest","text":"Request message for the SendMessage procedure. message TrialMessageRequest { repeated Message messages = 1 ; } messages: User data to send to other actors or the environment. The sender_name entry should not be set (it is part of the metadata of the procedure).","title":"TrialMessageRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#trialmessagereply","text":"Reply message for the SendMessage procedure. message TrialMessageReply {}","title":"TrialMessageReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agent-actor-api","text":"This API is defined in agent.proto . It is implemented by the agent application using the gRPC server API, and the orchestrator connects to the agent application. This API is used by agent actors that will be participating in new trials. Multiple simultaneous agent actors can be served from a single agent application instance. An actor endpoint, for the orchestrator to connect to, is defined in the trial parameters .","title":"Agent Actor API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#service-agentendpoint","text":"service AgentEndpoint { rpc OnStart ( AgentStartRequest ) returns ( AgentStartReply ) {} rpc OnObservation ( stream AgentObservationRequest ) returns ( stream AgentActionReply ) {} rpc OnReward ( AgentRewardRequest ) returns ( AgentRewardReply ) {} rpc OnMessage ( AgentMessageRequest ) returns ( AgentMessageReply ) {} rpc OnEnd ( AgentEndRequest ) returns ( AgentEndReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} }","title":"Service AgentEndpoint"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onstart","text":"Called when a new trial is started. Metadata: trial-id : UUID of the new trial the actor is participating in. actor-name : The name the actor has been assigned in the new trial.","title":"OnStart()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onobservation","text":"Called when a new observation from the environment is available. Metadata: trial-id : UUID of the trial that is the source of the data. actor-name : The name of the actor for which the data is intended.","title":"OnObservation()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onreward","text":"Called when a new reward is available. Metadata: trial-id : UUID of the trial that is the source of the data. actor-name : The name of the actor for which the data is intended.","title":"OnReward()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onmessage","text":"Called when new user data (messages) is available. Metadata: trial-id : UUID of the trial that is the source of the data. actor-name : The name of the actor for which the data is intended.","title":"OnMessage()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onend","text":"Called at the end of the trial. No more calls will be done related to the trial after this call. Metadata: trial-id : UUID of the trial that ended. actor-name : The name of the actor for which the data is intended.","title":"OnEnd()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#version_2","text":"Called to request version data. Metadata: None","title":"Version()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentstartrequest","text":"Request message for the OnStart procedure. message AgentStartRequest { string impl_name = 1 ; ActorConfig config = 2 ; repeated TrialActor actors_in_trial = 3 ; } impl_name: (optional) Name of the implementation that should run the actor in this trial. If not provided, an arbitrary implementation will be used. config: The configuration to start the actor. actors_in_trial: The list of all actors in the trial (including current actor). This list has the same length and order as the list of actors provided in different places in the API, for the same trial. The list can be empty (or not present) in some circumstances, even if there are actors (if necessary the list can be obtained in other ways).","title":"AgentStartRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentstartreply","text":"Reply message for the OnStart procedure. message AgentStartReply {}","title":"AgentStartReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentobservationrequest","text":"Request message for the OnObservation procedure. message AgentObservationRequest { Observation observation = 1 ; } observation: An observation from the environment.","title":"AgentObservationRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agenactionreply","text":"Reply message for the OnObservation procedure. message AgentActionReply { Action action = 1 ; repeated Reward rewards = 2 ; repeated Message messages = 3 ; } action: An action for the environment. rewards: Rewards for other actors. messages: User data to send to other actors or the environment. The sender_name entry should not be set.","title":"AgenActionReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentrewardrequest","text":"Request message for the OnReward procedure. message AgentRewardRequest { Reward reward = 1 ; } reward: Reward received from aggregating various rewards from actors or the environment.","title":"AgentRewardRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentrewardreply","text":"Reply message for the OnReward procedure. message AgentRewardReply {}","title":"AgentRewardReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentmessagerequest","text":"Request message for the OnMessage procedure. message AgentMessageRequest { repeated Message messages = 1 ; } messages: List of messages from actors or the environment.","title":"AgentMessageRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentmessagereply","text":"Reply message for the OnMessage procedure. message AgentMessageReply {}","title":"AgentMessageReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentendrequest","text":"Request message for the OnEnd procedure. message AgentEndRequest { ActorPeriodData final_data = 1 ; } final_data: The final (last) data for the trial.","title":"AgentEndRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#agentendreply","text":"Reply message for the OnEnd procedure. message AgentEndReply {}","title":"AgentEndReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#environment-api","text":"This API is defined in environment.proto . It is implemented by the environment application using the gRPC server API, and the orchestrator connects to the environment application. This API is used by environments that will run trials. There is only one environment per trial. Multiple simultaneous environments can be served from a single environment application instance (for different trials). The environment endpoint, for the orchestrator to connect to, is defined in the trial parameters .","title":"Environment API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#service-environmentendpoint","text":"service EnvironmentEndpoint { rpc OnStart ( EnvStartRequest ) returns ( EnvStartReply ) {} rpc OnAction ( stream EnvActionRequest ) returns ( stream EnvActionReply ) {} rpc OnMessage ( EnvMessageRequest ) returns ( EnvMessageReply ) {} rpc OnEnd ( EnvActionRequest ) returns ( EnvActionReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} }","title":"Service EnvironmentEndpoint"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onstart_1","text":"Called when a new trial is started. Metadata: trial-id : UUID of the new trial the environment is running.","title":"OnStart()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onaction","text":"Called when a set of actions from actors is available. Metadata: trial-id : UUID of the trial that is the source of the data.","title":"OnAction()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onmessage_1","text":"Called when user data from actors is received. Metadata: trial-id : UUID of the trial that is the source of the data.","title":"OnMessage()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onend_1","text":"Called to request the end of the trial. If no reply is sent within a pre-determined time, the environment is considered stalled, and the trial will force terminate. Metadata: trial-id : UUID of the trial to end.","title":"OnEnd()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#version_3","text":"Called to request version data. Metadata: None","title":"Version()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#envstartrequest","text":"Request message for the OnStart procedure. message EnvStartRequest { string impl_name = 1 ; EnvironmentConfig config = 2 ; repeated TrialActor actors_in_trial = 3 ; uint64 tick_id = 4 ; } impl_name: (optional) Name of the implementation that should run the environment for this trial. If not provided, an arbitrary implementation will be used. config: The configuration to start the environment. actors_in_trial: The list of all actors in the trial. This list has the same length and order as the list of actors provided in different places in the API, for the same trial. tick_id: The expected tick ID of the observation set returned in EnvStartReply .","title":"EnvStartRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#envstartreply","text":"Reply message for the OnStart procedure. message EnvStartReply { ObservationSet observation_set = 1 ; } observation_set: A set of observations for all actors of the trial.","title":"EnvStartReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#envactionrequest","text":"Request message for the OnAction and OnEnd procedures. message ActionSet { repeated bytes actions = 1 ; uint64 tick_id = 2 ; } message EnvActionRequest { ActionSet action_set = 1 ; bool reply_with_snapshot = 2 ; } actions: A list of actions, one for each actor of the trial. This list has the same length and order as the list of actors provided in different places in the API (e.g. actors_in_trial ), for the same trial. Each action is the serialization of the appropriate type for the actor (as defined in the cogment.yaml file). tick_id: The tick ID of the observations on which the actions are taken. action_set: The set of actions for all actors. reply_with_snapshot: If true, then request that the observations for the actors (in the reply) be snapshots. If false, the observations can be snapshots or deltas (at the discretion of the environment). See ObservationData .","title":"EnvActionRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#envactionreply","text":"Reply message for the OnAction and OnEnd procedures. message EnvActionReply { ObservationSet observation_set = 1 ; repeated Reward rewards = 2 ; repeated Message messages = 3 ; bool final_update = 4 ; } observation_set: A set of observations for all actors of the trial. rewards: A list of rewards for actors. messages: User data to send to actors. The sender_name entry should not be set. messages: A list of messages for actors. The sender actor entry should not be filled. final_update: If true, this will be the final update of the environment for this trial (i.e. end of the trial). This should always be true when replying to an OnEnd procedure call.","title":"EnvActionReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#envmessagerequest","text":"Request message for the OnMessage procedure. message EnvMessageRequest { repeated Message messages = 1 ; } messages: List of messages from actors.","title":"EnvMessageRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#envmessagereply","text":"Reply message for the OnMessage procedure. message EnvMessageReply {}","title":"EnvMessageReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#datalog-api","text":"This API is defined in datalog.proto . It is implemented by the data logger application using the gRPC server API, and the orchestrator connects to the data logger application. The data logger endpoint, for the orchestrator to connect to, is defined in the cogment.yaml file.","title":"Data/Log API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#service-logexporter","text":"service LogExporter { rpc OnLogSample ( stream LogExporterSampleRequest ) returns ( LogExporterSampleReply ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} }","title":"Service LogExporter"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onlogsample","text":"Called the first time a sample is available. This call will normally stay active as long as the orchestrator is running. If disconnected, the orchestrator will not reconnect unless restarted. Data samples are provided by the orchestrator in the request stream. Metadata: None","title":"OnLogSample()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#version_4","text":"Called to request version data. Metadata: None","title":"Version()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#logexportersamplerequest","text":"Stream request message for the OnLogSample procedure. message DatalogSample { string user_id = 1 ; ObservationSet observations = 2 ; repeated Action actions = 3 ; repeated Reward rewards = 4 ; repeated Message messages = 5 ; } message LogExporterSampleRequest { oneof msg { TrialParams trial_params = 1 ; DatalogSample sample = 2 ; } } user_id: The ID of the user that started the trial. observations: A set of observations for all actors. actions: Actions from all actors. This list has the same length and order as the list of actors provided in different places in the API (e.g. actors_in_trial ), for the same trial. Of interest here; it matches the list of actors provided in trial_params . rewards: List of rewards sent to actors. messages: List of user data sent to actors or the environment. trial_params: Trial params used for a new trial. This is usually sent on start of a trial before any other sample from the trial. sample: A data sample to be logged.","title":"LogExporterSampleRequest"},{"location":"cogment/cogment-low-level-api-guide/grpc/#logexportersamplereply","text":"Reply message for the OnLogSample procedure. message LogExporterSampleReply {}","title":"LogExporterSampleReply"},{"location":"cogment/cogment-low-level-api-guide/grpc/#hook-api","text":"This API is defined in hooks.proto . It is implemented by the pre-trial hook application using the gRPC server API, and the orchestrator connects to the application. The pre-trial hook endpoint, for the orchestrator to connect to, is defined in the cogment.yaml file.","title":"Hook API"},{"location":"cogment/cogment-low-level-api-guide/grpc/#service-trialhooks","text":"service TrialHooks { rpc OnPreTrial ( PreTrialContext ) returns ( PreTrialContext ) {} rpc Version ( VersionRequest ) returns ( VersionInfo ) {} }","title":"Service TrialHooks"},{"location":"cogment/cogment-low-level-api-guide/grpc/#onpretrial","text":"Called before a trial is started to set or modify the parameters for the trial. Metadata: trial-id : UUID of the new trial that will be started.","title":"OnPreTrial()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#version_5","text":"Called to request version data. Metadata: None","title":"Version()"},{"location":"cogment/cogment-low-level-api-guide/grpc/#pretrialcontext","text":"Request and reply message for the OnPreTrial procedure. message PreTrialContext { string impl_name = 1 ; TrialParams params = 2 ; string user_id = 3 ; } impl_name: (optional) Name of the implementation that should run the hook. If not provided, an arbitrary implementation will be used. Set on a request, ignored when replying. params: The trial parameters so far. The first hook to be called will receive the default parameters present in the cogment.yaml file, and subsequent hooks will receive the parameters sent from the previous hook. Typically, changes are made to this data and the message sent as a reply. user_id: The ID of the user that is starting the trial. Set on a request, ignored when replying.","title":"PreTrialContext"},{"location":"cogment/cogment-low-level-api-guide/overview/","text":"Cogment Low-Level API guide \u00b6 Who is this for \u00b6 Projects that involve tech stacks for which there is no high-level support yet. Developers of the framework itself. Curious people. Prerequisites \u00b6 The actual implementation of the Low-Level API uses gRPC. As this document is not meant to teach how to use the gRPC protocol and/or libraries, it will be assumed that the reader understands these concepts already. Differences from the High-Level API \u00b6 The high-level API takes a very object-oriented approach to trial management. Starting a trial creates an instance of an environment, as well as instances of agents. gRPC services \u00b6 The low-level API is fully described within the gRPC service definitions found in the api/cogment directory of the cogment framework source. Agent Service \u00b6 api/cogment/agent.proto describes the service that agent applications have to implement. Start() is called when a trial starts. End() is called when a trial ends. Update() is called to request an action from the agent, given an observation. Reward() is called to inform the agent of received feedback. Message() is called to inform the agent of received messages. Environment Service \u00b6 api/cogment/environment.proto describes the service that environment applications have to implement. Start() is called when a trial starts. End() is called when a trial ends. Update() is called to request an updated set of observations based on fresh actions. Message() is called to inform the environment of received messages. Frontend API \u00b6 api/cogment/orchestrator.proto describes the service the orchestrator exposes that frontend applications use to create and manipulate trials. StartTrial() to request the start of a new trial. TerminateTrial() to request the end of the trial. SendMessage() to send a message to an agent or the environment TrialInfo() to request additional information about an existing trial. Data Log Exporter API \u00b6 api/cogment/data.proto describes the services provided to save all trial data (for archival, replay or offline analysis). Log() to log a data sample (i.e. normally all data from a single tick/timestep) Hooks API \u00b6 api/cogment/hooks.proto describes the hook services provided to allow per trial configuration changes at runtime. PreTrial() is called before a trial starts. Common Data \u00b6 Most of the common data is found in api/cogment/common.proto , but other \"common\" data could be found in other proto files. Observation \u00b6 The observation class contains the observation data for an actor ( ObservationData ). The type is generic ( bytes ) to accomodate the different observation classes defined for each actor (after serialization), and the snapshot and delta observations (which are defined in the cogment.yaml file). The snapshot boolean, if set to True, indicates that the observation is a snapshot (i.e. full), and if False, indicates that the data is a delta encoding of the observation (i.e. changes only). ObservationSet \u00b6 The observationSet class is used by the environment to send multiple observations (i.e. one per actors) to the orchestrator. The list of observations matches one-for-one with the list of actors. Actor IDs \u00b6 Each actor within a trial is assigned an actor ID. Actor IDs are assigned deterministically from their order of instantiation within the cogment.yaml file, starting from 0.","title":"Overview"},{"location":"cogment/cogment-low-level-api-guide/overview/#cogment-low-level-api-guide","text":"","title":"Cogment Low-Level API guide"},{"location":"cogment/cogment-low-level-api-guide/overview/#who-is-this-for","text":"Projects that involve tech stacks for which there is no high-level support yet. Developers of the framework itself. Curious people.","title":"Who is this for"},{"location":"cogment/cogment-low-level-api-guide/overview/#prerequisites","text":"The actual implementation of the Low-Level API uses gRPC. As this document is not meant to teach how to use the gRPC protocol and/or libraries, it will be assumed that the reader understands these concepts already.","title":"Prerequisites"},{"location":"cogment/cogment-low-level-api-guide/overview/#differences-from-the-high-level-api","text":"The high-level API takes a very object-oriented approach to trial management. Starting a trial creates an instance of an environment, as well as instances of agents.","title":"Differences from the High-Level API"},{"location":"cogment/cogment-low-level-api-guide/overview/#grpc-services","text":"The low-level API is fully described within the gRPC service definitions found in the api/cogment directory of the cogment framework source.","title":"gRPC services"},{"location":"cogment/cogment-low-level-api-guide/overview/#agent-service","text":"api/cogment/agent.proto describes the service that agent applications have to implement. Start() is called when a trial starts. End() is called when a trial ends. Update() is called to request an action from the agent, given an observation. Reward() is called to inform the agent of received feedback. Message() is called to inform the agent of received messages.","title":"Agent Service"},{"location":"cogment/cogment-low-level-api-guide/overview/#environment-service","text":"api/cogment/environment.proto describes the service that environment applications have to implement. Start() is called when a trial starts. End() is called when a trial ends. Update() is called to request an updated set of observations based on fresh actions. Message() is called to inform the environment of received messages.","title":"Environment Service"},{"location":"cogment/cogment-low-level-api-guide/overview/#frontend-api","text":"api/cogment/orchestrator.proto describes the service the orchestrator exposes that frontend applications use to create and manipulate trials. StartTrial() to request the start of a new trial. TerminateTrial() to request the end of the trial. SendMessage() to send a message to an agent or the environment TrialInfo() to request additional information about an existing trial.","title":"Frontend API"},{"location":"cogment/cogment-low-level-api-guide/overview/#data-log-exporter-api","text":"api/cogment/data.proto describes the services provided to save all trial data (for archival, replay or offline analysis). Log() to log a data sample (i.e. normally all data from a single tick/timestep)","title":"Data Log Exporter API"},{"location":"cogment/cogment-low-level-api-guide/overview/#hooks-api","text":"api/cogment/hooks.proto describes the hook services provided to allow per trial configuration changes at runtime. PreTrial() is called before a trial starts.","title":"Hooks API"},{"location":"cogment/cogment-low-level-api-guide/overview/#common-data","text":"Most of the common data is found in api/cogment/common.proto , but other \"common\" data could be found in other proto files.","title":"Common Data"},{"location":"cogment/cogment-low-level-api-guide/overview/#observation","text":"The observation class contains the observation data for an actor ( ObservationData ). The type is generic ( bytes ) to accomodate the different observation classes defined for each actor (after serialization), and the snapshot and delta observations (which are defined in the cogment.yaml file). The snapshot boolean, if set to True, indicates that the observation is a snapshot (i.e. full), and if False, indicates that the data is a delta encoding of the observation (i.e. changes only).","title":"Observation"},{"location":"cogment/cogment-low-level-api-guide/overview/#observationset","text":"The observationSet class is used by the environment to send multiple observations (i.e. one per actors) to the orchestrator. The list of observations matches one-for-one with the list of actors.","title":"ObservationSet"},{"location":"cogment/cogment-low-level-api-guide/overview/#actor-ids","text":"Each actor within a trial is assigned an actor ID. Actor IDs are assigned deterministically from their order of instantiation within the cogment.yaml file, starting from 0.","title":"Actor IDs"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/","text":"Step 1: Create a new Trial \u00b6 Install Cogment \u00b6 To follow this tutorial you'll need a working installation of Cogment . If you haven't done so already, follow our installation instructions . Bootstrap the app \u00b6 The Cogment command line interface (CLI) includes a simple tool to generate the base files and folder structures for a Cogment app. The first thing we'll do is use it to create an app with 2 AIs able to play games of RPS. Using Cogment's terminology, we will create 2 actors sharing a single implementation picking a random move for each round. We will develop a service actor implementation which is well suited for AIs and no client actor implementation which would be required for an interactive actor, for exemple, an actor controlled by a Human player. In the step 5 we will create such implementation. Run the following to bootstrap the app in a rps directory: $ cogment init rps Enter how many actor classes should be created: 1 [class 1] Enter the name of the class: player [class #1 'player'] Enter the number of service implementations that should be created (empty for 1): 1 [class #1 'player' > service impl. #1] Enter the name of the implementation: random_agent [class #1 'player' > service impl. #1 'random_agent'] Enter the number of actor instances using this implementation (empty for 1): 2 [class #1 'player'] Should a client implementation be created (Y or N, empty for Y): N Should a web-client be created (Y or N, empty for Y): N $ cd rps To summarize, for this 2 players game, we created: 1 actor class, player , because RPS is a symmetric game, both players have the same role within the game, 1 actor implementation for this class, random_agent , because at the moment we only want to implement one way of playing, 2 actor instances, because the game has 2 players. \u2139\ufe0f For the remainder of this tutorial, unless mentioned, it is assumed that all operations are run in the rps directory. Building and running the app \u00b6 We can now check that everything works as expected. First, we will need to run the code generation phase and the build phase. $ cogment run generate $ cogment run build Run the following to start all the services of the Cogment app as docker containers: the orchestrator , the environment and our random_agent . $ cogment run start In another terminal, run the following to start a client for this Cogment app, this will connect to the running services to start a trial, let it run for a few seconds and then terminate it. $ cogment run client Executing docker-compose run --rm client in . Creating rps_client_run ... done Client up and running. Trial 'b8251a1a-fad0-43b9-a1cc-00dcbebbfaa7' starts Trial 'b8251a1a-fad0-43b9-a1cc-00dcbebbfaa7' terminating This should also generate some logs in the first terminal where the app services are running. You can now terminate the services using ctrl+C . At this point we have generated a working but empty Cogment app and we checked that it could build and run. We are now ready to start the actual implementation! Define our data structures \u00b6 Cogment uses Protocol Buffers to define data structures. The initial definitions are located in the data.proto and look like that. syntax = \"proto3\" ; package rps ; message EnvConfig { } message TrialConfig { EnvConfig env_config = 1 ; } message Observation {} message PlayerAction {} Note that a file named cogment.yaml was also created in the rps directory by the boostrap process. This file is the main configuration for your Cogment app. In it, you will see a reference to: import : proto : - data.proto EnvConfig and TrialConfig will be discussed in the coming steps. For now we'll focus on defining the Action Space and Observation Space for our RPS app. Action Space \u00b6 Let's start by filling up PlayerAction which defines what each player can do at each step of the game. In the case of RPS, players chose one move among the three alternatives giving their name to the game: \"Rock\" , \"Paper\" or \"Scissors\" . To do that we will use an enum called Move , enum Move { ROCK = 0 ; PAPER = 1 ; SCISSORS = 2 ; } and use that type in PlayerAction . message PlayerAction { Move move = 1 ; } Modify the data.proto file to include the above additions. Observation Space \u00b6 The Observation structure defines what the actors perceive from the environment. It is an input they use to choose which action to take. In the context of RPS, the environment is limited to the two players and what they played. We represent this information in a data structure called PlayerState using two properties. message PlayerState { Move last_move = 1 ; // Last move played bool won_last = 2 ; // Did the player win the last round } The Observation structure itself defines the observed players from the point of view of each player. message Observation { PlayerState me = 1 ; PlayerState them = 2 ; } Edit the data.proto file to include the above additions. This file is used during the code generation phase to make the defined data structures available to the different services. To check that everything is working build and run the application. Nothing should be different at this stage. This concludes the step 1 of the tutorial: you have bootstrapped a Cogment project, implemented the data structures defining the action and observation spaces, started your app and ran a trial. Let\u2019s move on to actually implementing our services in step 2 .","title":"Step 1: Bootstrap a Cogment app"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#step-1-create-a-new-trial","text":"","title":"Step 1: Create a new Trial"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#install-cogment","text":"To follow this tutorial you'll need a working installation of Cogment . If you haven't done so already, follow our installation instructions .","title":"Install Cogment"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#bootstrap-the-app","text":"The Cogment command line interface (CLI) includes a simple tool to generate the base files and folder structures for a Cogment app. The first thing we'll do is use it to create an app with 2 AIs able to play games of RPS. Using Cogment's terminology, we will create 2 actors sharing a single implementation picking a random move for each round. We will develop a service actor implementation which is well suited for AIs and no client actor implementation which would be required for an interactive actor, for exemple, an actor controlled by a Human player. In the step 5 we will create such implementation. Run the following to bootstrap the app in a rps directory: $ cogment init rps Enter how many actor classes should be created: 1 [class 1] Enter the name of the class: player [class #1 'player'] Enter the number of service implementations that should be created (empty for 1): 1 [class #1 'player' > service impl. #1] Enter the name of the implementation: random_agent [class #1 'player' > service impl. #1 'random_agent'] Enter the number of actor instances using this implementation (empty for 1): 2 [class #1 'player'] Should a client implementation be created (Y or N, empty for Y): N Should a web-client be created (Y or N, empty for Y): N $ cd rps To summarize, for this 2 players game, we created: 1 actor class, player , because RPS is a symmetric game, both players have the same role within the game, 1 actor implementation for this class, random_agent , because at the moment we only want to implement one way of playing, 2 actor instances, because the game has 2 players. \u2139\ufe0f For the remainder of this tutorial, unless mentioned, it is assumed that all operations are run in the rps directory.","title":"Bootstrap the app"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#building-and-running-the-app","text":"We can now check that everything works as expected. First, we will need to run the code generation phase and the build phase. $ cogment run generate $ cogment run build Run the following to start all the services of the Cogment app as docker containers: the orchestrator , the environment and our random_agent . $ cogment run start In another terminal, run the following to start a client for this Cogment app, this will connect to the running services to start a trial, let it run for a few seconds and then terminate it. $ cogment run client Executing docker-compose run --rm client in . Creating rps_client_run ... done Client up and running. Trial 'b8251a1a-fad0-43b9-a1cc-00dcbebbfaa7' starts Trial 'b8251a1a-fad0-43b9-a1cc-00dcbebbfaa7' terminating This should also generate some logs in the first terminal where the app services are running. You can now terminate the services using ctrl+C . At this point we have generated a working but empty Cogment app and we checked that it could build and run. We are now ready to start the actual implementation!","title":"Building and running the app"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#define-our-data-structures","text":"Cogment uses Protocol Buffers to define data structures. The initial definitions are located in the data.proto and look like that. syntax = \"proto3\" ; package rps ; message EnvConfig { } message TrialConfig { EnvConfig env_config = 1 ; } message Observation {} message PlayerAction {} Note that a file named cogment.yaml was also created in the rps directory by the boostrap process. This file is the main configuration for your Cogment app. In it, you will see a reference to: import : proto : - data.proto EnvConfig and TrialConfig will be discussed in the coming steps. For now we'll focus on defining the Action Space and Observation Space for our RPS app.","title":"Define our data structures"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#action-space","text":"Let's start by filling up PlayerAction which defines what each player can do at each step of the game. In the case of RPS, players chose one move among the three alternatives giving their name to the game: \"Rock\" , \"Paper\" or \"Scissors\" . To do that we will use an enum called Move , enum Move { ROCK = 0 ; PAPER = 1 ; SCISSORS = 2 ; } and use that type in PlayerAction . message PlayerAction { Move move = 1 ; } Modify the data.proto file to include the above additions.","title":"Action Space"},{"location":"cogment/tutorial/1-bootstrap-and-data-structures/#observation-space","text":"The Observation structure defines what the actors perceive from the environment. It is an input they use to choose which action to take. In the context of RPS, the environment is limited to the two players and what they played. We represent this information in a data structure called PlayerState using two properties. message PlayerState { Move last_move = 1 ; // Last move played bool won_last = 2 ; // Did the player win the last round } The Observation structure itself defines the observed players from the point of view of each player. message Observation { PlayerState me = 1 ; PlayerState them = 2 ; } Edit the data.proto file to include the above additions. This file is used during the code generation phase to make the defined data structures available to the different services. To check that everything is working build and run the application. Nothing should be different at this stage. This concludes the step 1 of the tutorial: you have bootstrapped a Cogment project, implemented the data structures defining the action and observation spaces, started your app and ran a trial. Let\u2019s move on to actually implementing our services in step 2 .","title":"Observation Space"},{"location":"cogment/tutorial/2-random-player/","text":"Step 2: Implement a first actor and environment \u00b6 This part of the tutorial follows step 1 , make sure you've gone through it before starting this one. Alternatively, the completed step 1 can be retrieved from the tutorial's repository . In this step of the tutorial, we will implement the (very simple) decison logic for the random player as well as the base mechanics for RPS, i.e. the rules of the game, in the environment services. Random player agent \u00b6 In the rps directory, the random_agent directory contains the python implementation for the eponymous service. You'll find two files here: requirements.txt is a pip requirement file defining the dependencies of the service. For the moment it only lists cogment , Cogment's python SDK. main.py contains the implementation of the service. Open main.py and take a look at the generated content. At the bottom you'll find the main function, it initializes Cogment's context, registers the random_agent actor's implementation, then starts the service itsef on tcp port 9000 and await for its termination. Cogment's python sdk leverages Python's asynchronous features , you'll need a basic understanding of them. async def main (): print ( \"Random-Agent actor service up and running.\" ) context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = random_agent , impl_name = \"random_agent\" , actor_classes = [ \"player\" ,]) await context . serve_all_registered ( cogment . ServedEndpoint ( port = 9000 )) At the beginning of the file, the function random_agent is the actor's implementation. This function is called once per actor and per trial and handles the full lifetime of the actor. The actor's initialization , before the async for . This is where, for example, actor's internal data can be defined before calling actor_session.start() to notify that it is ready, Its event loop , the content of the async for . This is where resides the implementation of the actor's response to various events, Its termination , after the async for . The generated implementation is very simple: it handles the three main kind of events: observations , rewards and messages , it does a default action whenever required, i.e. in response to an observation. We will further learn about how to use observations in step 4 and rewards in step 3 . Messages are out of the scope for this basics tutorial. Please note the import and usage of PlayerAction which is the data structure from data.proto defining the actor's action space. async def random_agent ( actor_session ): actor_session . start () async for event in actor_session . event_loop (): if event . observation : observation = event . observation print ( f \"' { actor_session . name } ' received an observation: ' { observation } '\" ) if event . type == cogment . EventType . ACTIVE : action = PlayerAction () actor_session . do_action ( action ) for reward in event . rewards : print ( f \"' { actor_session . name } ' received a reward for tick # { reward . tick_id } : { reward . value } \" ) for message in event . messages : print ( f \"' { actor_session . name } ' received a message from ' { message . sender_name } ': - ' { message . payload } '\" ) Our goal is to implement an actor playing at random. We first need to import the different Move , as defined in our data structures. We also need to import random , the python package generating random numbers. from data_pb2 import ROCK , PAPER , SCISSORS import random MOVES = [ ROCK , PAPER , SCISSORS ] Once this is available we can simply update the taking decision part of the actor's implementation to compute a random move whenever it is needed. if event . observation : observation = event . observation print ( f \"' { actor_session . name } ' received an observation: ' { observation } '\" ) if event . type == cogment . EventType . ACTIVE : action = PlayerAction ( move = random . choice ( MOVES )) actor_session . do_action ( action ) Modify the random_agent/main.py file to include the above additions. Implementing the rules of the game \u00b6 In the rps directory, the environment directory contains the python implementation for the eponymous service. Similarly to the actor's service, you will find two files here, requirements.txt and main.py . Open main.py and take a look at the generated content. The code is very similar to the random_agent 's. In the main function, instead of using register_actor , register_environment is used. The implementation function, called environment here, is structured similarly to the actor's one but handles two kinds of events: actions (and the last actions of a trial final_actions ) and message . Environments don't perform actions, they produce observations that are sent to the actors participating in the trial. Please note the import and usage of Observation which is the datastructure defined in data.proto defining the actors observation space. async def environment ( environment_session ): print ( \"environment starting\" ) # Create the initial observaton observation = Observation () # Start the trial and send that observation to all actors environment_session . start ([( \"*\" , observation )]) async for event in environment_session . event_loop (): if event . actions : actions = event . actions print ( f \"environment received the actions\" ) for actor , recv_action in zip ( environment_session . get_active_actors (), actions ): print ( f \" actor ' { actor . actor_name } ' did action ' { recv_action . action } '\" ) observation = Observation () if event . type == cogment . EventType . ACTIVE : # The trial is active environment_session . produce_observations ([( \"*\" , observation )]) else : # The trial termination has been requested environment_session . end ([( \"*\" , observation )]) for message in event . messages : print ( f \"environment received a message from ' { message . sender_name } ': - ' { message . payload } '\" ) print ( \"environment end\" ) Our goal, in this section, is to implement how the environment computes the observations from the actions done by the actors at a given timestep. We first import the needed datastructure and define a dictionary mapping each move to the move that defeats it. from data_pb2 import PlayerState , ROCK , PAPER , SCISSORS DEFEATS = { ROCK : PAPER , SCISSORS : ROCK , PAPER : SCISSORS } In the initialization phase of the environment implementation, i.e. before the async for , we create a simple state data structure that is keeping around the number of rounds played and won by each of the two players. We then compute the initial observation for each of the two players. One instance of PlayerState per player is created, each is used as the me and them state of each player's observation. state = { \"rounds_count\" : 0 , \"p1\" : { \"won_rounds_count\" : 0 }, \"p2\" : { \"won_rounds_count\" : 0 }, } print ( \"environment starting\" ) [ p1 , p2 ] = environment_session . get_active_actors () p1_state = PlayerState ( won_last = False , last_move = None ) p2_state = PlayerState ( won_last = False , last_move = None ) environment_session . start ([ ( p1 . actor_name , Observation ( me = p1_state , them = p2_state )), ( p2 . actor_name , Observation ( me = p2_state , them = p1_state )), ]) In the event loop we implement how the environment produces observations based on the actor's actions. We start by retrieving each player's action and computing who won the round. Then, we update the internal state . Finally, we produce up-to-date observations for the players. if event . actions : [ p1_action , p2_action ] = [ recv_action . action for recv_action in event . actions ] print ( f \" { p1 . actor_name } played { MOVES_STR [ p1_action . move ] } \" ) print ( f \" { p2 . actor_name } played { MOVES_STR [ p2_action . move ] } \" ) # Compute who wins, if the two players had the same move, nobody wins p1_state = PlayerState ( won_last = p1_action . move == DEFEATS [ p2_action . move ], last_move = p1_action . move ) p2_state = PlayerState ( won_last = p2_action . move == DEFEATS [ p1_action . move ], last_move = p2_action . move ) state [ \"rounds_count\" ] += 1 if p1_state . won_last : state [ \"p1\" ][ \"won_rounds_count\" ] += 1 print ( f \" { p1 . actor_name } wins!\" ) elif p2_state . won_last : state [ \"p2\" ][ \"won_rounds_count\" ] += 1 print ( f \" { p2 . actor_name } wins!\" ) else : print ( f \"draw.\" ) # Generate and send observations observations = [ ( p1 . actor_name , Observation ( me = p1_state , them = p2_state )), ( p2 . actor_name , Observation ( me = p2_state , them = p1_state )), ] if event . type == cogment . EventType . ACTIVE : # The trial is active environment_session . produce_observations ( observations ) else : # The trial termination has been requested environment_session . end ( observations ) Finally, in the termination phase, we print some stats about the trial itself. print ( \"environment end\" ) print ( f \" \\t * { state [ 'rounds_count' ] } rounds played\" ) print ( f \" \\t * { p1 . actor_name } won { state [ 'p1' ][ 'won_rounds_count' ] } rounds\" ) print ( f \" \\t * { p1 . actor_name } won { state [ 'p2' ][ 'won_rounds_count' ] } rounds\" ) print ( f \" \\t * { state [ 'rounds_count' ] - state [ 'p1' ][ 'won_rounds_count' ] - state [ 'p2' ][ 'won_rounds_count' ] } draws\" ) Modify the environment/main.py file to include the above additions. Please note that this code makes assumptions on the number of actors and their classes. Production code should handle non-standard cases in a better way. You can now build and run the application. Given the nature of the game and the fully random nature of the plays you should have around 1/3 of player 1 wins, 1/3 of player 2's and 1/3 of draws. This concludes the step 2 of the tutorial: you implemented your first actor and your first environment. Let\u2019s move on to learning more about rewards in step 3 .","title":"Step 2: Implement actor and environment"},{"location":"cogment/tutorial/2-random-player/#step-2-implement-a-first-actor-and-environment","text":"This part of the tutorial follows step 1 , make sure you've gone through it before starting this one. Alternatively, the completed step 1 can be retrieved from the tutorial's repository . In this step of the tutorial, we will implement the (very simple) decison logic for the random player as well as the base mechanics for RPS, i.e. the rules of the game, in the environment services.","title":"Step 2: Implement a first actor and environment"},{"location":"cogment/tutorial/2-random-player/#random-player-agent","text":"In the rps directory, the random_agent directory contains the python implementation for the eponymous service. You'll find two files here: requirements.txt is a pip requirement file defining the dependencies of the service. For the moment it only lists cogment , Cogment's python SDK. main.py contains the implementation of the service. Open main.py and take a look at the generated content. At the bottom you'll find the main function, it initializes Cogment's context, registers the random_agent actor's implementation, then starts the service itsef on tcp port 9000 and await for its termination. Cogment's python sdk leverages Python's asynchronous features , you'll need a basic understanding of them. async def main (): print ( \"Random-Agent actor service up and running.\" ) context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = random_agent , impl_name = \"random_agent\" , actor_classes = [ \"player\" ,]) await context . serve_all_registered ( cogment . ServedEndpoint ( port = 9000 )) At the beginning of the file, the function random_agent is the actor's implementation. This function is called once per actor and per trial and handles the full lifetime of the actor. The actor's initialization , before the async for . This is where, for example, actor's internal data can be defined before calling actor_session.start() to notify that it is ready, Its event loop , the content of the async for . This is where resides the implementation of the actor's response to various events, Its termination , after the async for . The generated implementation is very simple: it handles the three main kind of events: observations , rewards and messages , it does a default action whenever required, i.e. in response to an observation. We will further learn about how to use observations in step 4 and rewards in step 3 . Messages are out of the scope for this basics tutorial. Please note the import and usage of PlayerAction which is the data structure from data.proto defining the actor's action space. async def random_agent ( actor_session ): actor_session . start () async for event in actor_session . event_loop (): if event . observation : observation = event . observation print ( f \"' { actor_session . name } ' received an observation: ' { observation } '\" ) if event . type == cogment . EventType . ACTIVE : action = PlayerAction () actor_session . do_action ( action ) for reward in event . rewards : print ( f \"' { actor_session . name } ' received a reward for tick # { reward . tick_id } : { reward . value } \" ) for message in event . messages : print ( f \"' { actor_session . name } ' received a message from ' { message . sender_name } ': - ' { message . payload } '\" ) Our goal is to implement an actor playing at random. We first need to import the different Move , as defined in our data structures. We also need to import random , the python package generating random numbers. from data_pb2 import ROCK , PAPER , SCISSORS import random MOVES = [ ROCK , PAPER , SCISSORS ] Once this is available we can simply update the taking decision part of the actor's implementation to compute a random move whenever it is needed. if event . observation : observation = event . observation print ( f \"' { actor_session . name } ' received an observation: ' { observation } '\" ) if event . type == cogment . EventType . ACTIVE : action = PlayerAction ( move = random . choice ( MOVES )) actor_session . do_action ( action ) Modify the random_agent/main.py file to include the above additions.","title":"Random player agent"},{"location":"cogment/tutorial/2-random-player/#implementing-the-rules-of-the-game","text":"In the rps directory, the environment directory contains the python implementation for the eponymous service. Similarly to the actor's service, you will find two files here, requirements.txt and main.py . Open main.py and take a look at the generated content. The code is very similar to the random_agent 's. In the main function, instead of using register_actor , register_environment is used. The implementation function, called environment here, is structured similarly to the actor's one but handles two kinds of events: actions (and the last actions of a trial final_actions ) and message . Environments don't perform actions, they produce observations that are sent to the actors participating in the trial. Please note the import and usage of Observation which is the datastructure defined in data.proto defining the actors observation space. async def environment ( environment_session ): print ( \"environment starting\" ) # Create the initial observaton observation = Observation () # Start the trial and send that observation to all actors environment_session . start ([( \"*\" , observation )]) async for event in environment_session . event_loop (): if event . actions : actions = event . actions print ( f \"environment received the actions\" ) for actor , recv_action in zip ( environment_session . get_active_actors (), actions ): print ( f \" actor ' { actor . actor_name } ' did action ' { recv_action . action } '\" ) observation = Observation () if event . type == cogment . EventType . ACTIVE : # The trial is active environment_session . produce_observations ([( \"*\" , observation )]) else : # The trial termination has been requested environment_session . end ([( \"*\" , observation )]) for message in event . messages : print ( f \"environment received a message from ' { message . sender_name } ': - ' { message . payload } '\" ) print ( \"environment end\" ) Our goal, in this section, is to implement how the environment computes the observations from the actions done by the actors at a given timestep. We first import the needed datastructure and define a dictionary mapping each move to the move that defeats it. from data_pb2 import PlayerState , ROCK , PAPER , SCISSORS DEFEATS = { ROCK : PAPER , SCISSORS : ROCK , PAPER : SCISSORS } In the initialization phase of the environment implementation, i.e. before the async for , we create a simple state data structure that is keeping around the number of rounds played and won by each of the two players. We then compute the initial observation for each of the two players. One instance of PlayerState per player is created, each is used as the me and them state of each player's observation. state = { \"rounds_count\" : 0 , \"p1\" : { \"won_rounds_count\" : 0 }, \"p2\" : { \"won_rounds_count\" : 0 }, } print ( \"environment starting\" ) [ p1 , p2 ] = environment_session . get_active_actors () p1_state = PlayerState ( won_last = False , last_move = None ) p2_state = PlayerState ( won_last = False , last_move = None ) environment_session . start ([ ( p1 . actor_name , Observation ( me = p1_state , them = p2_state )), ( p2 . actor_name , Observation ( me = p2_state , them = p1_state )), ]) In the event loop we implement how the environment produces observations based on the actor's actions. We start by retrieving each player's action and computing who won the round. Then, we update the internal state . Finally, we produce up-to-date observations for the players. if event . actions : [ p1_action , p2_action ] = [ recv_action . action for recv_action in event . actions ] print ( f \" { p1 . actor_name } played { MOVES_STR [ p1_action . move ] } \" ) print ( f \" { p2 . actor_name } played { MOVES_STR [ p2_action . move ] } \" ) # Compute who wins, if the two players had the same move, nobody wins p1_state = PlayerState ( won_last = p1_action . move == DEFEATS [ p2_action . move ], last_move = p1_action . move ) p2_state = PlayerState ( won_last = p2_action . move == DEFEATS [ p1_action . move ], last_move = p2_action . move ) state [ \"rounds_count\" ] += 1 if p1_state . won_last : state [ \"p1\" ][ \"won_rounds_count\" ] += 1 print ( f \" { p1 . actor_name } wins!\" ) elif p2_state . won_last : state [ \"p2\" ][ \"won_rounds_count\" ] += 1 print ( f \" { p2 . actor_name } wins!\" ) else : print ( f \"draw.\" ) # Generate and send observations observations = [ ( p1 . actor_name , Observation ( me = p1_state , them = p2_state )), ( p2 . actor_name , Observation ( me = p2_state , them = p1_state )), ] if event . type == cogment . EventType . ACTIVE : # The trial is active environment_session . produce_observations ( observations ) else : # The trial termination has been requested environment_session . end ( observations ) Finally, in the termination phase, we print some stats about the trial itself. print ( \"environment end\" ) print ( f \" \\t * { state [ 'rounds_count' ] } rounds played\" ) print ( f \" \\t * { p1 . actor_name } won { state [ 'p1' ][ 'won_rounds_count' ] } rounds\" ) print ( f \" \\t * { p1 . actor_name } won { state [ 'p2' ][ 'won_rounds_count' ] } rounds\" ) print ( f \" \\t * { state [ 'rounds_count' ] - state [ 'p1' ][ 'won_rounds_count' ] - state [ 'p2' ][ 'won_rounds_count' ] } draws\" ) Modify the environment/main.py file to include the above additions. Please note that this code makes assumptions on the number of actors and their classes. Production code should handle non-standard cases in a better way. You can now build and run the application. Given the nature of the game and the fully random nature of the plays you should have around 1/3 of player 1 wins, 1/3 of player 2's and 1/3 of draws. This concludes the step 2 of the tutorial: you implemented your first actor and your first environment. Let\u2019s move on to learning more about rewards in step 3 .","title":"Implementing the rules of the game"},{"location":"cogment/tutorial/3-rewards/","text":"Step 3 - Rewards \u00b6 This part of the tutorial follows step 2 , make sure you've gone through it before starting this one. Alternatively the completed step 2 can be retrieved from the tutorial's repository . In this step of the tutorial, we will start thinking about rewards. Rewards are a way to evaluate how an actor performs at a task. They can be used to evaluate or compare different implementations of an actor, or, especially in the context or Reinforcement Learning, train an model. In Cogment, both the environment and other actors can evaluate an actor. Here, we will focus on sending reward from the environment. The first thing we'll do for this step is to add the concept of multi-round game to our RPS implementation. We'll learn to configure the environment along the way. Then, we will adapt the environment implementation to send a reward to the actor winning a game. Finally, we will retrieve rewards and other metrics from the running Cogment app. Adding the concept of a game \u00b6 Up until now, our implementation of RPS focused on rounds. However, RPS is usually played in games won by the player reaching a target score, i.e. a number of won rounds. Before sending rewards we need to adapt our implementation to support games. We will make the target score of each game configurable. The generated data structure EnvConfig , referenced within cogment.yaml in environment.config_type , defines the configuration of the environment. Let's add a target_game_score numerical property to it. message EnvConfig { int32 target_game_score = 1 ; } Modify the data.proto file with this update. The environment implementation can now be updated to know about games. During the initialization phase of the environment function, we can retrieve the value from the environment's configuration. target_game_score = environment_session . config . target_game_score Instead of counting rounds we update the state variable to count games and the score of the ongoing game. state = { \"games_count\" : 0 , \"p1\" : { \"won_games_count\" : 0 , \"current_game_score\" : 0 }, \"p2\" : { \"won_games_count\" : 0 , \"current_game_score\" : 0 }, } In the event loop we need to make two changes. First, Instead of counting the rounds, we will update each player current_game_score . if p1_state . won_last : state [ \"p1\" ][ \"current_game_score\" ] += 1 elif p2_state . won_last : state [ \"p2\" ][ \"current_game_score\" ] += 1 Second, once the observation is sent, we detect the end of each game and update the state accordingly. # Update the game scores if state [ \"p1\" ][ \"current_game_score\" ] >= target_game_score : state [ \"games_count\" ] += 1 state [ \"p1\" ][ \"current_game_score\" ] = 0 state [ \"p2\" ][ \"current_game_score\" ] = 0 state [ \"p1\" ][ \"won_games_count\" ] += 1 print ( f \" { p1 . actor_name } won game # { state [ 'games_count' ] } \" ) elif state [ \"p2\" ][ \"current_game_score\" ] >= target_game_score : state [ \"games_count\" ] += 1 state [ \"p1\" ][ \"current_game_score\" ] = 0 state [ \"p2\" ][ \"current_game_score\" ] = 0 state [ \"p2\" ][ \"won_games_count\" ] += 1 print ( f \" { p2 . actor_name } won game # { state [ 'games_count' ] } \" ) Finally, during the termination , we display stats about the games. print ( f \" \\t * { state [ 'games_count' ] } games played\" ) print ( f \" \\t * { p1 . actor_name } won { state [ 'p1' ][ 'won_games_count' ] } games\" ) print ( f \" \\t * { p2 . actor_name } won { state [ 'p2' ][ 'won_games_count' ] } games\" ) Modify the environment/main.py file with these updates. Now that the data structure is modified and the environment implementation uses it, we can define, for the default trial, a value for the target_game_score property. Let's start with games of 2 winning rounds. trial_params : environment : endpoint : grpc://environment:9000 config : target_game_score : 2 Modify the cogment.yaml file with this update. You can now build and run the application to check that it works as expected. In this simple implementation, the concept of game is local to the environment. It has no impact on the observation and action spaces, and thus no impact on the actor implementation. This means an actor wouldn't know that the round it currently plays is the tie breaker in a game or its very first round. As a result the actor will play every round the same way. Sending rewards to the actors \u00b6 The environment is now able to: compute when an actor wins a game, communicate this information to it and to the other Cogment app services, send rewards when an actor reaches a measurable goal, in our case, when it wins a game. Please note, that not all actions need to be rewarded. When a game is won, the environment will add a positive reward to the winner (we chose a value of 1) and a negative reward to the loser (we chose a value of -1). Cogment also supports the notion of confidence , a weight, between 0 and 1 that expresses the qualification of the reward sender in its appreciation. In this case we are applying objective rules, so we use a confidence of 1. In the event loop , when the first player wins a game we add the following. environment_session . add_reward ( value = 1 , confidence = 1 , to = [ p1 . actor_name ]) environment_session . add_reward ( value =- 1 , confidence = 1 , to = [ p2 . actor_name ]) When the second player wins a game we add the following. environment_session . add_reward ( value =- 1 , confidence = 1 , to = [ p1 . actor_name ]) environment_session . add_reward ( value = 1 , confidence = 1 , to = [ p2 . actor_name ]) Modify the environment/main.py file to include the above additions. You can now build and run the application to check that it works as expected. In particular you should see logs relative to the reception of rewards on the actor side. Using the metrics and dashboard services to retrieve & visualize the rewards over time \u00b6 \ud83d\udea7 This concludes the step 3 of the tutorial: you've learned about environment configuration, implemented your reward sending and used the metrics and dashboard services. Let\u2019s move on to implementing an RPS player that actually considers what was played before deciding on its next move in step 4 .","title":"Step 3: Introduce rewards"},{"location":"cogment/tutorial/3-rewards/#step-3-rewards","text":"This part of the tutorial follows step 2 , make sure you've gone through it before starting this one. Alternatively the completed step 2 can be retrieved from the tutorial's repository . In this step of the tutorial, we will start thinking about rewards. Rewards are a way to evaluate how an actor performs at a task. They can be used to evaluate or compare different implementations of an actor, or, especially in the context or Reinforcement Learning, train an model. In Cogment, both the environment and other actors can evaluate an actor. Here, we will focus on sending reward from the environment. The first thing we'll do for this step is to add the concept of multi-round game to our RPS implementation. We'll learn to configure the environment along the way. Then, we will adapt the environment implementation to send a reward to the actor winning a game. Finally, we will retrieve rewards and other metrics from the running Cogment app.","title":"Step 3 - Rewards"},{"location":"cogment/tutorial/3-rewards/#adding-the-concept-of-a-game","text":"Up until now, our implementation of RPS focused on rounds. However, RPS is usually played in games won by the player reaching a target score, i.e. a number of won rounds. Before sending rewards we need to adapt our implementation to support games. We will make the target score of each game configurable. The generated data structure EnvConfig , referenced within cogment.yaml in environment.config_type , defines the configuration of the environment. Let's add a target_game_score numerical property to it. message EnvConfig { int32 target_game_score = 1 ; } Modify the data.proto file with this update. The environment implementation can now be updated to know about games. During the initialization phase of the environment function, we can retrieve the value from the environment's configuration. target_game_score = environment_session . config . target_game_score Instead of counting rounds we update the state variable to count games and the score of the ongoing game. state = { \"games_count\" : 0 , \"p1\" : { \"won_games_count\" : 0 , \"current_game_score\" : 0 }, \"p2\" : { \"won_games_count\" : 0 , \"current_game_score\" : 0 }, } In the event loop we need to make two changes. First, Instead of counting the rounds, we will update each player current_game_score . if p1_state . won_last : state [ \"p1\" ][ \"current_game_score\" ] += 1 elif p2_state . won_last : state [ \"p2\" ][ \"current_game_score\" ] += 1 Second, once the observation is sent, we detect the end of each game and update the state accordingly. # Update the game scores if state [ \"p1\" ][ \"current_game_score\" ] >= target_game_score : state [ \"games_count\" ] += 1 state [ \"p1\" ][ \"current_game_score\" ] = 0 state [ \"p2\" ][ \"current_game_score\" ] = 0 state [ \"p1\" ][ \"won_games_count\" ] += 1 print ( f \" { p1 . actor_name } won game # { state [ 'games_count' ] } \" ) elif state [ \"p2\" ][ \"current_game_score\" ] >= target_game_score : state [ \"games_count\" ] += 1 state [ \"p1\" ][ \"current_game_score\" ] = 0 state [ \"p2\" ][ \"current_game_score\" ] = 0 state [ \"p2\" ][ \"won_games_count\" ] += 1 print ( f \" { p2 . actor_name } won game # { state [ 'games_count' ] } \" ) Finally, during the termination , we display stats about the games. print ( f \" \\t * { state [ 'games_count' ] } games played\" ) print ( f \" \\t * { p1 . actor_name } won { state [ 'p1' ][ 'won_games_count' ] } games\" ) print ( f \" \\t * { p2 . actor_name } won { state [ 'p2' ][ 'won_games_count' ] } games\" ) Modify the environment/main.py file with these updates. Now that the data structure is modified and the environment implementation uses it, we can define, for the default trial, a value for the target_game_score property. Let's start with games of 2 winning rounds. trial_params : environment : endpoint : grpc://environment:9000 config : target_game_score : 2 Modify the cogment.yaml file with this update. You can now build and run the application to check that it works as expected. In this simple implementation, the concept of game is local to the environment. It has no impact on the observation and action spaces, and thus no impact on the actor implementation. This means an actor wouldn't know that the round it currently plays is the tie breaker in a game or its very first round. As a result the actor will play every round the same way.","title":"Adding the concept of a game"},{"location":"cogment/tutorial/3-rewards/#sending-rewards-to-the-actors","text":"The environment is now able to: compute when an actor wins a game, communicate this information to it and to the other Cogment app services, send rewards when an actor reaches a measurable goal, in our case, when it wins a game. Please note, that not all actions need to be rewarded. When a game is won, the environment will add a positive reward to the winner (we chose a value of 1) and a negative reward to the loser (we chose a value of -1). Cogment also supports the notion of confidence , a weight, between 0 and 1 that expresses the qualification of the reward sender in its appreciation. In this case we are applying objective rules, so we use a confidence of 1. In the event loop , when the first player wins a game we add the following. environment_session . add_reward ( value = 1 , confidence = 1 , to = [ p1 . actor_name ]) environment_session . add_reward ( value =- 1 , confidence = 1 , to = [ p2 . actor_name ]) When the second player wins a game we add the following. environment_session . add_reward ( value =- 1 , confidence = 1 , to = [ p1 . actor_name ]) environment_session . add_reward ( value = 1 , confidence = 1 , to = [ p2 . actor_name ]) Modify the environment/main.py file to include the above additions. You can now build and run the application to check that it works as expected. In particular you should see logs relative to the reception of rewards on the actor side.","title":"Sending rewards to the actors"},{"location":"cogment/tutorial/3-rewards/#using-the-metrics-and-dashboard-services-to-retrieve-visualize-the-rewards-over-time","text":"\ud83d\udea7 This concludes the step 3 of the tutorial: you've learned about environment configuration, implemented your reward sending and used the metrics and dashboard services. Let\u2019s move on to implementing an RPS player that actually considers what was played before deciding on its next move in step 4 .","title":"Using the metrics and dashboard services to retrieve &amp; visualize the rewards over time"},{"location":"cogment/tutorial/4-heuristic-player/","text":"Step 4: Add a second actor implementation based on a heuristic \u00b6 This part of the tutorial follows step 3 , make sure you've gone through it before starting this one. Alternatively the completed step 3 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over another actor implementation and learn about using the received observations before doing an action. Creating a second actor implementation \u00b6 Let's start by creating another implementation of the player actor class. Because we expect it to be rather small and not use additional dependencies, this second implementation will live in the same service as the previous one. We will start by copying the random_agent implementation. In random_agent/main.py copy/paste the random_agent function and name it heuristic_agent . async def heuristic_agent ( actor_session ): Then, in the same file, register this \"new\" implementation in the main function. context . register_actor ( impl = heuristic_agent , impl_name = \"heuristic_agent\" , actor_classes = [ \"player\" ]) When the service starts it will now host the two implementations. We can now configure one of the player in the default trial, defined in cogment.yaml , to use the heuristic_agent implementation. actors : - name : player_1 actor_class : player implementation : random_agent endpoint : grpc://random-agent:9000 - name : player_2 actor_class : player implementation : heuristic_agent endpoint : grpc://random-agent:9000 Modify the cogment.yaml file to include the above addition. You can now build and run the application to check that it still works. Nothing should have changed except one of the player uses the code from the new implementation. Implementing a simple heuristic's agent \u00b6 While the random_player ignored the state of the game, picking its move at random, our new implementation will consider the received observations to pick its move. We will implement a subset of the strategies described in this article: If I won the last round, do the same thing, If my opponent won the last round, play the move that would have won against his, If the last round was a draw, play a random move. We will start by redefining in random_agent/main.py the same DEFEATS we used by the environment. DEFEATS = { ROCK : PAPER , SCISSORS : ROCK , PAPER : SCISSORS } Then, in the event loop, we look at the received observation before taking an action based on this simple strategy. observation = event . observation print ( f \"' { actor_session . name } ' received an observation: ' { observation } '\" ) if event . type == cogment . EventType . ACTIVE : if observation . snapshot . me . won_last : # I won the last round, let's play the same thing actor_session . do_action ( PlayerAction ( move = observation . snapshot . me . last_move )) elif observation . snapshot . them . won_last : # I lost the last round, let's play what would have won actor_session . do_action ( PlayerAction ( move = DEFEATS [ observation . snapshot . them . last_move ])) else : # last round was a draw, let's play randomly actor_session . do_action ( PlayerAction ( move = random . choice ( MOVES ))) Modify the random_player/main.py file accordingly. You can now build and run the application to check that it works. Don't expect the heuristic player to beat the random player, the nature of the game actually rewards pure randomness in the playing. You can however implement various strategies and see how they fare against each other. This concludes the step 4 of the tutorial: you've learned about adding and using different implementations of an actor class and how to access and use the received observations. Let\u2019s move on to adding a human player in the mix with step 5 .","title":"Step 4: Create a heuristic player"},{"location":"cogment/tutorial/4-heuristic-player/#step-4-add-a-second-actor-implementation-based-on-a-heuristic","text":"This part of the tutorial follows step 3 , make sure you've gone through it before starting this one. Alternatively the completed step 3 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over another actor implementation and learn about using the received observations before doing an action.","title":"Step 4: Add a second actor implementation based on a heuristic"},{"location":"cogment/tutorial/4-heuristic-player/#creating-a-second-actor-implementation","text":"Let's start by creating another implementation of the player actor class. Because we expect it to be rather small and not use additional dependencies, this second implementation will live in the same service as the previous one. We will start by copying the random_agent implementation. In random_agent/main.py copy/paste the random_agent function and name it heuristic_agent . async def heuristic_agent ( actor_session ): Then, in the same file, register this \"new\" implementation in the main function. context . register_actor ( impl = heuristic_agent , impl_name = \"heuristic_agent\" , actor_classes = [ \"player\" ]) When the service starts it will now host the two implementations. We can now configure one of the player in the default trial, defined in cogment.yaml , to use the heuristic_agent implementation. actors : - name : player_1 actor_class : player implementation : random_agent endpoint : grpc://random-agent:9000 - name : player_2 actor_class : player implementation : heuristic_agent endpoint : grpc://random-agent:9000 Modify the cogment.yaml file to include the above addition. You can now build and run the application to check that it still works. Nothing should have changed except one of the player uses the code from the new implementation.","title":"Creating a second actor implementation"},{"location":"cogment/tutorial/4-heuristic-player/#implementing-a-simple-heuristics-agent","text":"While the random_player ignored the state of the game, picking its move at random, our new implementation will consider the received observations to pick its move. We will implement a subset of the strategies described in this article: If I won the last round, do the same thing, If my opponent won the last round, play the move that would have won against his, If the last round was a draw, play a random move. We will start by redefining in random_agent/main.py the same DEFEATS we used by the environment. DEFEATS = { ROCK : PAPER , SCISSORS : ROCK , PAPER : SCISSORS } Then, in the event loop, we look at the received observation before taking an action based on this simple strategy. observation = event . observation print ( f \"' { actor_session . name } ' received an observation: ' { observation } '\" ) if event . type == cogment . EventType . ACTIVE : if observation . snapshot . me . won_last : # I won the last round, let's play the same thing actor_session . do_action ( PlayerAction ( move = observation . snapshot . me . last_move )) elif observation . snapshot . them . won_last : # I lost the last round, let's play what would have won actor_session . do_action ( PlayerAction ( move = DEFEATS [ observation . snapshot . them . last_move ])) else : # last round was a draw, let's play randomly actor_session . do_action ( PlayerAction ( move = random . choice ( MOVES ))) Modify the random_player/main.py file accordingly. You can now build and run the application to check that it works. Don't expect the heuristic player to beat the random player, the nature of the game actually rewards pure randomness in the playing. You can however implement various strategies and see how they fare against each other. This concludes the step 4 of the tutorial: you've learned about adding and using different implementations of an actor class and how to access and use the received observations. Let\u2019s move on to adding a human player in the mix with step 5 .","title":"Implementing a simple heuristic's agent"},{"location":"cogment/tutorial/5-human-player/","text":"Step 5: Add a human player in the loop \u00b6 This part of the tutorial follows step 4 , make sure you've gone through it before starting this one. Alternatively the completed step 4 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over another actor implementation, this time client-side, to enable Humans to play RPS. We will also learn how to let the environment control the termination of the trial. The client \u00b6 In the previous steps, we triggered the trials by running cogment run client . The more curious among you will have understood that this launches a client of the Cogment app, implemented in client/main.py . In this step, we will make changes to this file, this is therefore a good time to take a look at it. Open client/main.py and take a look at the generated content. The main starts similarly to the others by creating and configuring the main entry point to the SDK, Context . Then a trial_controller function is created: it enables retrieving the unique id for a trial and controls its lifetime (ending it by default after 10 seconds). Finally, a trial is started on the running orchestrator , using trial_controller and a default trial configuration. async def trial_controller ( control_session ): print ( f \"Trial ' { control_session . get_trial_id () } ' starts\" ) await asyncio . sleep ( 10 ) print ( f \"Trial ' { control_session . get_trial_id () } ' terminating\" ) await control_session . terminate_trial () await context . start_trial ( endpoint = \"orchestrator:9000\" , impl = trial_controller , trial_config = TrialConfig ()) Environment controlled trial \u00b6 While 10 seconds was plenty of time to get a decent number of AI vs AI games played, a Human player won't be as fast: we need to change how we control the duration and number of played games. To do that, we will switch from controlling the trial lifetime from the client's trial controller, to controlling it from the environment. Instead of a duration, our trial will last for a given number of games. That way AI vs AI trials will be configurable to last hundreds of games while trials involving Humans can be much shorter. Let's introduce a new property of the environment configuration, target_games_count , in data.proto . message EnvConfig { int32 target_game_score = 1 ; int32 target_games_count = 2 ; } We can then set its value for the default trial in cogment.yaml . trial_params : environment : endpoint : grpc://environment:9000 config : target_game_score : 2 target_games_count : 5 Environment implementations can trigger the end of a trial by calling the end function on the session instance. In our existing implementation, we will first prepare the observations instead of producing them right away. observations = [ ( p1 . actor_name , Observation ( me = p1_state , them = p2_state )), ( p2 . actor_name , Observation ( me = p2_state , them = p1_state )), ] And then, at the end of the event loop, either end the trial if the target games count is reached or produce the observations as before. if state [ \"games_count\" ] >= environment_session . config . target_games_count : environment_session . end ( observations = observations ) else : environment_session . produce_observations ( observations = observations ) Edit the environment/main.py file to include the above additions. You can now build and run the application. It should be much faster than before as the AIs only play 5 games. Client actor implementation \u00b6 We are now ready to involve a human player in our trials. To do that we will add a specific actor implementation in the client. While the previous service actor implementations are exposing endpoints Cogment's orchestrator connects to in order to run a trial, this client actor implementation connects to the orchestrator to join a trial. It changes a lot under the hood and enables interesting network topology because only the client needs to know how to reach the orchestrator, not the other way around. However, as you'll see, in terms of implementation it is very similar. This actor implementation will be located in the client code in client/main.py We first need to import the data structures needed to send actions. from data_pb2 import PlayerAction , ROCK , PAPER , SCISSORS MOVES = [ ROCK , PAPER , SCISSORS ] In the main function we then implement the human_player actor implementation, only playing PAPER for the moment, register the implementation and join the trial once it is initialized. context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) async def human_player ( actor_session ): round_index = 0 actor_session . start () async for event in actor_session . event_loop (): if event . observation : observation = event . observation if event . type == cogment . EventType . ACTIVE : print ( f \" \\n -- Round # { round_index + 1 } -- \\n \" ) next_action = PlayerAction ( move = PAPER ) actor_session . do_action ( next_action ) round_index += 1 context . register_actor ( impl = human_player , impl_name = \"human\" , actor_classes = [ \"player\" ]) # Create a controller controller = context . get_controller ( endpoint = cogment . Endpoint ( \"orchestrator:9000\" )) # Start a new trial trial_id = await controller . start_trial ( trial_config = TrialConfig ()) print ( f \"Trial ' { trial_id } ' starting\" ) # Let the human actor join the trial await context . join_trial ( trial_id = trial_id , endpoint = cogment . Endpoint ( \"orchestrator:9000\" ), impl_name = \"human\" ) print ( f \"Human actor joining trial ' { trial_id } '\" ) # Wait for the trial to end by itself async for trial_info in controller . watch_trials ( trial_state_filters = [ cogment . TrialState . ENDED ]): if trial_info . trial_id == trial_id : break print ( f \"Trial ' { trial_id } ' ended\" ) Modify the client/main.py file with these updates. We then need to modify the cogment.yaml to let the orchestrator know that player_1 now uses a client-side implementation. To do so we use a special endpoint, \"client\" , and we don't need to specify an implementation name. actors : - name : player_1 actor_class : player endpoint : client # implementation: random_agent # endpoint: grpc://random-agent:9000 You can now build and run the application. Everything should work but player 1 shouldn't fare too well as it only ever plays PAPER . Interactive prompt to let Humans play RPS \u00b6 Let's add a text user interface to our client in order to finally challenge AIs to a game of RPS. First we'll want to display what was played in the previous round. We will implement a dedicated function print_observation . MOVES_STR = [ \"\ud83d\udc4a rock\" , \"\u270b paper\" , \"\u270c\ufe0f scissors\" ] def print_observation ( round_index , observation ): print ( f \"\ud83e\uddd1 played { MOVES_STR [ observation . snapshot . me . last_move ] } \" ) print ( f \"\ud83e\udd16 played { MOVES_STR [ observation . snapshot . them . last_move ] } \" ) if observation . snapshot . me . won_last : print ( f \" -> \ud83e\uddd1 wins round # { round_index + 1 } \" ) elif observation . snapshot . them . won_last : print ( f \" -> \ud83e\udd16 wins the round # { round_index + 1 } \" ) else : print ( f \" -> round # { round_index + 1 } is a draw\" ) It needs to be called whenever the actor receives an observation, except for the first time, before the first round is played. Add the following just after the observation is retrieved in the event loop. if round_index > 0 : # The only time the observation is not relevant is on the first round of the first game print_observation ( round_index , observation ) Last but not least, instead of always picking PAPER we will read from the keyboard input what the player wishes to play. Using python's input function we can print a prompt and read whatever the user enters before pressing <ENTER> . Note that the following implementation expects a number between 1 and 3 and doesn't handle well any other input. move = MOVES [ int ( input ( f \"What's your move: { ', ' . join ([ f \" { name } ( { idx + 1 } )\" for idx , name in enumerate ( MOVES_STR )]) } ? \" ))] next_action = PlayerAction ( move = move ) Modify the client/main.py file to include the above additions. You can now build and run the application. You'll be presented with a prompt for choosing your moves and comparing your skills to the simple heuristic AI we implemented earlier. This concludes the step 5 of the tutorial: you implemented your first client actor and put your first human in the loop! This is also the final step for the basics tutorial. You can continue by implementing a web client to replace the command line interface we just developed in step 6 . You can also learn how to train an actor implementation using Reinforcement Learning in step 7 .","title":"Step 5: Add a human player in the loop"},{"location":"cogment/tutorial/5-human-player/#step-5-add-a-human-player-in-the-loop","text":"This part of the tutorial follows step 4 , make sure you've gone through it before starting this one. Alternatively the completed step 4 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over another actor implementation, this time client-side, to enable Humans to play RPS. We will also learn how to let the environment control the termination of the trial.","title":"Step 5: Add a human player in the loop"},{"location":"cogment/tutorial/5-human-player/#the-client","text":"In the previous steps, we triggered the trials by running cogment run client . The more curious among you will have understood that this launches a client of the Cogment app, implemented in client/main.py . In this step, we will make changes to this file, this is therefore a good time to take a look at it. Open client/main.py and take a look at the generated content. The main starts similarly to the others by creating and configuring the main entry point to the SDK, Context . Then a trial_controller function is created: it enables retrieving the unique id for a trial and controls its lifetime (ending it by default after 10 seconds). Finally, a trial is started on the running orchestrator , using trial_controller and a default trial configuration. async def trial_controller ( control_session ): print ( f \"Trial ' { control_session . get_trial_id () } ' starts\" ) await asyncio . sleep ( 10 ) print ( f \"Trial ' { control_session . get_trial_id () } ' terminating\" ) await control_session . terminate_trial () await context . start_trial ( endpoint = \"orchestrator:9000\" , impl = trial_controller , trial_config = TrialConfig ())","title":"The client"},{"location":"cogment/tutorial/5-human-player/#environment-controlled-trial","text":"While 10 seconds was plenty of time to get a decent number of AI vs AI games played, a Human player won't be as fast: we need to change how we control the duration and number of played games. To do that, we will switch from controlling the trial lifetime from the client's trial controller, to controlling it from the environment. Instead of a duration, our trial will last for a given number of games. That way AI vs AI trials will be configurable to last hundreds of games while trials involving Humans can be much shorter. Let's introduce a new property of the environment configuration, target_games_count , in data.proto . message EnvConfig { int32 target_game_score = 1 ; int32 target_games_count = 2 ; } We can then set its value for the default trial in cogment.yaml . trial_params : environment : endpoint : grpc://environment:9000 config : target_game_score : 2 target_games_count : 5 Environment implementations can trigger the end of a trial by calling the end function on the session instance. In our existing implementation, we will first prepare the observations instead of producing them right away. observations = [ ( p1 . actor_name , Observation ( me = p1_state , them = p2_state )), ( p2 . actor_name , Observation ( me = p2_state , them = p1_state )), ] And then, at the end of the event loop, either end the trial if the target games count is reached or produce the observations as before. if state [ \"games_count\" ] >= environment_session . config . target_games_count : environment_session . end ( observations = observations ) else : environment_session . produce_observations ( observations = observations ) Edit the environment/main.py file to include the above additions. You can now build and run the application. It should be much faster than before as the AIs only play 5 games.","title":"Environment controlled trial"},{"location":"cogment/tutorial/5-human-player/#client-actor-implementation","text":"We are now ready to involve a human player in our trials. To do that we will add a specific actor implementation in the client. While the previous service actor implementations are exposing endpoints Cogment's orchestrator connects to in order to run a trial, this client actor implementation connects to the orchestrator to join a trial. It changes a lot under the hood and enables interesting network topology because only the client needs to know how to reach the orchestrator, not the other way around. However, as you'll see, in terms of implementation it is very similar. This actor implementation will be located in the client code in client/main.py We first need to import the data structures needed to send actions. from data_pb2 import PlayerAction , ROCK , PAPER , SCISSORS MOVES = [ ROCK , PAPER , SCISSORS ] In the main function we then implement the human_player actor implementation, only playing PAPER for the moment, register the implementation and join the trial once it is initialized. context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) async def human_player ( actor_session ): round_index = 0 actor_session . start () async for event in actor_session . event_loop (): if event . observation : observation = event . observation if event . type == cogment . EventType . ACTIVE : print ( f \" \\n -- Round # { round_index + 1 } -- \\n \" ) next_action = PlayerAction ( move = PAPER ) actor_session . do_action ( next_action ) round_index += 1 context . register_actor ( impl = human_player , impl_name = \"human\" , actor_classes = [ \"player\" ]) # Create a controller controller = context . get_controller ( endpoint = cogment . Endpoint ( \"orchestrator:9000\" )) # Start a new trial trial_id = await controller . start_trial ( trial_config = TrialConfig ()) print ( f \"Trial ' { trial_id } ' starting\" ) # Let the human actor join the trial await context . join_trial ( trial_id = trial_id , endpoint = cogment . Endpoint ( \"orchestrator:9000\" ), impl_name = \"human\" ) print ( f \"Human actor joining trial ' { trial_id } '\" ) # Wait for the trial to end by itself async for trial_info in controller . watch_trials ( trial_state_filters = [ cogment . TrialState . ENDED ]): if trial_info . trial_id == trial_id : break print ( f \"Trial ' { trial_id } ' ended\" ) Modify the client/main.py file with these updates. We then need to modify the cogment.yaml to let the orchestrator know that player_1 now uses a client-side implementation. To do so we use a special endpoint, \"client\" , and we don't need to specify an implementation name. actors : - name : player_1 actor_class : player endpoint : client # implementation: random_agent # endpoint: grpc://random-agent:9000 You can now build and run the application. Everything should work but player 1 shouldn't fare too well as it only ever plays PAPER .","title":"Client actor implementation"},{"location":"cogment/tutorial/5-human-player/#interactive-prompt-to-let-humans-play-rps","text":"Let's add a text user interface to our client in order to finally challenge AIs to a game of RPS. First we'll want to display what was played in the previous round. We will implement a dedicated function print_observation . MOVES_STR = [ \"\ud83d\udc4a rock\" , \"\u270b paper\" , \"\u270c\ufe0f scissors\" ] def print_observation ( round_index , observation ): print ( f \"\ud83e\uddd1 played { MOVES_STR [ observation . snapshot . me . last_move ] } \" ) print ( f \"\ud83e\udd16 played { MOVES_STR [ observation . snapshot . them . last_move ] } \" ) if observation . snapshot . me . won_last : print ( f \" -> \ud83e\uddd1 wins round # { round_index + 1 } \" ) elif observation . snapshot . them . won_last : print ( f \" -> \ud83e\udd16 wins the round # { round_index + 1 } \" ) else : print ( f \" -> round # { round_index + 1 } is a draw\" ) It needs to be called whenever the actor receives an observation, except for the first time, before the first round is played. Add the following just after the observation is retrieved in the event loop. if round_index > 0 : # The only time the observation is not relevant is on the first round of the first game print_observation ( round_index , observation ) Last but not least, instead of always picking PAPER we will read from the keyboard input what the player wishes to play. Using python's input function we can print a prompt and read whatever the user enters before pressing <ENTER> . Note that the following implementation expects a number between 1 and 3 and doesn't handle well any other input. move = MOVES [ int ( input ( f \"What's your move: { ', ' . join ([ f \" { name } ( { idx + 1 } )\" for idx , name in enumerate ( MOVES_STR )]) } ? \" ))] next_action = PlayerAction ( move = move ) Modify the client/main.py file to include the above additions. You can now build and run the application. You'll be presented with a prompt for choosing your moves and comparing your skills to the simple heuristic AI we implemented earlier. This concludes the step 5 of the tutorial: you implemented your first client actor and put your first human in the loop! This is also the final step for the basics tutorial. You can continue by implementing a web client to replace the command line interface we just developed in step 6 . You can also learn how to train an actor implementation using Reinforcement Learning in step 7 .","title":"Interactive prompt to let Humans play RPS"},{"location":"cogment/tutorial/6-web-client/","text":"Step 6: Add a web client for the human player \u00b6 This part of the tutorial follows step 5 , make sure you've gone through it before starting this one. Alternatively the completed step 5 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over a web client implementation, to enable Humans to play RPS, while being able to take advantage of various web technologies. Prerequisites \u00b6 To develop a web client, we will need a working installation of Node.js. You can download and install this from: https://nodejs.org/en/download/ The web client \u00b6 In the previous steps, we triggered the trials by running cogment run client . This launched a trial using code in client/main.py . In this step we will trigger a trial using a React app. Before we start with the Cogment side of things, we'll need to get a few prerequisite files setup. Creating a React app \u00b6 First, we will initialize a React app. This can be done very simply by running: $ npx create-React-app web-client Once this is done, we will be able to open a React app in our browser by running the following commands: $ cd web-client $ npm start Adding Material UI \u00b6 We will be using Material UI for this web client. This will provide us with a nice and clean way to add styles to our application, as well as some components which we will use to reduce code size. Install Material UI by running the following commands from inside of the web-client folder: $ npm i @mateiral-ui/core $ npm i @material-ui/icons Setting up Docker \u00b6 In addition to the docker-compose services we already have, we'll need two more for this web client. One to run it, and another for a proxy service called grpcwebproxy . NOTE: grpcwebproxy link is a helpful program that allows grpc endpoints to be utilized by web applications. Web applications cannot natively use the grpc protocol that all Cogment elements use to communicate with one another. Using this proxy to translate the web socket connections it accepts into grpc requests solves this issue. For these services, let's add the following to the end of our docker-compose.yaml: web-client : build : context : web-client dockerfile : ../js_service.dockerfile environment : - NODE_ENV=development - CHOKIDAR_USEPOLLING=true - REACT_APP_APP_VERSION=dev restart : on-failure ports : - \"3000:3000\" depends_on : - grpcwebproxy grpcwebproxy : build : context : ./grpcwebproxy dockerfile : ../grpcwebproxy.dockerfile restart : on-failure ports : - \"8080:8080\" depends_on : - orchestrator We will also need two additional dockerfiles to go along these entries. The first one will be grpcwebproxy.dockerfile , with the following content: FROM golang:1.15.2 as dev WORKDIR /go ARG GO111MODULE = auto ENV GO111MODULE = ${ GO111MODULE } ENV GOPATH = /go ENV COGMENT_URL = orchestrator:9000 RUN go get github.com/improbable-eng/grpc-web/go/grpcwebproxy EXPOSE 8080 CMD [ \"grpcwebproxy\" , \"--backend_addr=orchestrator:9000\" , \"--run_tls_server=false\" , \"--allow_all_origins\" , \"--use_websockets\" ] The second one will be js_service.dockerfile , with the following content: # pull official base image FROM node:14 as dev # set working directory WORKDIR /app EXPOSE 3000 # copy generated app COPY . ./ # start app CMD [ \"npm\" , \"start\" ] NOTE: Since the port for grpcwebproxy is exposed outside of the docker network, the docker-compose entry and corresponding dockerfile are not actually needed for the web-client; it can just as easily be run outside of docker. However, doing it like this makes the command to startup the application much simpler. Finally, we have to add web-client and grpcwebproxy to the start, build, and stop commands in our cogment.yaml . build : docker-compose build orchestrator environment random_agent web-client grpcwebproxy start : docker-compose up orchestrator environment random_agent web-client grpcwebproxy stop : docker-compose stop orchestrator environment random_agent web-client grpcwebproxy Adding Cogment to our web client \u00b6 The easiest way to add Cogment to any web client is to start with a React app, then follow the three steps below: Install the Javascript SDK using: $ npm i @cogment/cogment-js-sdk while inside of the web-client folder Copy in the hooks folder from the tutorial's repository , found at 6-web-client/web-client/src/hooks , into your src directory. Navigate one folder up to your project directory (where you have your cogment.yaml) then run the following command to generate Javascript files from your defined protobufs: $ cogment generate --js_dir = ./web-client NOTE: Had we chosen Y at the beginning of this tutorial when asked by the CLI if we wanted a web client, the React hooks used in this section would normally have been generated with the command cogment init .\" Now that all that's done, we can finally start coding our web client! CODE \u00b6 NOTE: For each of the following files, we will provide the styles in a code block. Feel free to skip these, or make your own; they are not important to the function of this application. index.js / index.css \u00b6 When we created our React app, these two files were generated automatically. Replace their content with the following: NOTE: These can also be downloaded from the tutorial's repository . index.css: body { margin : 0 ; background-color : #c5cce8 ; } index.js import React from \"React\"; import ReactDOM from \"React-dom\"; import \"./index.css\"; import { App } from \"./App\"; import { createMuiTheme, responsiveFontSizes, ThemeProvider, } from \"@material-ui/core/styles\"; let theme = createMuiTheme({ palette: { primary: { light: \"#c5cce8\", main: \"#6B80C4\", }, secondary: { main: \"#ffb400\", }, }, }); theme = responsiveFontSizes(theme); ReactDOM.render( <React.StrictMode> <ThemeProvider theme={theme}> <App /> </ThemeProvider> </React.StrictMode>, document.getElementById(\"root\") ); This is simply to provide styles to our Material UI components. We haven't started with the actual Cogment part yet, which is exactly what we'll be doing next. App.js \u00b6 We'll start with a few imports. Some of these files don't exist yet, so we'll be creating them: //First is some React imports import React, { useEffect } from \"React\"; //Then some imports for icons and Material UI functionality we'll be using import { Box, Button, makeStyles, Typography, useTheme, } from \"@material-ui/core\"; //And here's the important part: we're importing the two things that will allow us to use Cogment. //First, the 'useActions' hook which will give us our observations as a human agent, as well as allow us to send actions. import { useActions } from \"./hooks/useActions\"; //Second, our 'cogSettings'. This is a file that was generated when we ran //`cogment generate --js_dir=./webclient` //This file tells our web client relevant information about our trials, environments, and actor classes. import { cogSettings } from \"./CogSettings\"; //These are messages which were defined in data.proto. These imports will need to change whenever their corresponding messages in data.proto are changed and `cogment generate` is run. import { PlayerAction } from \"./data_pb\"; Then we add a function that will convert the play, encoded as the same \"move\" enum that we defined in our data.proto, to a string we can use in our application: function getMoveText(move) { switch (move) { case 0: return \"rock\"; case 1: return \"paper\"; case 2: return \"scissors\"; default: throw new Error(\"Not a rock, paper, or scissors\"); } } Finally, the React component. At the start of this component is the most important part of our application: the useAction hook. This hook returns an array with 3 elements: event: this contains all the information about any observation, reward, or message we've received this tick. We will use this to see what plays we and the computer made. startTrial: this is a function which takes no arguments, and is a very simple way to start a new trial with our player actor. sendAction: this is a function which takes an argument of type 'Action'. This class can be imported from data_pb.js, but we'll see that later in this tutorial. This hook takes in 3 arguments: cogSettings: this is what's imported from CogSettings.js. It provides all the relevant information about data.proto to this hook so that it can function. actorName: the name of the human actor which this web client will be representing. This is defined in cogment.yaml. actorClass: the class of the human actor which this web client will be representing. This is defined in cogment.yaml. export const App = () => { const [event, startTrial, sendAction] = useActions( cogSettings, \"player_1\", \"player\" ); //Function to construct the Action which the player will send when they click either rock, paper, or scissors const choose = (move) => { const action = new PlayerAction(); action.setMove(move); sendAction(action); }; //This will start a trial as soon as we're connected to the orchestrator useEffect(() => { if (startTrial) startTrial(); }, [startTrial]); //Get any observation from the current event, events have observations, messages, and rewards, and all three can be unpacked from the event object //We will also unpack a helpful variable called 'last', this will allow us to know when the trial has ended const { observation, last } = event; const [gameState, setGameState] = useState({ gameStage: \"start\", roundIndex: 0, lastMoveComputer: 0, lastMoveHuman: 0, }); const [firstObservation, setFirstObservation] = useState(true); useEffect(() => { //Parse game state out of the observation //Some events don't contain an observation, so we need to store the observation contents in a state if (!observation) return; //The first observation is not useful, as it just contains the default game state, before players have made moves if (firstObservation) { setFirstObservation(false); return; } //Get all relevant information from the observation const roundIndex = gameState.roundIndex + 1; const gameStage = \"playing\"; const lastMoveComputer = observation.them.lastMove; const lastMoveHuman = observation.me.lastMove; const lastWonComputer = observation.them.wonLast; const lastWonHuman = observation.me.wonLast; setGameState({ gameStage, roundIndex, lastMoveComputer, lastMoveHuman, lastWonComputer, lastWonHuman, }); // eslint-disable-next-line react-hooks/exhaustive-deps }, [observation]); //The layout of the page return ( <Box> {/* Tell the player everything we know about the trial state, such as, plays, who won, etc... */} <Typography>Game stage: {gameState.gameStage}</Typography> <Typography> Human's move:{\" \"} {gameState.gameStage !== \"start\" && getMoveText(gameState.lastMoveHuman)} </Typography> <Typography> Computer's move:{\" \"} {gameState.gameStage !== \"start\" && getMoveText(gameState.lastMoveComputer)} </Typography> <Typography> Did Human win last round?{\" \"} {observation && gameState.lastWonHuman ? \"Yes\" : \"No\"} </Typography> <Typography> Did Computer win last round?{\" \"} {observation && gameState.lastWonComputer ? \"Yes\" : \"No\"} </Typography> <Button onClick={() => choose(0)}>Rock</Button> <Button onClick={() => choose(1)}>Paper</Button> <Button onClick={() => choose(2)}>Scissors</Button> </Box> ); }; hooks/useActions.js \u00b6 This hook does multiple things. It starts a trial, joins a trial, sends actions, and receives information from the orchestrator. The following is its annotated code: import { useEffect, useState } from \"React\"; import * as cogment from \"@cogment/cogment-js-sdk\"; export const useActions = (cogSettings, actorName, actorClass) => { //Events are composed of a possible observation, message, and reward const [event, setEvent] = useState({ observation: null, message: null, reward: null, }); //startTrial and sendAction will be set after the connected agent joins the trial const [startTrial, setStartTrial] = useState(null); const [sendAction, setSendAction] = useState(null); //Set up the connection and register the actor only once //In this hook, the connected agent is immediatly registered to any existing trial sitting at port 8080 (more accurately any grpcwebproxy pointing to a trial). Most of the time, this is the desired behaviour, but it could be changed in different circumstances by replacing this with something like setState(joinTrial), similar to setStartTrial further down this code useEffect(() => { //First we create our service, which will be our primary point of contact to the orchestrator const service = cogment.createService({ cogSettings, //grpcURL is an optional argument that in fact defaults to the following value. Here we're just showing that it can be set explicitly grpcURL: window.location.protocol + \"//\" + window.location.hostname + \":8080\", }); //Set up the actor object. An actorName and an actorClass is enough to define a unique actor to be added to a trial const actor = { name: actorName, actorClass: actorClass }; //Use the service to register an actor. registerActor takes two arguments, the second of which is a callback function which is given the actorSession of the registered actor as its only argument. With the provided actorSession, we can send actions, and receive events. service.registerActor(actor, async (actorSession) => { //Start the session actorSession.start(); //Double arrow function here because React will turn a single one into a lazy loaded function setSendAction(() => (action) => { actorSession.sendAction(action); }); /*actorSession.eventLoop is an async generator function, meaning we can use the syntax for await(const foo of generator()){ do stuff } to run some code every time there's new data provided by the function. This is massively useful for network streams. */ for await (const { observation, message, reward, } of actorSession.eventLoop()) { //Parse the observation into a regular JS object //TODO: this will eventually be part of the API //Eventually observations will be regular Javascript objects (same with messages, and rewards). But for now we must convert it to an object. let observationOBJ = event.observation && event.observation.toObject(); event.observation = observationOBJ; //If the type of the event is 3 (Ending), store that in event.last so we can use it later event.last = event.type === 3; //Set the event state to the received event, causing a hook update setEvent(event); } }); //Creating the trial controller must happen after actors are registered const trialController = service.createTrialController(); //Need to output a function so that the user can start the trial when all actors are connected //Again, double arrow function cause React will turn a single one into a lazy loaded function setStartTrial(() => async () => { //Start and join the trial. When we start a trial, we receive an object containing the trialID that can then be used to join it. //We will almost always want to do both these actions in sequence, since trials do not proceed without the connected agent if cogment.yaml specifies that a connected agent exists const { trialId } = await trialController.startTrial(actor.actorClass); await trialController.joinTrial(trialId, actor); }); }, [cogSettings, actorName, actorClass]); return [event, startTrial, sendAction]; }; Please note that the useActions hook is generated by cogment init . We've still gone through it in this tutorial, because that is where most of the Cogment related code is contained, and it must be understood if we want to use Cogment without React.JS. You can now see our app fully functional by going to the folder where our cogment.yaml sits, and running the commands: $ cogment run build $ cogment run start And opening up localhost:3000 in our browser. And with that we're done! Making it look good \u00b6 If we want a fancier interface, there is a completed UI in the tutorials repository that we can copy into our project. Then, along with some style code that can be found in the repository version of App.js, just replace the return statement from App.js with the following: <Box> <Header observation={observation} gameState={gameState} /> <Container className={classes.container}> <Player score={humanScore} color={theme.palette.primary.main} IconClass={PersonIcon} choose={choose} isHuman /> <Player score={computerScore} color={theme.palette.secondary.main} IconClass={ComputerIcon} selected={ gameState !== \"start\" && getMoveText(observation.them.lastRoundMove) } /> </Container> </Box>","title":"Step 6: Implement a web client for the human player"},{"location":"cogment/tutorial/6-web-client/#step-6-add-a-web-client-for-the-human-player","text":"This part of the tutorial follows step 5 , make sure you've gone through it before starting this one. Alternatively the completed step 5 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over a web client implementation, to enable Humans to play RPS, while being able to take advantage of various web technologies.","title":"Step 6: Add a web client for the human player"},{"location":"cogment/tutorial/6-web-client/#prerequisites","text":"To develop a web client, we will need a working installation of Node.js. You can download and install this from: https://nodejs.org/en/download/","title":"Prerequisites"},{"location":"cogment/tutorial/6-web-client/#the-web-client","text":"In the previous steps, we triggered the trials by running cogment run client . This launched a trial using code in client/main.py . In this step we will trigger a trial using a React app. Before we start with the Cogment side of things, we'll need to get a few prerequisite files setup.","title":"The web client"},{"location":"cogment/tutorial/6-web-client/#creating-a-react-app","text":"First, we will initialize a React app. This can be done very simply by running: $ npx create-React-app web-client Once this is done, we will be able to open a React app in our browser by running the following commands: $ cd web-client $ npm start","title":"Creating a React app"},{"location":"cogment/tutorial/6-web-client/#adding-material-ui","text":"We will be using Material UI for this web client. This will provide us with a nice and clean way to add styles to our application, as well as some components which we will use to reduce code size. Install Material UI by running the following commands from inside of the web-client folder: $ npm i @mateiral-ui/core $ npm i @material-ui/icons","title":"Adding Material UI"},{"location":"cogment/tutorial/6-web-client/#setting-up-docker","text":"In addition to the docker-compose services we already have, we'll need two more for this web client. One to run it, and another for a proxy service called grpcwebproxy . NOTE: grpcwebproxy link is a helpful program that allows grpc endpoints to be utilized by web applications. Web applications cannot natively use the grpc protocol that all Cogment elements use to communicate with one another. Using this proxy to translate the web socket connections it accepts into grpc requests solves this issue. For these services, let's add the following to the end of our docker-compose.yaml: web-client : build : context : web-client dockerfile : ../js_service.dockerfile environment : - NODE_ENV=development - CHOKIDAR_USEPOLLING=true - REACT_APP_APP_VERSION=dev restart : on-failure ports : - \"3000:3000\" depends_on : - grpcwebproxy grpcwebproxy : build : context : ./grpcwebproxy dockerfile : ../grpcwebproxy.dockerfile restart : on-failure ports : - \"8080:8080\" depends_on : - orchestrator We will also need two additional dockerfiles to go along these entries. The first one will be grpcwebproxy.dockerfile , with the following content: FROM golang:1.15.2 as dev WORKDIR /go ARG GO111MODULE = auto ENV GO111MODULE = ${ GO111MODULE } ENV GOPATH = /go ENV COGMENT_URL = orchestrator:9000 RUN go get github.com/improbable-eng/grpc-web/go/grpcwebproxy EXPOSE 8080 CMD [ \"grpcwebproxy\" , \"--backend_addr=orchestrator:9000\" , \"--run_tls_server=false\" , \"--allow_all_origins\" , \"--use_websockets\" ] The second one will be js_service.dockerfile , with the following content: # pull official base image FROM node:14 as dev # set working directory WORKDIR /app EXPOSE 3000 # copy generated app COPY . ./ # start app CMD [ \"npm\" , \"start\" ] NOTE: Since the port for grpcwebproxy is exposed outside of the docker network, the docker-compose entry and corresponding dockerfile are not actually needed for the web-client; it can just as easily be run outside of docker. However, doing it like this makes the command to startup the application much simpler. Finally, we have to add web-client and grpcwebproxy to the start, build, and stop commands in our cogment.yaml . build : docker-compose build orchestrator environment random_agent web-client grpcwebproxy start : docker-compose up orchestrator environment random_agent web-client grpcwebproxy stop : docker-compose stop orchestrator environment random_agent web-client grpcwebproxy","title":"Setting up Docker"},{"location":"cogment/tutorial/6-web-client/#adding-cogment-to-our-web-client","text":"The easiest way to add Cogment to any web client is to start with a React app, then follow the three steps below: Install the Javascript SDK using: $ npm i @cogment/cogment-js-sdk while inside of the web-client folder Copy in the hooks folder from the tutorial's repository , found at 6-web-client/web-client/src/hooks , into your src directory. Navigate one folder up to your project directory (where you have your cogment.yaml) then run the following command to generate Javascript files from your defined protobufs: $ cogment generate --js_dir = ./web-client NOTE: Had we chosen Y at the beginning of this tutorial when asked by the CLI if we wanted a web client, the React hooks used in this section would normally have been generated with the command cogment init .\" Now that all that's done, we can finally start coding our web client!","title":"Adding Cogment to our web client"},{"location":"cogment/tutorial/6-web-client/#code","text":"NOTE: For each of the following files, we will provide the styles in a code block. Feel free to skip these, or make your own; they are not important to the function of this application.","title":"CODE"},{"location":"cogment/tutorial/6-web-client/#indexjs-indexcss","text":"When we created our React app, these two files were generated automatically. Replace their content with the following: NOTE: These can also be downloaded from the tutorial's repository . index.css: body { margin : 0 ; background-color : #c5cce8 ; } index.js import React from \"React\"; import ReactDOM from \"React-dom\"; import \"./index.css\"; import { App } from \"./App\"; import { createMuiTheme, responsiveFontSizes, ThemeProvider, } from \"@material-ui/core/styles\"; let theme = createMuiTheme({ palette: { primary: { light: \"#c5cce8\", main: \"#6B80C4\", }, secondary: { main: \"#ffb400\", }, }, }); theme = responsiveFontSizes(theme); ReactDOM.render( <React.StrictMode> <ThemeProvider theme={theme}> <App /> </ThemeProvider> </React.StrictMode>, document.getElementById(\"root\") ); This is simply to provide styles to our Material UI components. We haven't started with the actual Cogment part yet, which is exactly what we'll be doing next.","title":"index.js / index.css"},{"location":"cogment/tutorial/6-web-client/#appjs","text":"We'll start with a few imports. Some of these files don't exist yet, so we'll be creating them: //First is some React imports import React, { useEffect } from \"React\"; //Then some imports for icons and Material UI functionality we'll be using import { Box, Button, makeStyles, Typography, useTheme, } from \"@material-ui/core\"; //And here's the important part: we're importing the two things that will allow us to use Cogment. //First, the 'useActions' hook which will give us our observations as a human agent, as well as allow us to send actions. import { useActions } from \"./hooks/useActions\"; //Second, our 'cogSettings'. This is a file that was generated when we ran //`cogment generate --js_dir=./webclient` //This file tells our web client relevant information about our trials, environments, and actor classes. import { cogSettings } from \"./CogSettings\"; //These are messages which were defined in data.proto. These imports will need to change whenever their corresponding messages in data.proto are changed and `cogment generate` is run. import { PlayerAction } from \"./data_pb\"; Then we add a function that will convert the play, encoded as the same \"move\" enum that we defined in our data.proto, to a string we can use in our application: function getMoveText(move) { switch (move) { case 0: return \"rock\"; case 1: return \"paper\"; case 2: return \"scissors\"; default: throw new Error(\"Not a rock, paper, or scissors\"); } } Finally, the React component. At the start of this component is the most important part of our application: the useAction hook. This hook returns an array with 3 elements: event: this contains all the information about any observation, reward, or message we've received this tick. We will use this to see what plays we and the computer made. startTrial: this is a function which takes no arguments, and is a very simple way to start a new trial with our player actor. sendAction: this is a function which takes an argument of type 'Action'. This class can be imported from data_pb.js, but we'll see that later in this tutorial. This hook takes in 3 arguments: cogSettings: this is what's imported from CogSettings.js. It provides all the relevant information about data.proto to this hook so that it can function. actorName: the name of the human actor which this web client will be representing. This is defined in cogment.yaml. actorClass: the class of the human actor which this web client will be representing. This is defined in cogment.yaml. export const App = () => { const [event, startTrial, sendAction] = useActions( cogSettings, \"player_1\", \"player\" ); //Function to construct the Action which the player will send when they click either rock, paper, or scissors const choose = (move) => { const action = new PlayerAction(); action.setMove(move); sendAction(action); }; //This will start a trial as soon as we're connected to the orchestrator useEffect(() => { if (startTrial) startTrial(); }, [startTrial]); //Get any observation from the current event, events have observations, messages, and rewards, and all three can be unpacked from the event object //We will also unpack a helpful variable called 'last', this will allow us to know when the trial has ended const { observation, last } = event; const [gameState, setGameState] = useState({ gameStage: \"start\", roundIndex: 0, lastMoveComputer: 0, lastMoveHuman: 0, }); const [firstObservation, setFirstObservation] = useState(true); useEffect(() => { //Parse game state out of the observation //Some events don't contain an observation, so we need to store the observation contents in a state if (!observation) return; //The first observation is not useful, as it just contains the default game state, before players have made moves if (firstObservation) { setFirstObservation(false); return; } //Get all relevant information from the observation const roundIndex = gameState.roundIndex + 1; const gameStage = \"playing\"; const lastMoveComputer = observation.them.lastMove; const lastMoveHuman = observation.me.lastMove; const lastWonComputer = observation.them.wonLast; const lastWonHuman = observation.me.wonLast; setGameState({ gameStage, roundIndex, lastMoveComputer, lastMoveHuman, lastWonComputer, lastWonHuman, }); // eslint-disable-next-line react-hooks/exhaustive-deps }, [observation]); //The layout of the page return ( <Box> {/* Tell the player everything we know about the trial state, such as, plays, who won, etc... */} <Typography>Game stage: {gameState.gameStage}</Typography> <Typography> Human's move:{\" \"} {gameState.gameStage !== \"start\" && getMoveText(gameState.lastMoveHuman)} </Typography> <Typography> Computer's move:{\" \"} {gameState.gameStage !== \"start\" && getMoveText(gameState.lastMoveComputer)} </Typography> <Typography> Did Human win last round?{\" \"} {observation && gameState.lastWonHuman ? \"Yes\" : \"No\"} </Typography> <Typography> Did Computer win last round?{\" \"} {observation && gameState.lastWonComputer ? \"Yes\" : \"No\"} </Typography> <Button onClick={() => choose(0)}>Rock</Button> <Button onClick={() => choose(1)}>Paper</Button> <Button onClick={() => choose(2)}>Scissors</Button> </Box> ); };","title":"App.js"},{"location":"cogment/tutorial/6-web-client/#hooksuseactionsjs","text":"This hook does multiple things. It starts a trial, joins a trial, sends actions, and receives information from the orchestrator. The following is its annotated code: import { useEffect, useState } from \"React\"; import * as cogment from \"@cogment/cogment-js-sdk\"; export const useActions = (cogSettings, actorName, actorClass) => { //Events are composed of a possible observation, message, and reward const [event, setEvent] = useState({ observation: null, message: null, reward: null, }); //startTrial and sendAction will be set after the connected agent joins the trial const [startTrial, setStartTrial] = useState(null); const [sendAction, setSendAction] = useState(null); //Set up the connection and register the actor only once //In this hook, the connected agent is immediatly registered to any existing trial sitting at port 8080 (more accurately any grpcwebproxy pointing to a trial). Most of the time, this is the desired behaviour, but it could be changed in different circumstances by replacing this with something like setState(joinTrial), similar to setStartTrial further down this code useEffect(() => { //First we create our service, which will be our primary point of contact to the orchestrator const service = cogment.createService({ cogSettings, //grpcURL is an optional argument that in fact defaults to the following value. Here we're just showing that it can be set explicitly grpcURL: window.location.protocol + \"//\" + window.location.hostname + \":8080\", }); //Set up the actor object. An actorName and an actorClass is enough to define a unique actor to be added to a trial const actor = { name: actorName, actorClass: actorClass }; //Use the service to register an actor. registerActor takes two arguments, the second of which is a callback function which is given the actorSession of the registered actor as its only argument. With the provided actorSession, we can send actions, and receive events. service.registerActor(actor, async (actorSession) => { //Start the session actorSession.start(); //Double arrow function here because React will turn a single one into a lazy loaded function setSendAction(() => (action) => { actorSession.sendAction(action); }); /*actorSession.eventLoop is an async generator function, meaning we can use the syntax for await(const foo of generator()){ do stuff } to run some code every time there's new data provided by the function. This is massively useful for network streams. */ for await (const { observation, message, reward, } of actorSession.eventLoop()) { //Parse the observation into a regular JS object //TODO: this will eventually be part of the API //Eventually observations will be regular Javascript objects (same with messages, and rewards). But for now we must convert it to an object. let observationOBJ = event.observation && event.observation.toObject(); event.observation = observationOBJ; //If the type of the event is 3 (Ending), store that in event.last so we can use it later event.last = event.type === 3; //Set the event state to the received event, causing a hook update setEvent(event); } }); //Creating the trial controller must happen after actors are registered const trialController = service.createTrialController(); //Need to output a function so that the user can start the trial when all actors are connected //Again, double arrow function cause React will turn a single one into a lazy loaded function setStartTrial(() => async () => { //Start and join the trial. When we start a trial, we receive an object containing the trialID that can then be used to join it. //We will almost always want to do both these actions in sequence, since trials do not proceed without the connected agent if cogment.yaml specifies that a connected agent exists const { trialId } = await trialController.startTrial(actor.actorClass); await trialController.joinTrial(trialId, actor); }); }, [cogSettings, actorName, actorClass]); return [event, startTrial, sendAction]; }; Please note that the useActions hook is generated by cogment init . We've still gone through it in this tutorial, because that is where most of the Cogment related code is contained, and it must be understood if we want to use Cogment without React.JS. You can now see our app fully functional by going to the folder where our cogment.yaml sits, and running the commands: $ cogment run build $ cogment run start And opening up localhost:3000 in our browser. And with that we're done!","title":"hooks/useActions.js"},{"location":"cogment/tutorial/6-web-client/#making-it-look-good","text":"If we want a fancier interface, there is a completed UI in the tutorials repository that we can copy into our project. Then, along with some style code that can be found in the repository version of App.js, just replace the return statement from App.js with the following: <Box> <Header observation={observation} gameState={gameState} /> <Container className={classes.container}> <Player score={humanScore} color={theme.palette.primary.main} IconClass={PersonIcon} choose={choose} isHuman /> <Player score={computerScore} color={theme.palette.secondary.main} IconClass={ComputerIcon} selected={ gameState !== \"start\" && getMoveText(observation.them.lastRoundMove) } /> </Container> </Box>","title":"Making it look good"},{"location":"cogment/tutorial/7-dqn-player/","text":"Step 7: Add a web client for the human player \u00b6 This part of the tutorial follows step 5 and step 6 , make sure you've gone through either one of those before starting this one. Alternatively the completed step 5 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over yet another actor implementation and this implementation will be learning from its experience. We will implement an RPS player using Reinforcement Learning (RL) and more precisely a Deep Q Network , one of the foundational algorithm of modern RL. While we will explain some aspects of RL and DQN along the way, we won't go into all the details. Interested readers can refer to \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto or to the original Deep Q Network article linked above. Creating an actor service \u00b6 Back in step 4 , we created a new implementation of the player actor class in the same service as the previous one. It was a sound choice for this implementation because it was small and didn't require additional dependencies. In some cases it makes more sense to create a fully separated service for a new actor implementation. This is what we will do here. Start by copy/pasting the random_agent folder and name the copy dqn_agent . Let's then clean up dqn_agent/main.py to keep only a single actor implentation and name it dqn_agent . You should have something like the following. import cog_settings from data_pb2 import PlayerAction import cogment import asyncio import random async def dqn_agent ( actor_session ): # ... async def main (): print ( \"Deep Q Network agents service up and running.\" ) context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = dqn_agent , impl_name = \"dqn_agent\" , actor_classes = [ \"player\" , ], ) await context . serve_all_registered ( cogment . ServedEndpoint ( port = 9000 )) if __name__ == \"__main__\" : asyncio . run ( main ()) Since we have created a new service we need to reference it at several places for everything to work properly. First, let's edit docker-compose.yaml to add the new service. To do that simply add the following under the services key, it tells docker-compose about the new service. dqn-agent : build : context : dqn_agent dockerfile : ../py_service.dockerfile Then we will need to edit cogment.yaml to make cogment run generate run in the new service's directory and have cogment run build and cogment run start respectively trigger its build and its start. We will change the generate , build and start key under commands . commands : generate : > cogment generate --python_dir environment --python_dir client --python_dir random_agent --python_dir dqn_agent # ... build : docker-compose build client dashboard metrics orchestrator environment random-agent dqn-agent # ... start : docker-compose up dashboard metrics orchestrator environment random-agent dqn-agent Finally, the metrics server needs to know about this new data source. In metrics/prometheus.yml , add a new item under the scrape_configs key. - job_name : \"dqn-agent\" dns_sd_configs : - names : - \"dqn-agent\" type : \"A\" port : 8000 refresh_interval : 5s Playing against the heuristic player \u00b6 We will train our new player against the heuristic player we previously developed. We first need to update the trial config in cogment.yaml : player_1 will be our new actor implementation while player_2 will be the heuristic implementation, trials will be 20 games long to generate enough meaningful data between each training steps. trial_params : environment : endpoint : grpc://environment:9000 config : target_game_score : 2 target_games_count : 20 actors : - name : player_1 actor_class : player implementation : dqn_agent endpoint : grpc://dqn-agent:9000 - name : player_2 actor_class : player implementation : heuristic_agent endpoint : grpc://random-agent:9000 We can also update client/main.py to run a bunch of trials sequentially. async def main (): print ( \"Client starting...\" ) context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) # Create a controller controller = context . get_controller ( endpoint = cogment . Endpoint ( \"orchestrator:9000\" )) # Start a trial campaign for i in range ( 1000 ): trial_id = await controller . start_trial ( trial_config = TrialConfig ()) print ( f \"Running trial # { i + 1 } with id ' { trial_id } '\" ) # Wait for the trial to end by itself async for trial_info in controller . watch_trials ( trial_state_filters = [ cogment . TrialState . ENDED ] ): if trial_info . trial_id == trial_id : break You can now build and run the application. It should take a few minutes to run as it goes through the trial campaign. Implementing the Deep Q Network \u00b6 We have set everything up, we can now focus on implementing our DQN agent. A Deep Q Network is a neural network taking an observation as input, and outputs the Q value for each of the actions in the action space. The Q Value is an estimation of the expected value of all the rewards if a given action is taken. The DQN agent action policy is therefore to take the action having the largest predicted Q Value. Let's start by implementing this part and we will then deal with training this model. In the rest of this tutorial we will use Tensorflow and its Keras API for the model itself, as well as numpy for datastructures. Let's import these at the top of dqn_agent/main.py . import numpy as np import tensorflow as tf Let's get into the meat of the matter by implementing a function to create our model. We are using Keras functional API to create the following layers: Two scalar inputs, the last moves of the player and the opponent. Each input is one-hot encoded to avoid assuming an unwanted ordering and quantitative relationship between the moves. The two encoded inputs are concatenated to a single vector. A dense non-linear hidden layer is added. The output layers estimates the Q value for each move. Everything then gets wrapped up and returned. This function is then used to create a global _model that we will use in the actor implementation. MOVES = [ ROCK , PAPER , SCISSORS ] actions_count = len ( MOVES ) def create_model (): # 1. Input layers in_me_last_move = tf . keras . Input ( name = \"obs_me_last_move\" , shape = ( 1 )) in_them_last_move = tf . keras . Input ( name = \"obs_them_last_move\" , shape = ( 1 )) # 2. One hot encoding of the layers one_hot_move = tf . keras . layers . experimental . preprocessing . CategoryEncoding ( name = \"one_hot_move\" , max_tokens = len ( MOVES ), output_mode = \"binary\" ) one_hot_me_last_move = one_hot_move ( in_me_last_move ) one_hot_them_last_move = one_hot_move ( in_them_last_move ) # 3. Concatenating the two inputs concat_ins = tf . keras . layers . concatenate ( [ one_hot_me_last_move , one_hot_them_last_move ] ) # 4. Dense hidden layer hidden_layer = tf . keras . layers . Dense ( 24 , activation = \"relu\" )( concat_ins ) # 5. Output outs = tf . keras . layers . Dense ( actions_count , activation = \"linear\" )( hidden_layer ) return tf . keras . Model ( inputs = [ in_me_last_move , in_them_last_move ], outputs = outs , name = \"rps_dqn_policy\" ) _model = create_model () The other piece of the puzzle is implementing a small function that'll convert our observations into inputs for the model we just created. As most of the encoding is handled by the model itself it's fairly straightforward. def model_ins_from_observations ( observations ): return { \"obs_me_last_move\" : np . array ([[ o . snapshot . me . last_move ] for o in observations ]), \"obs_them_last_move\" : np . array ( [[ o . snapshot . them . last_move ] for o in observations ] ), } Finally we can make it work together by replacing the random choice of action by the use of the model. At the moment the model will just use the random initialization weights so don't expect much ! Here is how the event loop in the dqn_agent function will need to be updated to: Use model_ins_from_observations to compute the model inputs, Use the model in inference mode to compute the q value of each of the possible actions, Finally do the action having the largest q value. if event . observation : model_ins = model_ins_from_observations ([ event . observation ]) if event . type == cogment . EventType . ACTIVE : model_outs = _model ( model_ins , training = False ) action = tf . math . argmax ( model_outs [ 0 ]) . numpy () actor_session . do_action ( PlayerAction ( move = action )) You can now build and run the application. It should take a few minutes to run as it goes through the trial campaign. In this example we define _model (and other variables in the following sections) as global mutable variables. It works in our case because the dqn agents are neither distributed nor multithreaded. Random exploration \u00b6 With the previous code, you might have noticed that the agent will play exactly the same action given the same set of observations, this is because the weights of the model are fixed. However, especially at the beginning of the training process we want the agent to experience a variety of situations. We address this issue by introducing a decaying exploration rate epsilon . First we will define as global variables, the parameters for this epsilon value: its minimum value, its maximum and initial value and its decay per tick. We also define as a global variable the current value of epsilon. You can add the following after the imports in dqn_agent/main.py . epsilon_min = 0.05 epsilon_max = 1.0 epsilon_decay_per_tick = ( epsilon_max - epsilon_min ) / 1000.0 # Linearly reach the lowest exploration rate after 1000 ticks _epsilon = epsilon_max We then create a simple function we can use everytime an action needs to be taken to retrieve and update _epsilon def get_and_update_epsilon (): global _epsilon current_epsilon = _epsilon _epsilon -= epsilon_decay_per_tick _epsilon = max ( _epsilon , epsilon_min ) return current_epsilon This function can then be used to do random actions occasionally to facilitate the exploration. To do that, we need to modify slightly how the actions are computed and submitted. if event . type == cogment . EventType . ACTIVE : if np . random . rand ( 1 )[ 0 ] < get_and_update_epsilon (): # Take random action action = np . random . choice ( actions_count ) else : model_outs = _model ( model_ins , training = False ) action = tf . math . argmax ( model_outs [ 0 ]) . numpy () actor_session . do_action ( PlayerAction ( move = action )) You can now build and run the application. Nothing should appear different at this stage. Replay buffer \u00b6 In our journey to train a model, the next stage is to build an experience replay buffer to collect actions/observations/rewards triples over the course of the trials. Once done, it'll be usable to train the model using this data. We will start by creating the datastructure. We are using a column-oriented structure relying on numpy arrays as they interoperate easily with tensorflow and support the needed manipulation primitives. Each row is a sample corresponding to one tick: the received observation and reward, the selected action as well as the next tick's received observation. def create_replay_buffer (): return { \"obs_me_last_move\" : np . array ([]), \"obs_them_last_move\" : np . array ([]), \"action\" : np . array ([]), \"reward\" : np . array ([]), \"next_obs_me_last_move\" : np . array ([]), \"next_obs_them_last_move\" : np . array ([]), } _rb = create_replay_buffer () During each trial the agent will collect its data points in a trial replay buffer then append it to the global one. To achieve that we will first create the function in charge of the appending then collect data during the trial and call the \"append\" function. The following function will take a trial replay buffer and append it to the global _rb . To avoid memory overflow the replay buffer size is capped. _collected_samples_count = 0 max_replay_buffer_size = 100000 def append_trial_replay_buffer ( trial_rb ): global _rb global _collected_samples_count trial_rb_size = len ( trial_rb [ \"obs_me_last_move\" ]) for key in _rb . keys (): # Append the trial data to the current vector _rb [ key ] = np . append ( _rb [ key ], trial_rb [ key ]) # Enfore the size limit by discarding older data if len ( _rb [ key ]) > max_replay_buffer_size : _rb [ key ] = _rb [ key ][ - max_replay_buffer_size :] _collected_samples_count += trial_rb_size rb_size = len ( _rb [ \"obs_me_last_move\" ]) # Sanity check, all vectors in the replay buffer should have the same size for key in _rb . keys (): assert rb_size == len ( _rb [ key ]) print ( f \" { trial_rb_size } new samples stored after a trial, now having { rb_size } samples over a total of { _collected_samples_count } collected samples.\" ) The dqn_agent function can then be updated to collect received observations and reward and sent actions. By default every action gets a zero reward. When a reward for a specific tick is received its value gets updated. async def dqn_agent ( actor_session ): actor_session . start () trial_rb = create_replay_buffer () async for event in actor_session . event_loop (): if event . observation : model_ins = model_ins_from_observations ([ event . observation ]) if event . type == cogment . EventType . ACTIVE : # [...] trial_rb [ \"obs_me_last_move\" ] = np . append ( trial_rb [ \"obs_me_last_move\" ], model_ins [ \"obs_me_last_move\" ] ) trial_rb [ \"obs_them_last_move\" ] = np . append ( trial_rb [ \"obs_them_last_move\" ], model_ins [ \"obs_them_last_move\" ] ) trial_rb [ \"action\" ] = np . append ( trial_rb [ \"action\" ], [ action ]) trial_rb [ \"reward\" ] = np . append ( trial_rb [ \"reward\" ], [ 0.0 ]) else : trial_rb [ \"obs_me_last_move\" ] = np . append ( trial_rb [ \"obs_me_last_move\" ], model_ins [ \"obs_me_last_move\" ] ) trial_rb [ \"obs_them_last_move\" ] = np . append ( trial_rb [ \"obs_them_last_move\" ], model_ins [ \"obs_them_last_move\" ] ) for reward in event . rewards : trial_rb [ \"reward\" ][ reward . tick_id ] = reward . value # Shifting the observations to get the next observations trial_rb [ \"next_obs_me_last_move\" ] = trial_rb [ \"obs_me_last_move\" ][ 1 :] trial_rb [ \"next_obs_them_last_move\" ] = trial_rb [ \"obs_them_last_move\" ][ 1 :] # Dropping the last row, as it only contains the last observations trial_rb [ \"obs_me_last_move\" ] = trial_rb [ \"obs_me_last_move\" ][: - 1 ] trial_rb [ \"obs_them_last_move\" ] = trial_rb [ \"obs_them_last_move\" ][: - 1 ] append_trial_replay_buffer ( trial_rb ) You can now build and run the application. The behavior should be the same but the log should confirm that data gets accumulated. Training! \u00b6 Here we are, all the pieces are in place we can implement the training proper. The function is a standard implementation of DQN and is decomposed in 4 steps: Select a random batch of samples from the replay buffer Compute the target Q value for each sample from the received reward and the next observation using a previous version of the model. (Re)compute the estimated Q value of each sample from the selected action and observation using the current version of the model. Perform an optimization step of the model parameters trying to reduce the loss between the samples estimated and target q values. batch_size = 50 # Size of batch taken from replay buffer gamma = 0.99 # Discount factor for future rewards optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.00025 , clipnorm = 1.0 ) loss_function = tf . keras . losses . Huber () target_model_update_interval = 1000 _target_model = create_model () def train (): global _model global _target_model rb_size = len ( _rb [ \"obs_me_last_move\" ]) if rb_size >= batch_size : # Step 1 - Randomly select a batch batch_indices = np . random . choice ( range ( rb_size ), size = batch_size ) batch_rb = create_replay_buffer () for key in batch_rb . keys (): batch_rb [ key ] = np . take ( _rb [ key ], batch_indices ) # Step 2 - Compute target q values ## Predict the expected reward for the next observation of each sample ## Use the target model for stability target_actions_q_values = _target_model ( { \"obs_me_last_move\" : batch_rb [ \"next_obs_me_last_move\" ], \"obs_them_last_move\" : batch_rb [ \"next_obs_them_last_move\" ], } ) ## target Q value = reward + discount factor * expected future reward target_q_values = batch_rb [ \"reward\" ] + gamma * tf . reduce_max ( target_actions_q_values , axis = 1 ) # Step 3 - Compute estimated q values ## Create masks of the taken actions to later select relevant q values selected_actions_masks = tf . one_hot ( batch_rb [ \"action\" ], actions_count ) with tf . GradientTape () as tape : ## Recompute q values for all the actions at each sample estimated_actions_q_values = _model ( { \"obs_me_last_move\" : batch_rb [ \"obs_me_last_move\" ], \"obs_them_last_move\" : batch_rb [ \"obs_them_last_move\" ], } ) ## Apply the masks to get the Q value for taken actions estimated_q_values = tf . reduce_sum ( tf . multiply ( estimated_actions_q_values , selected_actions_masks ), axis = 1 ) ## Compute loss between the target Q values and the estimated Q values loss = loss_function ( target_q_values , estimated_q_values ) print ( f \"loss= { loss . numpy () } \" ) ## Backpropagation! grads = tape . gradient ( loss , _model . trainable_variables ) optimizer . apply_gradients ( zip ( grads , _model . trainable_variables )) # Update the target model if _collected_samples_count % target_model_update_interval == 0 : _target_model . set_weights ( _model . get_weights ()) This function then needs to be called at the end of each trial after the call to append_trial_replay_buffer . You can now build and run the application. The dqn agent will start to learn and quickly prevails against the heuristic implementation. This can be observed by opening the dashboard at http://localhost:3003 and opening the reward page. You should be able to track the progression of the dqn implementation. This concludes the step 7 of the tutorial: you implemented your first trained actor implementation!","title":"Step 7: Add a player trained with Reinforcement Learning using DQN"},{"location":"cogment/tutorial/7-dqn-player/#step-7-add-a-web-client-for-the-human-player","text":"This part of the tutorial follows step 5 and step 6 , make sure you've gone through either one of those before starting this one. Alternatively the completed step 5 can be retrieved from the tutorial's repository . In this step of the tutorial, we will go over yet another actor implementation and this implementation will be learning from its experience. We will implement an RPS player using Reinforcement Learning (RL) and more precisely a Deep Q Network , one of the foundational algorithm of modern RL. While we will explain some aspects of RL and DQN along the way, we won't go into all the details. Interested readers can refer to \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto or to the original Deep Q Network article linked above.","title":"Step 7: Add a web client for the human player"},{"location":"cogment/tutorial/7-dqn-player/#creating-an-actor-service","text":"Back in step 4 , we created a new implementation of the player actor class in the same service as the previous one. It was a sound choice for this implementation because it was small and didn't require additional dependencies. In some cases it makes more sense to create a fully separated service for a new actor implementation. This is what we will do here. Start by copy/pasting the random_agent folder and name the copy dqn_agent . Let's then clean up dqn_agent/main.py to keep only a single actor implentation and name it dqn_agent . You should have something like the following. import cog_settings from data_pb2 import PlayerAction import cogment import asyncio import random async def dqn_agent ( actor_session ): # ... async def main (): print ( \"Deep Q Network agents service up and running.\" ) context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) context . register_actor ( impl = dqn_agent , impl_name = \"dqn_agent\" , actor_classes = [ \"player\" , ], ) await context . serve_all_registered ( cogment . ServedEndpoint ( port = 9000 )) if __name__ == \"__main__\" : asyncio . run ( main ()) Since we have created a new service we need to reference it at several places for everything to work properly. First, let's edit docker-compose.yaml to add the new service. To do that simply add the following under the services key, it tells docker-compose about the new service. dqn-agent : build : context : dqn_agent dockerfile : ../py_service.dockerfile Then we will need to edit cogment.yaml to make cogment run generate run in the new service's directory and have cogment run build and cogment run start respectively trigger its build and its start. We will change the generate , build and start key under commands . commands : generate : > cogment generate --python_dir environment --python_dir client --python_dir random_agent --python_dir dqn_agent # ... build : docker-compose build client dashboard metrics orchestrator environment random-agent dqn-agent # ... start : docker-compose up dashboard metrics orchestrator environment random-agent dqn-agent Finally, the metrics server needs to know about this new data source. In metrics/prometheus.yml , add a new item under the scrape_configs key. - job_name : \"dqn-agent\" dns_sd_configs : - names : - \"dqn-agent\" type : \"A\" port : 8000 refresh_interval : 5s","title":"Creating an actor service"},{"location":"cogment/tutorial/7-dqn-player/#playing-against-the-heuristic-player","text":"We will train our new player against the heuristic player we previously developed. We first need to update the trial config in cogment.yaml : player_1 will be our new actor implementation while player_2 will be the heuristic implementation, trials will be 20 games long to generate enough meaningful data between each training steps. trial_params : environment : endpoint : grpc://environment:9000 config : target_game_score : 2 target_games_count : 20 actors : - name : player_1 actor_class : player implementation : dqn_agent endpoint : grpc://dqn-agent:9000 - name : player_2 actor_class : player implementation : heuristic_agent endpoint : grpc://random-agent:9000 We can also update client/main.py to run a bunch of trials sequentially. async def main (): print ( \"Client starting...\" ) context = cogment . Context ( cog_settings = cog_settings , user_id = \"rps\" ) # Create a controller controller = context . get_controller ( endpoint = cogment . Endpoint ( \"orchestrator:9000\" )) # Start a trial campaign for i in range ( 1000 ): trial_id = await controller . start_trial ( trial_config = TrialConfig ()) print ( f \"Running trial # { i + 1 } with id ' { trial_id } '\" ) # Wait for the trial to end by itself async for trial_info in controller . watch_trials ( trial_state_filters = [ cogment . TrialState . ENDED ] ): if trial_info . trial_id == trial_id : break You can now build and run the application. It should take a few minutes to run as it goes through the trial campaign.","title":"Playing against the heuristic player"},{"location":"cogment/tutorial/7-dqn-player/#implementing-the-deep-q-network","text":"We have set everything up, we can now focus on implementing our DQN agent. A Deep Q Network is a neural network taking an observation as input, and outputs the Q value for each of the actions in the action space. The Q Value is an estimation of the expected value of all the rewards if a given action is taken. The DQN agent action policy is therefore to take the action having the largest predicted Q Value. Let's start by implementing this part and we will then deal with training this model. In the rest of this tutorial we will use Tensorflow and its Keras API for the model itself, as well as numpy for datastructures. Let's import these at the top of dqn_agent/main.py . import numpy as np import tensorflow as tf Let's get into the meat of the matter by implementing a function to create our model. We are using Keras functional API to create the following layers: Two scalar inputs, the last moves of the player and the opponent. Each input is one-hot encoded to avoid assuming an unwanted ordering and quantitative relationship between the moves. The two encoded inputs are concatenated to a single vector. A dense non-linear hidden layer is added. The output layers estimates the Q value for each move. Everything then gets wrapped up and returned. This function is then used to create a global _model that we will use in the actor implementation. MOVES = [ ROCK , PAPER , SCISSORS ] actions_count = len ( MOVES ) def create_model (): # 1. Input layers in_me_last_move = tf . keras . Input ( name = \"obs_me_last_move\" , shape = ( 1 )) in_them_last_move = tf . keras . Input ( name = \"obs_them_last_move\" , shape = ( 1 )) # 2. One hot encoding of the layers one_hot_move = tf . keras . layers . experimental . preprocessing . CategoryEncoding ( name = \"one_hot_move\" , max_tokens = len ( MOVES ), output_mode = \"binary\" ) one_hot_me_last_move = one_hot_move ( in_me_last_move ) one_hot_them_last_move = one_hot_move ( in_them_last_move ) # 3. Concatenating the two inputs concat_ins = tf . keras . layers . concatenate ( [ one_hot_me_last_move , one_hot_them_last_move ] ) # 4. Dense hidden layer hidden_layer = tf . keras . layers . Dense ( 24 , activation = \"relu\" )( concat_ins ) # 5. Output outs = tf . keras . layers . Dense ( actions_count , activation = \"linear\" )( hidden_layer ) return tf . keras . Model ( inputs = [ in_me_last_move , in_them_last_move ], outputs = outs , name = \"rps_dqn_policy\" ) _model = create_model () The other piece of the puzzle is implementing a small function that'll convert our observations into inputs for the model we just created. As most of the encoding is handled by the model itself it's fairly straightforward. def model_ins_from_observations ( observations ): return { \"obs_me_last_move\" : np . array ([[ o . snapshot . me . last_move ] for o in observations ]), \"obs_them_last_move\" : np . array ( [[ o . snapshot . them . last_move ] for o in observations ] ), } Finally we can make it work together by replacing the random choice of action by the use of the model. At the moment the model will just use the random initialization weights so don't expect much ! Here is how the event loop in the dqn_agent function will need to be updated to: Use model_ins_from_observations to compute the model inputs, Use the model in inference mode to compute the q value of each of the possible actions, Finally do the action having the largest q value. if event . observation : model_ins = model_ins_from_observations ([ event . observation ]) if event . type == cogment . EventType . ACTIVE : model_outs = _model ( model_ins , training = False ) action = tf . math . argmax ( model_outs [ 0 ]) . numpy () actor_session . do_action ( PlayerAction ( move = action )) You can now build and run the application. It should take a few minutes to run as it goes through the trial campaign. In this example we define _model (and other variables in the following sections) as global mutable variables. It works in our case because the dqn agents are neither distributed nor multithreaded.","title":"Implementing the Deep Q Network"},{"location":"cogment/tutorial/7-dqn-player/#random-exploration","text":"With the previous code, you might have noticed that the agent will play exactly the same action given the same set of observations, this is because the weights of the model are fixed. However, especially at the beginning of the training process we want the agent to experience a variety of situations. We address this issue by introducing a decaying exploration rate epsilon . First we will define as global variables, the parameters for this epsilon value: its minimum value, its maximum and initial value and its decay per tick. We also define as a global variable the current value of epsilon. You can add the following after the imports in dqn_agent/main.py . epsilon_min = 0.05 epsilon_max = 1.0 epsilon_decay_per_tick = ( epsilon_max - epsilon_min ) / 1000.0 # Linearly reach the lowest exploration rate after 1000 ticks _epsilon = epsilon_max We then create a simple function we can use everytime an action needs to be taken to retrieve and update _epsilon def get_and_update_epsilon (): global _epsilon current_epsilon = _epsilon _epsilon -= epsilon_decay_per_tick _epsilon = max ( _epsilon , epsilon_min ) return current_epsilon This function can then be used to do random actions occasionally to facilitate the exploration. To do that, we need to modify slightly how the actions are computed and submitted. if event . type == cogment . EventType . ACTIVE : if np . random . rand ( 1 )[ 0 ] < get_and_update_epsilon (): # Take random action action = np . random . choice ( actions_count ) else : model_outs = _model ( model_ins , training = False ) action = tf . math . argmax ( model_outs [ 0 ]) . numpy () actor_session . do_action ( PlayerAction ( move = action )) You can now build and run the application. Nothing should appear different at this stage.","title":"Random exploration"},{"location":"cogment/tutorial/7-dqn-player/#replay-buffer","text":"In our journey to train a model, the next stage is to build an experience replay buffer to collect actions/observations/rewards triples over the course of the trials. Once done, it'll be usable to train the model using this data. We will start by creating the datastructure. We are using a column-oriented structure relying on numpy arrays as they interoperate easily with tensorflow and support the needed manipulation primitives. Each row is a sample corresponding to one tick: the received observation and reward, the selected action as well as the next tick's received observation. def create_replay_buffer (): return { \"obs_me_last_move\" : np . array ([]), \"obs_them_last_move\" : np . array ([]), \"action\" : np . array ([]), \"reward\" : np . array ([]), \"next_obs_me_last_move\" : np . array ([]), \"next_obs_them_last_move\" : np . array ([]), } _rb = create_replay_buffer () During each trial the agent will collect its data points in a trial replay buffer then append it to the global one. To achieve that we will first create the function in charge of the appending then collect data during the trial and call the \"append\" function. The following function will take a trial replay buffer and append it to the global _rb . To avoid memory overflow the replay buffer size is capped. _collected_samples_count = 0 max_replay_buffer_size = 100000 def append_trial_replay_buffer ( trial_rb ): global _rb global _collected_samples_count trial_rb_size = len ( trial_rb [ \"obs_me_last_move\" ]) for key in _rb . keys (): # Append the trial data to the current vector _rb [ key ] = np . append ( _rb [ key ], trial_rb [ key ]) # Enfore the size limit by discarding older data if len ( _rb [ key ]) > max_replay_buffer_size : _rb [ key ] = _rb [ key ][ - max_replay_buffer_size :] _collected_samples_count += trial_rb_size rb_size = len ( _rb [ \"obs_me_last_move\" ]) # Sanity check, all vectors in the replay buffer should have the same size for key in _rb . keys (): assert rb_size == len ( _rb [ key ]) print ( f \" { trial_rb_size } new samples stored after a trial, now having { rb_size } samples over a total of { _collected_samples_count } collected samples.\" ) The dqn_agent function can then be updated to collect received observations and reward and sent actions. By default every action gets a zero reward. When a reward for a specific tick is received its value gets updated. async def dqn_agent ( actor_session ): actor_session . start () trial_rb = create_replay_buffer () async for event in actor_session . event_loop (): if event . observation : model_ins = model_ins_from_observations ([ event . observation ]) if event . type == cogment . EventType . ACTIVE : # [...] trial_rb [ \"obs_me_last_move\" ] = np . append ( trial_rb [ \"obs_me_last_move\" ], model_ins [ \"obs_me_last_move\" ] ) trial_rb [ \"obs_them_last_move\" ] = np . append ( trial_rb [ \"obs_them_last_move\" ], model_ins [ \"obs_them_last_move\" ] ) trial_rb [ \"action\" ] = np . append ( trial_rb [ \"action\" ], [ action ]) trial_rb [ \"reward\" ] = np . append ( trial_rb [ \"reward\" ], [ 0.0 ]) else : trial_rb [ \"obs_me_last_move\" ] = np . append ( trial_rb [ \"obs_me_last_move\" ], model_ins [ \"obs_me_last_move\" ] ) trial_rb [ \"obs_them_last_move\" ] = np . append ( trial_rb [ \"obs_them_last_move\" ], model_ins [ \"obs_them_last_move\" ] ) for reward in event . rewards : trial_rb [ \"reward\" ][ reward . tick_id ] = reward . value # Shifting the observations to get the next observations trial_rb [ \"next_obs_me_last_move\" ] = trial_rb [ \"obs_me_last_move\" ][ 1 :] trial_rb [ \"next_obs_them_last_move\" ] = trial_rb [ \"obs_them_last_move\" ][ 1 :] # Dropping the last row, as it only contains the last observations trial_rb [ \"obs_me_last_move\" ] = trial_rb [ \"obs_me_last_move\" ][: - 1 ] trial_rb [ \"obs_them_last_move\" ] = trial_rb [ \"obs_them_last_move\" ][: - 1 ] append_trial_replay_buffer ( trial_rb ) You can now build and run the application. The behavior should be the same but the log should confirm that data gets accumulated.","title":"Replay buffer"},{"location":"cogment/tutorial/7-dqn-player/#training","text":"Here we are, all the pieces are in place we can implement the training proper. The function is a standard implementation of DQN and is decomposed in 4 steps: Select a random batch of samples from the replay buffer Compute the target Q value for each sample from the received reward and the next observation using a previous version of the model. (Re)compute the estimated Q value of each sample from the selected action and observation using the current version of the model. Perform an optimization step of the model parameters trying to reduce the loss between the samples estimated and target q values. batch_size = 50 # Size of batch taken from replay buffer gamma = 0.99 # Discount factor for future rewards optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.00025 , clipnorm = 1.0 ) loss_function = tf . keras . losses . Huber () target_model_update_interval = 1000 _target_model = create_model () def train (): global _model global _target_model rb_size = len ( _rb [ \"obs_me_last_move\" ]) if rb_size >= batch_size : # Step 1 - Randomly select a batch batch_indices = np . random . choice ( range ( rb_size ), size = batch_size ) batch_rb = create_replay_buffer () for key in batch_rb . keys (): batch_rb [ key ] = np . take ( _rb [ key ], batch_indices ) # Step 2 - Compute target q values ## Predict the expected reward for the next observation of each sample ## Use the target model for stability target_actions_q_values = _target_model ( { \"obs_me_last_move\" : batch_rb [ \"next_obs_me_last_move\" ], \"obs_them_last_move\" : batch_rb [ \"next_obs_them_last_move\" ], } ) ## target Q value = reward + discount factor * expected future reward target_q_values = batch_rb [ \"reward\" ] + gamma * tf . reduce_max ( target_actions_q_values , axis = 1 ) # Step 3 - Compute estimated q values ## Create masks of the taken actions to later select relevant q values selected_actions_masks = tf . one_hot ( batch_rb [ \"action\" ], actions_count ) with tf . GradientTape () as tape : ## Recompute q values for all the actions at each sample estimated_actions_q_values = _model ( { \"obs_me_last_move\" : batch_rb [ \"obs_me_last_move\" ], \"obs_them_last_move\" : batch_rb [ \"obs_them_last_move\" ], } ) ## Apply the masks to get the Q value for taken actions estimated_q_values = tf . reduce_sum ( tf . multiply ( estimated_actions_q_values , selected_actions_masks ), axis = 1 ) ## Compute loss between the target Q values and the estimated Q values loss = loss_function ( target_q_values , estimated_q_values ) print ( f \"loss= { loss . numpy () } \" ) ## Backpropagation! grads = tape . gradient ( loss , _model . trainable_variables ) optimizer . apply_gradients ( zip ( grads , _model . trainable_variables )) # Update the target model if _collected_samples_count % target_model_update_interval == 0 : _target_model . set_weights ( _model . get_weights ()) This function then needs to be called at the end of each trial after the call to append_trial_replay_buffer . You can now build and run the application. The dqn agent will start to learn and quickly prevails against the heuristic implementation. This can be observed by opening the dashboard at http://localhost:3003 and opening the reward page. You should be able to track the progression of the dqn implementation. This concludes the step 7 of the tutorial: you implemented your first trained actor implementation!","title":"Training!"},{"location":"cogment/tutorial/introduction/","text":"Tutorial \u00b6 You've reached the Cogment tutorial, the best way to learn about the concepts and the usage details of Cogment by using it to create a Rock-Paper-Scissors simulation and build AIs to play the game. Full sources for the tutorials are available at https://github.com/cogment/cogment-tutorial-rps Rock-Paper-Scissors (RPS) \u00b6 Let's quote wikipedia Rock paper scissors [...] is a hand game usually played between two people, in which each player simultaneously forms one of three shapes with an outstretched hand. These shapes are \"rock\" (a closed fist), \"paper\" (a flat hand), and \"scissors\" (a fist with the index finger and middle finger extended, forming a V). \"Scissors\" is identical to the two-fingered V sign (also indicating \"victory\" or \"peace\") except that it is pointed horizontally instead of being held upright in the air. A simultaneous, zero-sum game, it has only two possible outcomes: a draw, or a win for one player and a loss for the other. A player who decides to play rock will beat another player who has chosen scissors (\"rock crushes scissors\"[...]), but will lose to one who has played paper (\"paper covers rock\"); a play of paper will lose to a play of scissors (\"scissors cuts paper\"). If both players choose the same shape, the game is tied and is usually immediately replayed to break the tie. The type of game originated in China and spread with increased contact with East Asia, while developing different variants in signs over time. Its rules can be expressed with the following statements: 2 players are competing to win the most rounds in a game; During each round, players play one move each, simultaneously; 3 moves are available, rock, paper and scissors; rock beats scissors, scissors beats paper and paper beats rock; playing the same move leads to a draw and the round needs to be replayed. RPS is a very simple game with straightforward rules. As long as we \"forbid\" pure random moves, that are very difficult to beat, it is an interesting testbed to develop AIs that compete with Humans. Unlike deep games such as chess or go, the power is not really in the brute force exploration of possible outcomes but in getting some level of understanding of how the opponent plays to be able to anticipate their moves. A good read on the subject of AI and RPS is this article by Benjamin Peterson published by Towards AI: Towards an AI for Rock, Paper, Scissors . Now that we have better general knowledge on the game itself, let's start with the tutorial. Basics \u00b6 In the first 5 steps of the tutorial, you'll go from a blank state to a Cogment app implementing RPS with 3 different player actor implementations: a random player, a simple heuristic player and a human player. The implementations will be done in Python 3, you'll need a good knowledge of the language to follow through. Step 1: Bootstrap the RPS project and define observation & action space data structures Step 2: Implement a first actor and environment Step 3: Introduce rewards Step 4: Create a second actor implementation based on a heuristic Step 5: Add a human player in the loop Webapp \u00b6 In the sixth step of the tutorial, you'll implement your first webapp to provide a more user friendly interface for the human player. The implementation will be done in Javascript and using React. Step 6: Implement a web client for the human player Learning actors \u00b6 In the seventh step of the tutorial, you'll implement your an actor trained with Reinforcement Learning. The implementation will be done in Python and using Tensorflow. Step 7: Add a player trained with Reinforcement Learning using DQN","title":"Introduction"},{"location":"cogment/tutorial/introduction/#tutorial","text":"You've reached the Cogment tutorial, the best way to learn about the concepts and the usage details of Cogment by using it to create a Rock-Paper-Scissors simulation and build AIs to play the game. Full sources for the tutorials are available at https://github.com/cogment/cogment-tutorial-rps","title":"Tutorial"},{"location":"cogment/tutorial/introduction/#rock-paper-scissors-rps","text":"Let's quote wikipedia Rock paper scissors [...] is a hand game usually played between two people, in which each player simultaneously forms one of three shapes with an outstretched hand. These shapes are \"rock\" (a closed fist), \"paper\" (a flat hand), and \"scissors\" (a fist with the index finger and middle finger extended, forming a V). \"Scissors\" is identical to the two-fingered V sign (also indicating \"victory\" or \"peace\") except that it is pointed horizontally instead of being held upright in the air. A simultaneous, zero-sum game, it has only two possible outcomes: a draw, or a win for one player and a loss for the other. A player who decides to play rock will beat another player who has chosen scissors (\"rock crushes scissors\"[...]), but will lose to one who has played paper (\"paper covers rock\"); a play of paper will lose to a play of scissors (\"scissors cuts paper\"). If both players choose the same shape, the game is tied and is usually immediately replayed to break the tie. The type of game originated in China and spread with increased contact with East Asia, while developing different variants in signs over time. Its rules can be expressed with the following statements: 2 players are competing to win the most rounds in a game; During each round, players play one move each, simultaneously; 3 moves are available, rock, paper and scissors; rock beats scissors, scissors beats paper and paper beats rock; playing the same move leads to a draw and the round needs to be replayed. RPS is a very simple game with straightforward rules. As long as we \"forbid\" pure random moves, that are very difficult to beat, it is an interesting testbed to develop AIs that compete with Humans. Unlike deep games such as chess or go, the power is not really in the brute force exploration of possible outcomes but in getting some level of understanding of how the opponent plays to be able to anticipate their moves. A good read on the subject of AI and RPS is this article by Benjamin Peterson published by Towards AI: Towards an AI for Rock, Paper, Scissors . Now that we have better general knowledge on the game itself, let's start with the tutorial.","title":"Rock-Paper-Scissors (RPS)"},{"location":"cogment/tutorial/introduction/#basics","text":"In the first 5 steps of the tutorial, you'll go from a blank state to a Cogment app implementing RPS with 3 different player actor implementations: a random player, a simple heuristic player and a human player. The implementations will be done in Python 3, you'll need a good knowledge of the language to follow through. Step 1: Bootstrap the RPS project and define observation & action space data structures Step 2: Implement a first actor and environment Step 3: Introduce rewards Step 4: Create a second actor implementation based on a heuristic Step 5: Add a human player in the loop","title":"Basics"},{"location":"cogment/tutorial/introduction/#webapp","text":"In the sixth step of the tutorial, you'll implement your first webapp to provide a more user friendly interface for the human player. The implementation will be done in Javascript and using React. Step 6: Implement a web client for the human player","title":"Webapp"},{"location":"cogment/tutorial/introduction/#learning-actors","text":"In the seventh step of the tutorial, you'll implement your an actor trained with Reinforcement Learning. The implementation will be done in Python and using Tensorflow. Step 7: Add a player trained with Reinforcement Learning using DQN","title":"Learning actors"},{"location":"concepts/core-concepts/","text":"Cogment Core Concepts Guide \u00b6 Welcome to the Cogment core concepts guide. It contains information that is pertinent to both the high-level SDK and the low-level API . Core Concepts \u00b6 Cogment is built around concepts adapted from multi-agent systems (agents, environment), Markov decision processes (action and observation space) and reinforcement learning (trials, rewards). Trials \u00b6 Trials are what a Cogment deployment runs. They enable Actors to interact with their Environment . Trials are started by clients connecting to Cogment. A trial can end either by being terminated from a client or end by itself, for example once a specific state of the Environment is reached. During the trial: The Environment generates observations of its internal state and sends them to the actors . Given these observations , each actor might choose and take an action . The Environment receives the actions and updates its state. Rewards can be sent to the actors from either the environment or other actors. Actors receive rewards . The actors or the environment can send messages to actors or the environment. A log of the activity during the trial (observations, actions, rewards & messages) is produced and can be stored. A trial is defined by the participating Actors and the host Environment . As a concept, Trials are quite close to Reinforcement Learning (RL)'s Episodes , i.e. all the states that come between an initial state and a terminal state. However, because Cogment can be used outside of an RL context, we prefer using the more generic term of Trial. Actors \u00b6 Actors within a trial instantiate actor classes defined by the nature of the information they receive from the environment , their observation space , and what actions they can perform, their action space . In Cogment, the observation and action space are defined as typed data structures. In particular, Cogment uses protobuf as a format to specify these data structures. This typing defines both an interface contract between the Actors and the Environment and helps convey semantic information, thus facilitating the independent design and development of both. An Actor might be controlled either by a software Agent , or by a Human. Whichever the case, the process of generating actions based on observations remains the same, and the Environment treats them the same. Environment \u00b6 The Environment is the context within which the Trial takes place. The Environment receives the actions done by the actors, usually updates an internal state, and generates an observation for each Actor . The Environment is the main integration point between Cogment and an external system, either a simulation or a real world system . The cogment.yaml \u00b6 At the heart of every Cogment project is a YAML file typically called cogment.yaml . Its primary role is to define the actor classes present within the project, including their action & observation spaces , as well as a default configuration for trials, including the number of actor participating in each trial and their class and implementation. Architecture \u00b6 Running trials with Cogment usually involves the deployment of a cluster of services and its clients. These components are either provided by the Cogment framework, depicted below in blue, or implemented for a particular project, depicted below in orange. User implemented components use one of the Cogment SDKs or directly implement the underlying protocol . Components communicate using gRPC , clients can also communicate in a web-friendly way using gRPC-Web and grpcwebproxy . Orchestrator \u00b6 The Orchestrator is the glue that binds everything together. It is responsible for running the trials and contacting other services as needed to ensure their execution. The key aspect of Cogment's orchestrator is its capacity to handle a number of network connections in parallel while keeping its responsiveness. Controller \u00b6 The Controller is a key part of using Cogment, it initiates communication with the Orchestrator to control the execution of trials . It is responsible for starting Trials , retrieving and watching their state (including the end of the trial), or requesting trial termination. Environment \u00b6 The Environment implementation is accessed by the Orchestrator to run the Environment during Trials . Using one of Cogment's SDKs , the Environment can be implemented as a function integrating a \"state of the world\" with the Trial . This function performs the following tasks during the Trial: Generate Observations from the current state of the world , for example retrieving the visible objects from a 3D simulation. Apply the Actions , thus updating the state of the world , for example changing the velocity of a moving vehicle in a race simulation. Evaluate the performance of Actors and send them Rewards , for example by checking if a vehicle crossed the finish line in a race simulation. Send and receive direct messages. Actors \u00b6 Actors can be implemented in two different ways, either as a service or as a client. Service Actor implementations are accessed by the Orchestrator during Trials , while Client Actor implementations join a Trial by initiating the communication with the Orchestrator. Client Actors implementations can reach a Cogment deployment through NAT traversal . This makes them particularly well-suited to implement human-driven Actors, in web-browsers for example. Using one of Cogment's SDKs Actors can be implemented as functions handling the integration between a decision-making Actor ( software agent or Human) and the Trial . This function performs the following tasks during the Trial: Receive Observations and do Actions in response, for example vectorizing the retrieved observation, feeding it to a neural network and converting its output to an Action. Receive Rewards , for example using them to update a neural network. Send and receive direct messages. Please note that rewards can also be retrieved after the fact using an activity logger . Additional optional services \u00b6 Beyond the core services described above, a Cogment deployment can include these additional ones: Pre trial hooks can be used to dynamically setup Trials from a given configuration, for example changing the number of Actors or pointing to other Environment or Actor implementations. Activity Logger can be used to listen to the activity during a trial (actions, observations, rewards, messages), for example, to do store these data in order to do offline training of AI agents.","title":"Core Concepts"},{"location":"concepts/core-concepts/#cogment-core-concepts-guide","text":"Welcome to the Cogment core concepts guide. It contains information that is pertinent to both the high-level SDK and the low-level API .","title":"Cogment Core Concepts Guide"},{"location":"concepts/core-concepts/#core-concepts","text":"Cogment is built around concepts adapted from multi-agent systems (agents, environment), Markov decision processes (action and observation space) and reinforcement learning (trials, rewards).","title":"Core Concepts"},{"location":"concepts/core-concepts/#trials","text":"Trials are what a Cogment deployment runs. They enable Actors to interact with their Environment . Trials are started by clients connecting to Cogment. A trial can end either by being terminated from a client or end by itself, for example once a specific state of the Environment is reached. During the trial: The Environment generates observations of its internal state and sends them to the actors . Given these observations , each actor might choose and take an action . The Environment receives the actions and updates its state. Rewards can be sent to the actors from either the environment or other actors. Actors receive rewards . The actors or the environment can send messages to actors or the environment. A log of the activity during the trial (observations, actions, rewards & messages) is produced and can be stored. A trial is defined by the participating Actors and the host Environment . As a concept, Trials are quite close to Reinforcement Learning (RL)'s Episodes , i.e. all the states that come between an initial state and a terminal state. However, because Cogment can be used outside of an RL context, we prefer using the more generic term of Trial.","title":"Trials"},{"location":"concepts/core-concepts/#actors","text":"Actors within a trial instantiate actor classes defined by the nature of the information they receive from the environment , their observation space , and what actions they can perform, their action space . In Cogment, the observation and action space are defined as typed data structures. In particular, Cogment uses protobuf as a format to specify these data structures. This typing defines both an interface contract between the Actors and the Environment and helps convey semantic information, thus facilitating the independent design and development of both. An Actor might be controlled either by a software Agent , or by a Human. Whichever the case, the process of generating actions based on observations remains the same, and the Environment treats them the same.","title":"Actors"},{"location":"concepts/core-concepts/#environment","text":"The Environment is the context within which the Trial takes place. The Environment receives the actions done by the actors, usually updates an internal state, and generates an observation for each Actor . The Environment is the main integration point between Cogment and an external system, either a simulation or a real world system .","title":"Environment"},{"location":"concepts/core-concepts/#the-cogmentyaml","text":"At the heart of every Cogment project is a YAML file typically called cogment.yaml . Its primary role is to define the actor classes present within the project, including their action & observation spaces , as well as a default configuration for trials, including the number of actor participating in each trial and their class and implementation.","title":"The cogment.yaml"},{"location":"concepts/core-concepts/#architecture","text":"Running trials with Cogment usually involves the deployment of a cluster of services and its clients. These components are either provided by the Cogment framework, depicted below in blue, or implemented for a particular project, depicted below in orange. User implemented components use one of the Cogment SDKs or directly implement the underlying protocol . Components communicate using gRPC , clients can also communicate in a web-friendly way using gRPC-Web and grpcwebproxy .","title":"Architecture"},{"location":"concepts/core-concepts/#orchestrator","text":"The Orchestrator is the glue that binds everything together. It is responsible for running the trials and contacting other services as needed to ensure their execution. The key aspect of Cogment's orchestrator is its capacity to handle a number of network connections in parallel while keeping its responsiveness.","title":"Orchestrator"},{"location":"concepts/core-concepts/#controller","text":"The Controller is a key part of using Cogment, it initiates communication with the Orchestrator to control the execution of trials . It is responsible for starting Trials , retrieving and watching their state (including the end of the trial), or requesting trial termination.","title":"Controller"},{"location":"concepts/core-concepts/#environment_1","text":"The Environment implementation is accessed by the Orchestrator to run the Environment during Trials . Using one of Cogment's SDKs , the Environment can be implemented as a function integrating a \"state of the world\" with the Trial . This function performs the following tasks during the Trial: Generate Observations from the current state of the world , for example retrieving the visible objects from a 3D simulation. Apply the Actions , thus updating the state of the world , for example changing the velocity of a moving vehicle in a race simulation. Evaluate the performance of Actors and send them Rewards , for example by checking if a vehicle crossed the finish line in a race simulation. Send and receive direct messages.","title":"Environment"},{"location":"concepts/core-concepts/#actors_1","text":"Actors can be implemented in two different ways, either as a service or as a client. Service Actor implementations are accessed by the Orchestrator during Trials , while Client Actor implementations join a Trial by initiating the communication with the Orchestrator. Client Actors implementations can reach a Cogment deployment through NAT traversal . This makes them particularly well-suited to implement human-driven Actors, in web-browsers for example. Using one of Cogment's SDKs Actors can be implemented as functions handling the integration between a decision-making Actor ( software agent or Human) and the Trial . This function performs the following tasks during the Trial: Receive Observations and do Actions in response, for example vectorizing the retrieved observation, feeding it to a neural network and converting its output to an Action. Receive Rewards , for example using them to update a neural network. Send and receive direct messages. Please note that rewards can also be retrieved after the fact using an activity logger .","title":"Actors"},{"location":"concepts/core-concepts/#additional-optional-services","text":"Beyond the core services described above, a Cogment deployment can include these additional ones: Pre trial hooks can be used to dynamically setup Trials from a given configuration, for example changing the number of Actors or pointing to other Environment or Actor implementations. Activity Logger can be used to listen to the activity during a trial (actions, observations, rewards, messages), for example, to do store these data in order to do offline training of AI agents.","title":"Additional optional services"},{"location":"concepts/glossary/","text":"Glossary \u00b6 Terminology is a very important part of understanding new concepts and learning how to use new technology. The words we use throughout our documentation may cause problems if one is not familiar with how we use those words; this is a glossary of terms for newcomers and seasoned developers alike. Some familiar terms may have additional caveats specifically added to their definition in the context of the Cogment Framework (generally for clarity). A \u2014B\u2014C\u2014D\u2014 E \u2014 F \u2014G\u2014 H \u2014I\u2014J\u2014K\u2014L\u2014 M \u2014N\u2014 O \u2014 P \u2014Q\u2014 R \u2014S\u2014 T \u2014 U \u2014V\u2014W\u2014X\u2014Y A \u00b6 Actor \u00b6 An actor is somebody or something who/which interacts with the environment by executing certain actions, taking observations, and receiving rewards (positive or negative) for this. An Actor can be an Agent (of any level of complexity and any type of flexibility, from bots to ML agents), or a human user. Actor Class \u00b6 Each Actor always belongs to a single Actor Class. An Actor Class is primarily defined by its associated Action Space , as a property of an environment . For example, pilot and passenger could be two different Actor Classes. Action \u00b6 An Action is an interaction an Actor performs on the environment. Actions are picked from the Action Space , A single element of an Action Space. Agent \u00b6 We usually call agent, non-human Actors . Agents can use on any sort of decision-making underlying system, able to learn or not. E \u00b6 Environment \u00b6 The environment is the set of rules defining how a trial evolves over time for any given use case. For example, to train a pilot agent , a flight simulation would be the environment. Actors can interact with the environment itself, or with each other through the environment, within the boundaries of the environment ruleset (i.e. how an environment can change, from environmental rulesets or the actions of Actors in the environment). A stateful instance of an environment. Environment State \u00b6 An environment state is the specific set of conditions in which the environment is at a specific time (for example, when it is first instantiated). These conditions can be observable or not, and our Framework does not concern itself with the ones that are not. F \u00b6 Framework \u00b6 These two elements combined are what we call the framework: Orchestrator SDKs Frontend \u00b6 The interface, usually an app, that humans use to interact with the rest of the system; the software that turns humans into Actors . H \u00b6 Human / Artificial Intelligence Interaction Loop Training \u00b6 We call Human / AI interaction loop training the fundamental paradigm our Framework was build for: a continuous loop between humans and agents where they learn from each other. It\u2019s a way to train agents in an environment where direct human interactions, whether between humans, between humans and the environment, or between humans and agents, provide live data to the agents (first part of the loop), as well as a way for agents to interact with humans, either directly or through the environment (second part of the loop). M \u00b6 Message \u00b6 Messages can be sent from any actor or the environment to any actor or the environment . The message can be any protobuf class. This creates channels between any set of actors and the environment . These channels can be used for applications where communication between actors and the environment need to be outside of the standard observation and action spaces. Model \u00b6 A model is a representation, usually a mathematical one in our context, of a concept, structure, system, or an aspect of the real world. It is usually a simplified and abstracted representation. O \u00b6 Observation \u00b6 An observation is the subset of the environment state that an Actor based its choice of Action on. Observation delta \u00b6 An observation delta is the difference between two observations . Usually, we encode deltas from the past to the future. Observation transition \u00b6 An observation transition is an observation delta between two consecutive observations . Observation space \u00b6 An Observation space is the set of all possible observations an Actor can make of an environment . Orchestrator \u00b6 The Orchestrator is the central piece of our framework ; it\u2019s an executable that handles several things: It circulates data flows between Actors and Environments . It dumps datasets in the chosen storage location. It compresses & encrypts data. It collates various reward sources (usually environment or actors ) into a single reward for an Actor. It instantiates the trials . P \u00b6 Plugin/extension \u00b6 A plugin or extension adds functionality to our core framework . We provide plugins that handle special features such as Deployment, Dataset storage destinations, Analytics, that one may or may not choose to use alongside the core framework, depending on their specific needs. Protocol Buffer \u00b6 A binary data format for serialized communication, .proto files are used to specify the available data structures. You can learn more at https://developers.google.com/protocol-buffers/ . R \u00b6 Reward \u00b6 A sent reward is a measure of an Actor\u2019s performance within the environment at a given tick . The reward can be sent by the environment, and/or a different Actor. They are sent to the Orchestrator , which collate before they are received by the target actor. A received reward is a single measure of an Actor\u2019s performance. It is produced when at least one reward is sent to the actor at a given tick . Reward function \u00b6 A reward function describes how an agent \"ought\" to behave; what behaviours lead to Rewards . Note that in our case, Reward functions can be used to reward any Actor , regardless of it being human or not. Reinforcement Learning (RL) \u00b6 RL is a specific method to train agents , using reward functions . T \u00b6 Tick \u00b6 A tick is a discrete timestep between two states of the environment , in our Framework , ticks within a trial are numbered. Trial \u00b6 A trial is a single run of a use case, with a beginning and end, populated with a single instance of the use case\u2019s environment and its actors . U \u00b6 Use case \u00b6 The problem one wants to solve.","title":"Glossary"},{"location":"concepts/glossary/#glossary","text":"Terminology is a very important part of understanding new concepts and learning how to use new technology. The words we use throughout our documentation may cause problems if one is not familiar with how we use those words; this is a glossary of terms for newcomers and seasoned developers alike. Some familiar terms may have additional caveats specifically added to their definition in the context of the Cogment Framework (generally for clarity). A \u2014B\u2014C\u2014D\u2014 E \u2014 F \u2014G\u2014 H \u2014I\u2014J\u2014K\u2014L\u2014 M \u2014N\u2014 O \u2014 P \u2014Q\u2014 R \u2014S\u2014 T \u2014 U \u2014V\u2014W\u2014X\u2014Y","title":"Glossary"},{"location":"concepts/glossary/#a","text":"","title":"A"},{"location":"concepts/glossary/#actor","text":"An actor is somebody or something who/which interacts with the environment by executing certain actions, taking observations, and receiving rewards (positive or negative) for this. An Actor can be an Agent (of any level of complexity and any type of flexibility, from bots to ML agents), or a human user.","title":"Actor"},{"location":"concepts/glossary/#actor-class","text":"Each Actor always belongs to a single Actor Class. An Actor Class is primarily defined by its associated Action Space , as a property of an environment . For example, pilot and passenger could be two different Actor Classes.","title":"Actor Class"},{"location":"concepts/glossary/#action","text":"An Action is an interaction an Actor performs on the environment. Actions are picked from the Action Space , A single element of an Action Space.","title":"Action"},{"location":"concepts/glossary/#agent","text":"We usually call agent, non-human Actors . Agents can use on any sort of decision-making underlying system, able to learn or not.","title":"Agent"},{"location":"concepts/glossary/#e","text":"","title":"E"},{"location":"concepts/glossary/#environment","text":"The environment is the set of rules defining how a trial evolves over time for any given use case. For example, to train a pilot agent , a flight simulation would be the environment. Actors can interact with the environment itself, or with each other through the environment, within the boundaries of the environment ruleset (i.e. how an environment can change, from environmental rulesets or the actions of Actors in the environment). A stateful instance of an environment.","title":"Environment"},{"location":"concepts/glossary/#environment-state","text":"An environment state is the specific set of conditions in which the environment is at a specific time (for example, when it is first instantiated). These conditions can be observable or not, and our Framework does not concern itself with the ones that are not.","title":"Environment State"},{"location":"concepts/glossary/#f","text":"","title":"F"},{"location":"concepts/glossary/#framework","text":"These two elements combined are what we call the framework: Orchestrator SDKs","title":"Framework"},{"location":"concepts/glossary/#frontend","text":"The interface, usually an app, that humans use to interact with the rest of the system; the software that turns humans into Actors .","title":"Frontend"},{"location":"concepts/glossary/#h","text":"","title":"H"},{"location":"concepts/glossary/#human-artificial-intelligence-interaction-loop-training","text":"We call Human / AI interaction loop training the fundamental paradigm our Framework was build for: a continuous loop between humans and agents where they learn from each other. It\u2019s a way to train agents in an environment where direct human interactions, whether between humans, between humans and the environment, or between humans and agents, provide live data to the agents (first part of the loop), as well as a way for agents to interact with humans, either directly or through the environment (second part of the loop).","title":"Human / Artificial Intelligence Interaction Loop Training"},{"location":"concepts/glossary/#m","text":"","title":"M"},{"location":"concepts/glossary/#message","text":"Messages can be sent from any actor or the environment to any actor or the environment . The message can be any protobuf class. This creates channels between any set of actors and the environment . These channels can be used for applications where communication between actors and the environment need to be outside of the standard observation and action spaces.","title":"Message"},{"location":"concepts/glossary/#model","text":"A model is a representation, usually a mathematical one in our context, of a concept, structure, system, or an aspect of the real world. It is usually a simplified and abstracted representation.","title":"Model"},{"location":"concepts/glossary/#o","text":"","title":"O"},{"location":"concepts/glossary/#observation","text":"An observation is the subset of the environment state that an Actor based its choice of Action on.","title":"Observation"},{"location":"concepts/glossary/#observation-delta","text":"An observation delta is the difference between two observations . Usually, we encode deltas from the past to the future.","title":"Observation delta"},{"location":"concepts/glossary/#observation-transition","text":"An observation transition is an observation delta between two consecutive observations .","title":"Observation transition"},{"location":"concepts/glossary/#observation-space","text":"An Observation space is the set of all possible observations an Actor can make of an environment .","title":"Observation space"},{"location":"concepts/glossary/#orchestrator","text":"The Orchestrator is the central piece of our framework ; it\u2019s an executable that handles several things: It circulates data flows between Actors and Environments . It dumps datasets in the chosen storage location. It compresses & encrypts data. It collates various reward sources (usually environment or actors ) into a single reward for an Actor. It instantiates the trials .","title":"Orchestrator"},{"location":"concepts/glossary/#p","text":"","title":"P"},{"location":"concepts/glossary/#pluginextension","text":"A plugin or extension adds functionality to our core framework . We provide plugins that handle special features such as Deployment, Dataset storage destinations, Analytics, that one may or may not choose to use alongside the core framework, depending on their specific needs.","title":"Plugin/extension"},{"location":"concepts/glossary/#protocol-buffer","text":"A binary data format for serialized communication, .proto files are used to specify the available data structures. You can learn more at https://developers.google.com/protocol-buffers/ .","title":"Protocol Buffer"},{"location":"concepts/glossary/#r","text":"","title":"R"},{"location":"concepts/glossary/#reward","text":"A sent reward is a measure of an Actor\u2019s performance within the environment at a given tick . The reward can be sent by the environment, and/or a different Actor. They are sent to the Orchestrator , which collate before they are received by the target actor. A received reward is a single measure of an Actor\u2019s performance. It is produced when at least one reward is sent to the actor at a given tick .","title":"Reward"},{"location":"concepts/glossary/#reward-function","text":"A reward function describes how an agent \"ought\" to behave; what behaviours lead to Rewards . Note that in our case, Reward functions can be used to reward any Actor , regardless of it being human or not.","title":"Reward function"},{"location":"concepts/glossary/#reinforcement-learning-rl","text":"RL is a specific method to train agents , using reward functions .","title":"Reinforcement Learning (RL)"},{"location":"concepts/glossary/#t","text":"","title":"T"},{"location":"concepts/glossary/#tick","text":"A tick is a discrete timestep between two states of the environment , in our Framework , ticks within a trial are numbered.","title":"Tick"},{"location":"concepts/glossary/#trial","text":"A trial is a single run of a use case, with a beginning and end, populated with a single instance of the use case\u2019s environment and its actors .","title":"Trial"},{"location":"concepts/glossary/#u","text":"","title":"U"},{"location":"concepts/glossary/#use-case","text":"The problem one wants to solve.","title":"Use case"},{"location":"deployment-guide/cloud-deployment/","text":"Cogment Cloud Deployment \u00b6","title":"Cogment Cloud Deployment"},{"location":"deployment-guide/cloud-deployment/#cogment-cloud-deployment","text":"","title":"Cogment Cloud Deployment"},{"location":"deployment-guide/local-deployement/","text":"Cogment Local Deployment \u00b6","title":"Cogment Local Deployment"},{"location":"deployment-guide/local-deployement/#cogment-local-deployment","text":"","title":"Cogment Local Deployment"},{"location":"introduction/installation/","text":"How to Download and Install Cogment \u00b6 Pre-Requisites \u00b6 Please install: Docker and docker-compose protoc Install the latest Cogment CLI \u00b6 cogment CLI releases are available here as executable binaries. Pick a version, usually the latest one should be the right pick. At the end of the release notes, click on \"Assets\" to choose and download the appropriate version for your system. Rename the file to \"cogment\", and add it to your PATH environmental variable . You can follow more specific instructions for your OS in the following. Linux \u00b6 The following downloads version COGMENT_CLI_VERSION of the cli to /usr/local/bin , a location already belonging to your PATH in most linux distributions and make sure it is executable. Simply replace COGMENT_CLI_VERSION with the version you want to download, e.g. v1.0.1 . $ curl -L https://github.com/cogment/cogment-cli/releases/download/COGMENT_CLI_VERSION/cogment-linux-amd64 -o /usr/local/bin/cogment && chmod +x /usr/local/bin/cogment macOS \u00b6 At the moment Cogment will only work on x86 intel macs The following downloads version COGMENT_CLI_VERSION of the cli to /usr/local/bin , a location already belonging to your PATH in macOS and make sure it is executable. Simply replace COGMENT_CLI_VERSION with the version you want to download, e.g. v1.0.1 . $ curl -L https://github.com/cogment/cogment-cli/releases/download/COGMENT_CLI_VERSION/cogment-macOS-amd64 -o /usr/local/bin/cogment && chmod +x /usr/local/bin/cogment Windows \u00b6 Download the windows version of the cogment CLI as described above. Rename the downloaded file cogment-windows-amd64.exe to cogment.exe . Copy it to an easy to find location, e.g. c:\\\\cogment . Add the c:\\\\cogment folder to your PATH environmental variable . Check that Cogment CLI is accessible. \u00b6 With a working installation you can run the following in a terminal: $ cogment version You can then list all the commands by typing: $ cogment help or for help on each individual command: $ cogment help <command> Test your installation \u00b6 In order to test that your installation is fully working, run an existing Cogment app, for example one of the steps of the tutorial. Download or clone the sources for the official Rock-Paper-Scissors ( RPS ) tutorial from https://github.com/cogment/cogment-tutorial-rps . Once it is done, run the following in the directory you retrieved: $ cd 5 -human-player $ cogment run generate $ cogment run build $ cogment run start The first cogment command will run the code generation phase for this project. If everything runs fine it means cogment and Protobuf's protoc are installed correctly. The second will build docker images for the services of this Cogment app. If everything runs fine it means the docker and docker-compose installations are functional. Finally, the third command will start the Cogment app. In another terminal you can connect to it and play a few games of RPS against a simple AI agent. $ cogment run client Congratulations, you have a working installation of Cogment! We recommend you head to the Cogment tutorial to learn how to implement this RPS app from scratch.","title":"Installation & Setup"},{"location":"introduction/installation/#how-to-download-and-install-cogment","text":"","title":"How to Download and Install Cogment"},{"location":"introduction/installation/#pre-requisites","text":"Please install: Docker and docker-compose protoc","title":"Pre-Requisites"},{"location":"introduction/installation/#install-the-latest-cogment-cli","text":"cogment CLI releases are available here as executable binaries. Pick a version, usually the latest one should be the right pick. At the end of the release notes, click on \"Assets\" to choose and download the appropriate version for your system. Rename the file to \"cogment\", and add it to your PATH environmental variable . You can follow more specific instructions for your OS in the following.","title":"Install the latest Cogment CLI"},{"location":"introduction/installation/#linux","text":"The following downloads version COGMENT_CLI_VERSION of the cli to /usr/local/bin , a location already belonging to your PATH in most linux distributions and make sure it is executable. Simply replace COGMENT_CLI_VERSION with the version you want to download, e.g. v1.0.1 . $ curl -L https://github.com/cogment/cogment-cli/releases/download/COGMENT_CLI_VERSION/cogment-linux-amd64 -o /usr/local/bin/cogment && chmod +x /usr/local/bin/cogment","title":"Linux"},{"location":"introduction/installation/#macos","text":"At the moment Cogment will only work on x86 intel macs The following downloads version COGMENT_CLI_VERSION of the cli to /usr/local/bin , a location already belonging to your PATH in macOS and make sure it is executable. Simply replace COGMENT_CLI_VERSION with the version you want to download, e.g. v1.0.1 . $ curl -L https://github.com/cogment/cogment-cli/releases/download/COGMENT_CLI_VERSION/cogment-macOS-amd64 -o /usr/local/bin/cogment && chmod +x /usr/local/bin/cogment","title":"macOS"},{"location":"introduction/installation/#windows","text":"Download the windows version of the cogment CLI as described above. Rename the downloaded file cogment-windows-amd64.exe to cogment.exe . Copy it to an easy to find location, e.g. c:\\\\cogment . Add the c:\\\\cogment folder to your PATH environmental variable .","title":"Windows"},{"location":"introduction/installation/#check-that-cogment-cli-is-accessible","text":"With a working installation you can run the following in a terminal: $ cogment version You can then list all the commands by typing: $ cogment help or for help on each individual command: $ cogment help <command>","title":"Check that Cogment CLI is accessible."},{"location":"introduction/installation/#test-your-installation","text":"In order to test that your installation is fully working, run an existing Cogment app, for example one of the steps of the tutorial. Download or clone the sources for the official Rock-Paper-Scissors ( RPS ) tutorial from https://github.com/cogment/cogment-tutorial-rps . Once it is done, run the following in the directory you retrieved: $ cd 5 -human-player $ cogment run generate $ cogment run build $ cogment run start The first cogment command will run the code generation phase for this project. If everything runs fine it means cogment and Protobuf's protoc are installed correctly. The second will build docker images for the services of this Cogment app. If everything runs fine it means the docker and docker-compose installations are functional. Finally, the third command will start the Cogment app. In another terminal you can connect to it and play a few games of RPS against a simple AI agent. $ cogment run client Congratulations, you have a working installation of Cogment! We recommend you head to the Cogment tutorial to learn how to implement this RPS app from scratch.","title":"Test your installation"},{"location":"support/community-channels/","text":"Community \u00b6 The best way to interact with the Cogment community is to use Discord and join our server. If you're unfamiliar with Discord , it's a community tool allowing people to regroup, chat via text and voice and interact, that can be used either through any web browser, or through its dedicated client applications for computers and mobile devices . Cogment Discord Server \u00b6 To join our Discord server, simply click on the link below. If you have the dedicated client application, it will open it there, if not, it will use your web browser. Find us on Cogment's Discord server. Cogment subreddit \u00b6 Cogment also has an official subreddit you can explore.","title":"Community channels"},{"location":"support/community-channels/#community","text":"The best way to interact with the Cogment community is to use Discord and join our server. If you're unfamiliar with Discord , it's a community tool allowing people to regroup, chat via text and voice and interact, that can be used either through any web browser, or through its dedicated client applications for computers and mobile devices .","title":"Community"},{"location":"support/community-channels/#cogment-discord-server","text":"To join our Discord server, simply click on the link below. If you have the dedicated client application, it will open it there, if not, it will use your web browser. Find us on Cogment's Discord server.","title":"Cogment Discord Server"},{"location":"support/community-channels/#cogment-subreddit","text":"Cogment also has an official subreddit you can explore.","title":"Cogment subreddit"},{"location":"support/troubleshooting/","text":"Troubleshooting \u00b6 \ud83d\udea7","title":"Troubleshooting"},{"location":"support/troubleshooting/#troubleshooting","text":"\ud83d\udea7","title":"Troubleshooting"}]}